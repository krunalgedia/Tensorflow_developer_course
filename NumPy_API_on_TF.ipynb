{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "import timeit\n",
    "from datetime import datetime\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow version 2.5.0-dev20210102\n"
     ]
    }
   ],
   "source": [
    "print(\"Using TensorFlow version %s\" % tf.__version__)\n",
    "import tensorflow.experimental.numpy as tnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created ND array with shape = (5, 3), rank = 2, dtype = float32 on device = /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\n",
      "The ND array wraps a tf.Tensor: tf.Tensor(\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]], shape=(5, 3), dtype=float32)\n",
      "\n",
      "ndarray.T has shape (3, 5)\n",
      "narray.reshape(-1) has shape 15\n"
     ]
    }
   ],
   "source": [
    "# ND Array == instance of  tf.experimental.numpy.ndarray\n",
    "#             -> internally wraps tf.Tensor\n",
    "\n",
    "# Create an ND array and check out different attributes.\n",
    "ones = tnp.ones([5, 3], dtype=tnp.float32)\n",
    "print(\"Created ND array with shape = %s, rank = %s, \"\"dtype = %s on device = %s\\n\" % (ones.shape, ones.ndim, ones.dtype, ones.data.device))\n",
    "\n",
    "# Check out the internally wrapped `tf.Tensor` object.\n",
    "print(\"The ND array wraps a tf.Tensor: %s\\n\" % ones.data)\n",
    "\n",
    "# Try commonly used member functions.\n",
    "print(\"ndarray.T has shape %s\" % str(ones.T.shape))\n",
    "print(\"narray.reshape(-1) has shape %s\" % ones.reshape(-1).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type promotion for operations\n",
      "int32 + int64 => int64\n",
      "int32 + float32 => float64\n",
      "int32 + float64 => float64\n",
      "int64 + float32 => float64\n",
      "int64 + float64 => float64\n",
      "float32 + float64 => float64\n",
      "Type inference during array creation\n",
      "tnp.asarray(1).dtype == tnp.int32\n",
      "tnp.asarray(1.).dtype == tnp.float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Type promotion for operations\")\n",
    "values = [tnp.asarray(1, dtype=d) for d in (tnp.int32, tnp.int64, tnp.float32, tnp.float64)]\n",
    "for i, v1 in enumerate(values):\n",
    "  for v2 in values[i+1:]:\n",
    "    print(\"%s + %s => %s\" % (v1.dtype, v2.dtype, (v1 + v2).dtype))\n",
    "\n",
    "print(\"Type inference during array creation\")\n",
    "print(\"tnp.asarray(1).dtype == tnp.%s\" % tnp.asarray(1).dtype)\n",
    "print(\"tnp.asarray(1.).dtype == tnp.%s\\n\" % tnp.asarray(1.).dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broadcasting shapes (2, 3), (3,) and (1, 2, 1) gives shape (1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "x = tnp.ones([2, 3])\n",
    "y = tnp.ones([3])\n",
    "z = tnp.ones([1, 2, 1])\n",
    "print(\"Broadcasting shapes %s, %s and %s gives shape %s\" % (x.shape, y.shape, z.shape, (x + y + z).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum = 6.0. Class: <class 'numpy.float64'>\n",
      "sum = 6.0. Class: <class 'tensorflow.python.ops.numpy_ops.np_arrays.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# this interchange may cause data copies!!! (esp. for passing np.ndarray to tf numpy)\n",
    "# ND array passed into NumPy function.\n",
    "np_sum = np.sum(tnp.ones([2, 3]))\n",
    "print(\"sum = %s. Class: %s\" % (float(np_sum), np_sum.__class__))\n",
    "\n",
    "# `np.ndarray` passed into TensorFlow NumPy function.\n",
    "tnp_sum = tnp.sum(np.ones([2, 3]))\n",
    "print(\"sum = %s. Class: %s\" % (float(tnp_sum), tnp_sum.__class__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# It is easy to plot ND arrays, given the __array__ interface.\n",
    "labels = 15 + 2 * tnp.random.randn(1000)\n",
    "len(labels)\n",
    "_ = plt.hist(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = ndarray<tf.Tensor([2. 2.], shape=(2,), dtype=float64)>\n",
      "class = <class 'tensorflow.python.ops.numpy_ops.np_arrays.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x = tnp.ones([2]) + np.ones([2])\n",
    "print(\"x = %s\\nclass = %s\" % (x, x.__class__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndarray<tf.Tensor([1 2], shape=(2,), dtype=int32)>\n",
      "tf.Tensor([1 2], shape=(2,), dtype=int32)\n",
      "tf.Tensor([1 2], shape=(2,), dtype=int32)\n",
      "[1 2] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1, 2])\n",
    "\n",
    "# Convert `tf.Tensor` to `ndarray`.\n",
    "tnp_x = tnp.asarray(x)\n",
    "print(tnp_x)\n",
    "\n",
    "# Convert `ndarray` to `tf.Tensor` can be done in following ways.\n",
    "print(tnp_x.data)\n",
    "print(tf.convert_to_tensor(tnp_x))\n",
    "\n",
    "# Note that tf.Tensor.numpy() will continue to return `np.ndarray`.\n",
    "print(x.numpy(), x.numpy().__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output = tf.Tensor(6.0, shape=(), dtype=float32)\n",
      "Output = ndarray<tf.Tensor(6.0, shape=(), dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "# ND array passed into TensorFlow function.\n",
    "# This returns a `tf.Tensor`.\n",
    "tf_sum = tf.reduce_sum(tnp.ones([2, 3], tnp.float32))\n",
    "print(\"Output = %s\" % tf_sum)\n",
    "\n",
    "# `tf.Tensor` passed into TensorFlow NumPy function.\n",
    "# This returns an ND array.\n",
    "tnp_sum = tnp.sum(tf.ones([2, 3]))\n",
    "print(\"Output = %s\" % tnp_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tf.Tensor(\n",
      "[[2. 2.]\n",
      " [2. 2.]], shape=(2, 2), dtype=float32)\n",
      "Class = <class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "x = tnp.ones([2, 2]) + tf.ones([2, 1])\n",
    "print(\"x = %s\\nClass = %s\" % (x, x.__class__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndarray<tf.Tensor(\n",
      "[[-0.571265  0.542683]\n",
      " [-0.571265  0.542683]], shape=(2, 2), dtype=float32)>\n",
      "(ndarray<<tf.Tensor: shape=(32, 64), dtype=float32, numpy=\n",
      "array([[ 2.7971673e-01, -2.0902634e-02,  2.3262843e-01, ...,\n",
      "        -9.4256150e-03,  2.2022738e-01, -2.5893027e-01],\n",
      "       [-9.6556221e-05, -2.9957063e-02, -1.7519373e-01, ...,\n",
      "         1.0354334e-01, -5.5686809e-02,  8.0912657e-02],\n",
      "       [-1.8033135e-01,  5.8357317e-02,  1.6310488e-01, ...,\n",
      "        -1.5995122e-02, -7.3345877e-02,  2.9494342e-01],\n",
      "       ...,\n",
      "       [-1.7130308e-01, -3.3424415e-02, -9.2471652e-02, ...,\n",
      "         1.3585578e-01, -1.5599339e-02,  8.8118970e-02],\n",
      "       [ 5.0635736e-02, -1.4859751e-01,  6.7666225e-02, ...,\n",
      "         6.7930304e-02, -2.3089866e-01,  4.4580404e-02],\n",
      "       [ 1.6832185e-01,  3.9510950e-01, -3.1958616e-01, ...,\n",
      "         2.2902837e-02,  1.2933820e-01,  1.6916427e-01]], dtype=float32)>>, ndarray<<tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
      "array([ 1.2630885 ,  0.298951  ,  0.03969102, -0.25278562,  0.4497498 ,\n",
      "       -0.80704623,  0.28190964, -0.42667276, -0.0583753 , -1.1930869 ,\n",
      "        0.7319062 ,  0.57585263, -0.8843388 ,  0.78114957,  0.06054248,\n",
      "       -0.14103729,  0.8670958 ,  0.20609352,  1.4947882 ,  0.28783372,\n",
      "        0.88162965,  0.46619287, -0.65306735,  0.18258959, -1.5527741 ,\n",
      "       -1.2384771 , -0.11188938,  1.6160794 , -1.1533188 , -0.01105277,\n",
      "        2.0281374 , -0.17364675,  0.7047859 ,  2.2989423 , -0.24377526,\n",
      "        0.33743477,  0.41134614, -0.28118244, -0.69234455, -0.7043025 ,\n",
      "        1.0228953 , -0.7772415 , -0.46889296, -1.423989  ,  0.28486133,\n",
      "        1.247766  ,  0.75949925, -4.356715  ,  0.6985812 , -0.04203487,\n",
      "        0.61732304,  0.30338874, -0.04892324, -0.6289042 ,  1.7137827 ,\n",
      "       -0.38053346, -0.22811987, -0.7715558 ,  0.11461217,  0.66669405,\n",
      "       -0.9052594 ,  0.8375133 , -0.29689345,  0.17988433], dtype=float32)>>, ndarray<<tf.Tensor: shape=(64, 2), dtype=float32, numpy=\n",
      "array([[-0.01240459,  0.23352262],\n",
      "       [-0.07552443,  0.16402517],\n",
      "       [-0.23697692, -0.04328338],\n",
      "       [ 0.09507713, -0.15861446],\n",
      "       [ 0.11829838, -0.13547856],\n",
      "       [-0.03968341, -0.22612005],\n",
      "       [-0.0588419 ,  0.04428777],\n",
      "       [ 0.0536256 , -0.09316557],\n",
      "       [ 0.20110478,  0.10099268],\n",
      "       [-0.32831526,  0.12811475],\n",
      "       [ 0.04135718,  0.20343184],\n",
      "       [ 0.05004187,  0.09528553],\n",
      "       [ 0.07499377, -0.10101952],\n",
      "       [-0.10842343, -0.09504023],\n",
      "       [ 0.20118989, -0.02483533],\n",
      "       [ 0.22187306,  0.15271805],\n",
      "       [-0.25094432, -0.02231073],\n",
      "       [ 0.0709527 ,  0.12362248],\n",
      "       [ 0.13397835, -0.14319772],\n",
      "       [-0.07362787,  0.02915849],\n",
      "       [ 0.08876196, -0.08118203],\n",
      "       [-0.07304851, -0.08499515],\n",
      "       [ 0.09706033,  0.06733689],\n",
      "       [-0.0125428 , -0.03911091],\n",
      "       [-0.272236  , -0.18317121],\n",
      "       [ 0.04165704,  0.06171016],\n",
      "       [-0.0052023 , -0.10569489],\n",
      "       [-0.01664912,  0.02602075],\n",
      "       [ 0.32699803,  0.05644507],\n",
      "       [-0.15760086,  0.2073392 ],\n",
      "       [-0.19063592,  0.1616785 ],\n",
      "       [-0.1051987 ,  0.06118518],\n",
      "       [-0.00825777,  0.27044868],\n",
      "       [-0.04257215, -0.08261891],\n",
      "       [-0.02221251,  0.3309132 ],\n",
      "       [ 0.07601763, -0.0835389 ],\n",
      "       [ 0.16677304, -0.06180792],\n",
      "       [-0.05330173, -0.0306808 ],\n",
      "       [-0.00250135, -0.24221666],\n",
      "       [-0.03818471, -0.02360924],\n",
      "       [-0.18780205,  0.01623914],\n",
      "       [-0.19536415, -0.3287875 ],\n",
      "       [ 0.2583105 , -0.02538333],\n",
      "       [-0.09300172, -0.03287093],\n",
      "       [ 0.07636674, -0.13826102],\n",
      "       [-0.04944159,  0.02380352],\n",
      "       [ 0.19132032, -0.01842739],\n",
      "       [ 0.2047334 , -0.02734435],\n",
      "       [ 0.11191573, -0.05633363],\n",
      "       [ 0.05262309, -0.06932167],\n",
      "       [-0.00387226,  0.09586014],\n",
      "       [ 0.16565551, -0.04687931],\n",
      "       [ 0.05594395, -0.2234846 ],\n",
      "       [-0.04975588, -0.21517251],\n",
      "       [-0.17182301,  0.12063164],\n",
      "       [-0.11572135,  0.02962304],\n",
      "       [ 0.02967411,  0.0605958 ],\n",
      "       [ 0.06078031, -0.10113074],\n",
      "       [ 0.02581402, -0.18208528],\n",
      "       [-0.11077761, -0.07979369],\n",
      "       [-0.0991542 ,  0.08989142],\n",
      "       [-0.21603975, -0.07861938],\n",
      "       [ 0.04433536,  0.07733671],\n",
      "       [-0.00118436,  0.1371273 ]], dtype=float32)>>)\n"
     ]
    }
   ],
   "source": [
    "class Model(object):\n",
    "#  \"\"\"Model with a dense and a linear layer.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.weights = None\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        if self.weights is None:\n",
    "            size = inputs.shape[1]\n",
    "            # Note that type `tnp.float32` is used for performance.\n",
    "            stddev = tnp.sqrt(size).astype(tnp.float32)\n",
    "            w1 = tnp.random.randn(size, 64).astype(tnp.float32) / stddev\n",
    "            bias = tnp.random.randn(64).astype(tnp.float32)\n",
    "            w2 = tnp.random.randn(64, 2).astype(tnp.float32) / 8\n",
    "            self.weights = (w1, bias, w2)\n",
    "        else:\n",
    "            w1, bias, w2 = self.weights\n",
    "        y = tnp.matmul(inputs, w1) + bias\n",
    "        y = tnp.maximum(y, 0)  # Relu\n",
    "        return tnp.matmul(y, w2)  # Linear projection\n",
    "\n",
    "model = Model()\n",
    "# Create input data and compute predictions.\n",
    "print(model.predict(tnp.ones([2, 32], dtype=tnp.float32)))\n",
    "print(model.weights)\n",
    "\n",
    "def create_batch(batch_size=32):\n",
    "#  \"\"\"Creates a batch of input and labels.\"\"\"\n",
    "    return (tnp.random.randn(batch_size, 32).astype(tnp.float32),tnp.random.randn(batch_size, 2).astype(tnp.float32))\n",
    "\n",
    "def compute_gradients(model, inputs, labels):\n",
    "#  \"\"\"Computes gradients of squared loss between model prediction and labels.\"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        assert model.weights is not None\n",
    "        # Note that `model.weights` need to be explicitly watched since they are not tf.Variables.\n",
    "        tape.watch(model.weights)\n",
    "        # Compute prediction and loss\n",
    "        prediction = model.predict(inputs)\n",
    "        loss = tnp.sum(tnp.square(prediction - labels))\n",
    "        # This call computes the gradient through the computation above.\n",
    "        return tape.gradient(loss, model.weights)\n",
    "\n",
    "inputs, labels = create_batch()  \n",
    "gradients = compute_gradients(model, inputs, labels)  \n",
    "# Verify that gradients are of type ND array.\n",
    "assert isinstance(gradients[0], tnp.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager performance\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(ndarray<<tf.Tensor: shape=(32, 64), dtype=float32, numpy=\n",
       " array([[-3.6878880e-02, -4.2285824e-01, -1.3323547e+01, ...,\n",
       "          1.2142377e+00,  2.3592346e+01, -2.8850470e+00],\n",
       "        [ 2.7767455e-02,  5.7683039e-01, -1.2723574e+01, ...,\n",
       "          5.0739288e+00,  5.1007832e+01, -1.7326290e+01],\n",
       "        [ 1.7343797e-02,  1.0158749e+01,  4.5556396e+01, ...,\n",
       "          2.3112207e+01,  7.2193542e+01, -3.6999718e+01],\n",
       "        ...,\n",
       "        [ 1.0608150e-01,  5.4015174e+00,  3.9306648e+01, ...,\n",
       "          1.0580072e+01, -2.6720156e+01, -2.7604361e+01],\n",
       "        [ 3.4141131e-02, -2.0888191e+01, -7.8890976e+01, ...,\n",
       "         -3.7434006e+01, -1.9936989e+01,  5.6651421e+01],\n",
       "        [-8.4357679e-02, -8.6374035e+00, -9.5639877e+00, ...,\n",
       "         -1.3327133e+01, -4.8845348e+00,  1.1626429e+01]], dtype=float32)>>,\n",
       " ndarray<<tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
       " array([-5.3140894e-02,  9.5286118e+01,  2.8991153e+02,  6.2652893e+00,\n",
       "         1.5762982e+02,  8.3150146e+01,  8.8440315e+01, -3.5871525e+00,\n",
       "         5.7855057e+01,  1.1923872e+02, -6.3895645e+01, -4.0615871e+01,\n",
       "         3.5720490e+01,  1.5682110e+01,  8.1257038e+00, -3.5101391e+01,\n",
       "        -5.8853588e+01, -2.3027906e+01,  8.0656691e+00, -8.4653931e+00,\n",
       "        -3.6686127e+01,  3.5358760e+00, -4.1972668e+01,  7.2481857e+01,\n",
       "         4.0684498e+01, -6.0501728e+01,  1.5450386e+02,  2.4775464e+02,\n",
       "         5.0695957e+01,  9.2224693e+01,  7.0474304e+01, -2.3092997e+01,\n",
       "         8.2362061e+00, -2.8624125e+01, -6.0728842e-01,  1.5808148e+02,\n",
       "         3.1394291e+01,  5.2444906e+00,  2.2566602e-01,  1.6943321e+02,\n",
       "        -6.7042007e+01,  5.1408264e+01,  7.9082112e+00, -2.9896533e+02,\n",
       "         1.2131904e+01, -3.6512211e+01, -1.3205422e-01, -8.5905111e-01,\n",
       "         9.3159080e-01, -4.9806564e+01, -8.0912056e+01,  2.2231169e+01,\n",
       "         1.7811778e+02, -2.0728165e-01,  4.8956075e+00,  1.9111752e+01,\n",
       "         5.2470375e+01,  4.6207348e+01,  2.2852625e+01,  2.5963663e+02,\n",
       "        -5.6281120e+01,  1.8606366e+02,  1.7286806e+02, -3.2474515e+02],\n",
       "       dtype=float32)>>,\n",
       " ndarray<<tf.Tensor: shape=(64, 2), dtype=float32, numpy=\n",
       " array([[-1.6104765e-01,  2.2413889e-01],\n",
       "        [-7.8247418e+02,  3.9310320e+03],\n",
       "        [-3.6771667e+02,  1.3356094e+03],\n",
       "        [-1.3448377e+00,  5.1738396e+01],\n",
       "        [-4.3882135e+02,  2.6396162e+03],\n",
       "        [-8.3524918e+01,  3.9544128e+02],\n",
       "        [-5.1095654e+02,  2.1733713e+03],\n",
       "        [-6.1032764e+01,  5.2479523e+02],\n",
       "        [-6.8757431e+01,  1.4794284e+02],\n",
       "        [-8.6055344e+01,  4.0179752e+02],\n",
       "        [-2.1201358e+02,  1.9459529e+03],\n",
       "        [-2.8244397e+02,  1.3568732e+03],\n",
       "        [-2.2598001e+02,  1.3488864e+03],\n",
       "        [-1.7933145e+02,  3.6807178e+02],\n",
       "        [-2.9867207e+01,  1.5192610e+02],\n",
       "        [-2.6359638e+01,  1.6262920e+02],\n",
       "        [-1.9157727e+02,  1.1003514e+03],\n",
       "        [-1.8113100e+01,  1.2887389e+02],\n",
       "        [-6.0319374e+01,  3.4978333e+02],\n",
       "        [-5.6849255e+02,  3.0383228e+03],\n",
       "        [-4.6564693e+01,  1.0613677e+03],\n",
       "        [-6.3144612e-01,  1.1498164e+01],\n",
       "        [-9.3875771e+01,  3.8019489e+02],\n",
       "        [-1.9896353e+02,  1.0656737e+03],\n",
       "        [-1.1929777e+02,  1.0722388e+03],\n",
       "        [-9.3659149e+01,  4.8508533e+02],\n",
       "        [-4.2847293e+02,  2.1881460e+03],\n",
       "        [-2.1653561e+02,  1.7180422e+03],\n",
       "        [-4.8693890e+02,  2.1296045e+03],\n",
       "        [-1.3478022e+00,  5.1737207e+02],\n",
       "        [-1.8592459e+02,  6.5468506e+02],\n",
       "        [-4.1048846e+02,  1.1218708e+03],\n",
       "        [ 2.1131618e+01,  5.1362434e+01],\n",
       "        [-3.7940254e+01,  1.0378140e+02],\n",
       "        [-2.2368538e+00,  7.6592131e+00],\n",
       "        [-4.9745129e+02,  3.0697383e+03],\n",
       "        [-1.8121403e+01,  3.2320080e+01],\n",
       "        [-2.0706836e+02,  7.2159778e+02],\n",
       "        [-1.7600780e+01,  9.9700363e+01],\n",
       "        [-4.7902124e+02,  1.6616030e+03],\n",
       "        [-1.8430434e+02,  1.4084012e+03],\n",
       "        [-2.4963991e+02,  1.9520612e+03],\n",
       "        [-7.5476639e+01,  2.9740811e+02],\n",
       "        [-2.7891275e+02,  2.1141580e+03],\n",
       "        [-4.4727896e+02,  1.2918486e+03],\n",
       "        [-2.1746909e+02,  2.0172363e+03],\n",
       "        [-8.3092873e+01,  2.6124640e+02],\n",
       "        [ 1.6462424e+00,  1.6220467e+01],\n",
       "        [-7.9845279e-02,  2.2552450e+00],\n",
       "        [-5.3077583e+01,  1.8679047e+02],\n",
       "        [-1.6135168e+01,  4.7391458e+02],\n",
       "        [-3.6901047e+01,  3.7410574e+02],\n",
       "        [-2.1070172e+02,  1.0854731e+03],\n",
       "        [ 3.0128870e+00,  8.9699875e+01],\n",
       "        [ 4.2222847e+01,  2.1382706e+02],\n",
       "        [ 6.6025896e+00,  1.2753029e+02],\n",
       "        [-6.5068005e+02,  2.0554216e+03],\n",
       "        [-3.9933266e+01,  3.4022137e+02],\n",
       "        [-1.4555391e+01,  7.0189934e+01],\n",
       "        [-3.1587683e+02,  1.4191521e+03],\n",
       "        [-4.4073387e+01,  1.1991985e+02],\n",
       "        [-3.8872211e+02,  2.7945293e+03],\n",
       "        [-5.9124634e+01,  4.7064813e+02],\n",
       "        [-2.7057812e+02,  1.6575486e+03]], dtype=float32)>>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1474899999921035 ms\n",
      "\n",
      "tf.function compiled performance\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ndarray<<tf.Tensor: shape=(32, 64), dtype=float32, numpy=\n",
       " array([[-3.6878880e-02, -4.2285824e-01, -1.3323547e+01, ...,\n",
       "          1.2142377e+00,  2.3592346e+01, -2.8850470e+00],\n",
       "        [ 2.7767455e-02,  5.7683039e-01, -1.2723574e+01, ...,\n",
       "          5.0739288e+00,  5.1007832e+01, -1.7326290e+01],\n",
       "        [ 1.7343797e-02,  1.0158749e+01,  4.5556396e+01, ...,\n",
       "          2.3112207e+01,  7.2193542e+01, -3.6999718e+01],\n",
       "        ...,\n",
       "        [ 1.0608150e-01,  5.4015174e+00,  3.9306648e+01, ...,\n",
       "          1.0580072e+01, -2.6720156e+01, -2.7604361e+01],\n",
       "        [ 3.4141131e-02, -2.0888191e+01, -7.8890976e+01, ...,\n",
       "         -3.7434006e+01, -1.9936989e+01,  5.6651421e+01],\n",
       "        [-8.4357679e-02, -8.6374035e+00, -9.5639877e+00, ...,\n",
       "         -1.3327133e+01, -4.8845348e+00,  1.1626429e+01]], dtype=float32)>>,\n",
       " ndarray<<tf.Tensor: shape=(64,), dtype=float32, numpy=\n",
       " array([-5.3140894e-02,  9.5286118e+01,  2.8991153e+02,  6.2652893e+00,\n",
       "         1.5762982e+02,  8.3150146e+01,  8.8440315e+01, -3.5871525e+00,\n",
       "         5.7855057e+01,  1.1923872e+02, -6.3895645e+01, -4.0615871e+01,\n",
       "         3.5720490e+01,  1.5682110e+01,  8.1257038e+00, -3.5101391e+01,\n",
       "        -5.8853588e+01, -2.3027906e+01,  8.0656691e+00, -8.4653931e+00,\n",
       "        -3.6686127e+01,  3.5358760e+00, -4.1972668e+01,  7.2481857e+01,\n",
       "         4.0684498e+01, -6.0501728e+01,  1.5450386e+02,  2.4775464e+02,\n",
       "         5.0695957e+01,  9.2224693e+01,  7.0474304e+01, -2.3092997e+01,\n",
       "         8.2362061e+00, -2.8624125e+01, -6.0728842e-01,  1.5808148e+02,\n",
       "         3.1394291e+01,  5.2444906e+00,  2.2566602e-01,  1.6943321e+02,\n",
       "        -6.7042007e+01,  5.1408264e+01,  7.9082112e+00, -2.9896533e+02,\n",
       "         1.2131904e+01, -3.6512211e+01, -1.3205422e-01, -8.5905111e-01,\n",
       "         9.3159080e-01, -4.9806564e+01, -8.0912056e+01,  2.2231169e+01,\n",
       "         1.7811778e+02, -2.0728165e-01,  4.8956075e+00,  1.9111752e+01,\n",
       "         5.2470375e+01,  4.6207348e+01,  2.2852625e+01,  2.5963663e+02,\n",
       "        -5.6281120e+01,  1.8606366e+02,  1.7286806e+02, -3.2474515e+02],\n",
       "       dtype=float32)>>,\n",
       " ndarray<<tf.Tensor: shape=(64, 2), dtype=float32, numpy=\n",
       " array([[-1.6104765e-01,  2.2413889e-01],\n",
       "        [-7.8247418e+02,  3.9310320e+03],\n",
       "        [-3.6771667e+02,  1.3356094e+03],\n",
       "        [-1.3448377e+00,  5.1738396e+01],\n",
       "        [-4.3882135e+02,  2.6396162e+03],\n",
       "        [-8.3524918e+01,  3.9544128e+02],\n",
       "        [-5.1095654e+02,  2.1733713e+03],\n",
       "        [-6.1032764e+01,  5.2479523e+02],\n",
       "        [-6.8757431e+01,  1.4794284e+02],\n",
       "        [-8.6055344e+01,  4.0179752e+02],\n",
       "        [-2.1201358e+02,  1.9459529e+03],\n",
       "        [-2.8244397e+02,  1.3568732e+03],\n",
       "        [-2.2598001e+02,  1.3488864e+03],\n",
       "        [-1.7933145e+02,  3.6807178e+02],\n",
       "        [-2.9867207e+01,  1.5192610e+02],\n",
       "        [-2.6359638e+01,  1.6262920e+02],\n",
       "        [-1.9157727e+02,  1.1003514e+03],\n",
       "        [-1.8113100e+01,  1.2887389e+02],\n",
       "        [-6.0319374e+01,  3.4978333e+02],\n",
       "        [-5.6849255e+02,  3.0383228e+03],\n",
       "        [-4.6564693e+01,  1.0613677e+03],\n",
       "        [-6.3144612e-01,  1.1498164e+01],\n",
       "        [-9.3875771e+01,  3.8019489e+02],\n",
       "        [-1.9896353e+02,  1.0656737e+03],\n",
       "        [-1.1929777e+02,  1.0722388e+03],\n",
       "        [-9.3659149e+01,  4.8508533e+02],\n",
       "        [-4.2847293e+02,  2.1881460e+03],\n",
       "        [-2.1653561e+02,  1.7180422e+03],\n",
       "        [-4.8693890e+02,  2.1296045e+03],\n",
       "        [-1.3478022e+00,  5.1737207e+02],\n",
       "        [-1.8592459e+02,  6.5468506e+02],\n",
       "        [-4.1048846e+02,  1.1218708e+03],\n",
       "        [ 2.1131618e+01,  5.1362434e+01],\n",
       "        [-3.7940254e+01,  1.0378140e+02],\n",
       "        [-2.2368538e+00,  7.6592131e+00],\n",
       "        [-4.9745129e+02,  3.0697383e+03],\n",
       "        [-1.8121403e+01,  3.2320080e+01],\n",
       "        [-2.0706836e+02,  7.2159778e+02],\n",
       "        [-1.7600780e+01,  9.9700363e+01],\n",
       "        [-4.7902124e+02,  1.6616030e+03],\n",
       "        [-1.8430434e+02,  1.4084012e+03],\n",
       "        [-2.4963991e+02,  1.9520612e+03],\n",
       "        [-7.5476639e+01,  2.9740811e+02],\n",
       "        [-2.7891275e+02,  2.1141580e+03],\n",
       "        [-4.4727896e+02,  1.2918486e+03],\n",
       "        [-2.1746909e+02,  2.0172363e+03],\n",
       "        [-8.3092873e+01,  2.6124640e+02],\n",
       "        [ 1.6462424e+00,  1.6220467e+01],\n",
       "        [-7.9845279e-02,  2.2552450e+00],\n",
       "        [-5.3077583e+01,  1.8679047e+02],\n",
       "        [-1.6135168e+01,  4.7391458e+02],\n",
       "        [-3.6901047e+01,  3.7410574e+02],\n",
       "        [-2.1070172e+02,  1.0854731e+03],\n",
       "        [ 3.0128870e+00,  8.9699875e+01],\n",
       "        [ 4.2222847e+01,  2.1382706e+02],\n",
       "        [ 6.6025896e+00,  1.2753029e+02],\n",
       "        [-6.5068005e+02,  2.0554216e+03],\n",
       "        [-3.9933266e+01,  3.4022137e+02],\n",
       "        [-1.4555391e+01,  7.0189934e+01],\n",
       "        [-3.1587683e+02,  1.4191521e+03],\n",
       "        [-4.4073387e+01,  1.1991985e+02],\n",
       "        [-3.8872211e+02,  2.7945293e+03],\n",
       "        [-5.9124634e+01,  4.7064813e+02],\n",
       "        [-2.7057812e+02,  1.6575486e+03]], dtype=float32)>>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6182999999946333 ms\n"
     ]
    }
   ],
   "source": [
    "inputs, labels = create_batch(512)\n",
    "print(\"Eager performance\")\n",
    "compute_gradients(model, inputs, labels)\n",
    "print(timeit.timeit(lambda: compute_gradients(model, inputs, labels),\n",
    "                    number=10)* 100, \"ms\")\n",
    "\n",
    "print(\"\\ntf.function compiled performance\")\n",
    "compiled_compute_gradients = tf.function(compute_gradients)\n",
    "compiled_compute_gradients(model, inputs, labels)  # warmup\n",
    "print(timeit.timeit(lambda: compiled_compute_gradients(model, inputs, labels),\n",
    "                    number=10) * 100, \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight shape: (32, 64), batch size: 128, per example gradient shape: (128, 32, 64) \n",
      "Weight shape: (64,), batch size: 128, per example gradient shape: (128, 64) \n",
      "Weight shape: (64, 2), batch size: 128, per example gradient shape: (128, 64, 2) \n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def vectorized_per_example_gradients(inputs, labels):\n",
    "  def single_example_gradient(arg):\n",
    "    inp, label = arg\n",
    "    return compute_gradients(model,\n",
    "                             tnp.expand_dims(inp, 0),\n",
    "                             tnp.expand_dims(label, 0))\n",
    "  # Note that a call to `tf.vectorized_map` semantically maps\n",
    "  # `single_example_gradient` over each row of `inputs` and `labels`.\n",
    "  # The interface is similar to `tf.map_fn`.\n",
    "  # The underlying machinery vectorizes away this map loop which gives\n",
    "  # nice speedups.\n",
    "  return tf.vectorized_map(single_example_gradient, (inputs, labels))\n",
    "\n",
    "batch_size = 128\n",
    "inputs, labels = create_batch(batch_size)\n",
    "\n",
    "per_example_gradients = vectorized_per_example_gradients(inputs, labels)\n",
    "for w, p in zip(model.weights, per_example_gradients):\n",
    "  print(\"Weight shape: %s, batch size: %s, per example gradient shape: %s \" % (\n",
    "      w.shape, batch_size, p.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All logical devices: [LogicalDevice(name='/device:CPU:0', device_type='CPU')]\n",
      "All physical devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"All logical devices:\", tf.config.list_logical_devices())\n",
    "print(\"All physical devices:\", tf.config.list_physical_devices())\n",
    "\n",
    "# Try to get the GPU device. If unavailable, fallback to CPU.\n",
    "try:\n",
    "  device = tf.config.list_logical_devices(device_type=\"GPU\")[0]\n",
    "except IndexError:\n",
    "  device = \"/device:CPU:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: /device:CPU:0\n",
      "prediction is placed on /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "print(\"Using device: %s\" % str(device))\n",
    "# Run operations in the `tf.device` scope.\n",
    "# If a GPU is available, these operations execute on the GPU and outputs are\n",
    "# placed on the GPU memory.\n",
    "with tf.device(device):\n",
    "  prediction = model.predict(create_batch(5)[0])\n",
    "\n",
    "print(\"prediction is placed on %s\" % prediction.data.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/job:localhost/replica:0/task:0/device:CPU:0\n",
      "/job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/device:CPU:0\"):\n",
    "  prediction_cpu = tnp.copy(prediction)\n",
    "print(prediction.data.device)\n",
    "print(prediction_cpu.data.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
