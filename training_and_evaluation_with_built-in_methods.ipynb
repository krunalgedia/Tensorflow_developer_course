{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow version 2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "import timeit\n",
    "from datetime import datetime\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "print(\"Using TensorFlow version %s\" % tf.__version__)\n",
    "#import tensorflow.experimental.numpy as tnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model training and evaluation is same for any keras models-> Sequential, Functional APIs, subclassing models\n",
    "#Input can be NumPy, tf.Numpy, eager tensors, tf.data.Datasets, pd.dataframe, python generators yielding batch of data and label\n",
    "# Input data: Small & fits in memory-> NumPy arrays \n",
    "#             Large & distributed training needed -> tf.data Dataset objects\n",
    "#             Large & lot of custom python modules needed for data preprocessing -> keras.utils.Sequence\n",
    "\n",
    "# Training -> optimizers, losses, metrics\n",
    "\n",
    "# Consider following Functional end-to-end MNIST dataset loaded as NumPy ararys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/2\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.3424 - sparse_categorical_accuracy: 0.9028 - val_loss: 0.3438 - val_sparse_categorical_accuracy: 0.8922\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.1708 - sparse_categorical_accuracy: 0.9493 - val_loss: 0.1515 - val_sparse_categorical_accuracy: 0.9583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.34237003326416016, 0.1707540601491928],\n",
       " 'sparse_categorical_accuracy': [0.9028000235557556, 0.9493399858474731],\n",
       " 'val_loss': [0.34384363889694214, 0.15149162709712982],\n",
       " 'val_sparse_categorical_accuracy': [0.8921999931335449, 0.958299994468689]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1565 - sparse_categorical_accuracy: 0.9518\n",
      "test loss, test acc: [0.15645146369934082, 0.9517999887466431]\n",
      "Generate predictions for 3 samples\n",
      "predictions shape: (3, 10)\n"
     ]
    }
   ],
   "source": [
    "# end to end example\n",
    "# Functional Model\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Load data and pre-process\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocess the data (these are NumPy arrays)\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")\n",
    "\n",
    "# Reserve 10,000 samples for validation\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]\n",
    "\n",
    "# Training configuration\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "# fit -> train model by slicing train set into 'batches' of 'batch_size' and iterate over the entire dataset for given 'epochs'\n",
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=2,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(x_val, y_val),\n",
    ")\n",
    "\n",
    "# loss value and metric values during training\n",
    "history.history \n",
    "\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 3 samples\")\n",
    "predictions = model.predict(x_test[:3])\n",
    "print(\"predictions shape:\", predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile()\n",
    "# loss function, optimizer and metric(in list format)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "# some string identfiers also exists:\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiled and uncomplied model functions for later usage:\n",
    "def get_uncompiled_model():\n",
    "    inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "    x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "    x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_compiled_model():\n",
    "    model = get_uncompiled_model()\n",
    "    model.compile(\n",
    "        optimizer=\"rmsprop\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"sparse_categorical_accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 0.0161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x236dfd36160>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 0.0385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x236e015f2e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "  1/782 [..............................] - ETA: 0s - loss: 2.2851 - categorical_true_positives: 9.0000WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_begin` time: 0.0051s). Check your callbacks.\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3406 - categorical_true_positives: 45094.0000\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.1581 - categorical_true_positives: 47645.0000\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.1169 - categorical_true_positives: 48211.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x236e0665940>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Custom losses -> Two ways depending how you calculate loss:\n",
    "# 1. If only y_pred and y_true reguired -> function method\n",
    "# 2. If any extra parameter need other than y_{true,pred} -> function by sub-classing\n",
    "\n",
    "# example for 1.\n",
    "def custom_mean_squared_error(y_true, y_pred):\n",
    "    return tf.math.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "model = get_uncompiled_model()\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=custom_mean_squared_error)\n",
    "\n",
    "# We need to one-hot encode the labels to use MSE\n",
    "y_train_one_hot = tf.one_hot(y_train, depth=10)\n",
    "model.fit(x_train, y_train_one_hot, batch_size=64, epochs=1)\n",
    "\n",
    "# Example for 2. Subclassing tf.keras.Loss requires __init__ and call:\n",
    "class CustomMSE(keras.losses.Loss):\n",
    "    def __init__(self, regularization_factor=0.1, name=\"custom_mse\"):\n",
    "        super().__init__(name=name)\n",
    "        self.regularization_factor = regularization_factor\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        mse = tf.math.reduce_mean(tf.square(y_true - y_pred))\n",
    "        reg = tf.math.reduce_mean(tf.square(0.5 - y_pred))\n",
    "        return mse + reg * self.regularization_factor\n",
    "\n",
    "\n",
    "model = get_uncompiled_model()\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=CustomMSE())\n",
    "\n",
    "y_train_one_hot = tf.one_hot(y_train, depth=10)\n",
    "model.fit(x_train, y_train_one_hot, batch_size=64, epochs=1)\n",
    "\n",
    "# Custom metrics\n",
    "# Subclassing tf.keras.metrics.Metric class with __init__, update_state, result, reset_states\n",
    "# following metric computes number of gtrue positives\n",
    "\n",
    "class CategoricalTruePositives(keras.metrics.Metric):\n",
    "    def __init__(self, name=\"categorical_true_positives\", **kwargs):\n",
    "        super(CategoricalTruePositives, self).__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name=\"ctp\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.reshape(tf.argmax(y_pred, axis=1), shape=(-1, 1))\n",
    "        values = tf.cast(y_true, \"int32\") == tf.cast(y_pred, \"int32\")\n",
    "        values = tf.cast(values, \"float32\")\n",
    "        if sample_weight is not None:\n",
    "            sample_weight = tf.cast(sample_weight, \"float32\")\n",
    "            values = tf.multiply(values, sample_weight)\n",
    "        self.true_positives.assign_add(tf.reduce_sum(values))\n",
    "\n",
    "    def result(self):\n",
    "        return self.true_positives\n",
    "\n",
    "    def reset_states(self):\n",
    "        # The state of the metric will be reset at the start of each epoch.\n",
    "        self.true_positives.assign(0.0)\n",
    "\n",
    "\n",
    "model = get_uncompiled_model()\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[CategoricalTruePositives()],\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 2.5176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x236e09d5580>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3385 - std_of_activation: 1.0215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x236e0d21550>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 2.5052 - std_of_activation: 0.0020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x236dffed940>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add_loss and add_metric -> define them in a sub-class layer and add the layer while building model or add them in the end on the complete model\n",
    "\n",
    "# losses and metrics which require non-standard signature\n",
    "# Eg: loss from activation layer instead of output y_pred! \n",
    "# activity regularization loss example (built-in do exist):\n",
    "# Method 1\n",
    "class ActivityRegularizationLayer(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        self.add_loss(tf.reduce_sum(inputs) * 0.1)\n",
    "        return inputs  # Pass-through layer.\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "\n",
    "# Insert activity regularization as a layer\n",
    "x = ActivityRegularizationLayer()(x)\n",
    "\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "# The displayed loss will be much higher than before\n",
    "# due to the regularization component.\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1)\n",
    "\n",
    "# add_metric:\n",
    "class MetricLoggingLayer(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        # The `aggregation` argument defines\n",
    "        # how to aggregate the per-batch values\n",
    "        # over each epoch:\n",
    "        # in this case we simply average them.\n",
    "        self.add_metric(\n",
    "            keras.backend.std(inputs), name=\"std_of_activation\", aggregation=\"mean\"\n",
    "        )\n",
    "        return inputs  # Pass-through layer.\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "\n",
    "# Insert std logging as a layer.\n",
    "x = MetricLoggingLayer()(x)\n",
    "\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1)\n",
    "\n",
    "# Method 2\n",
    "# However, in functional API, easier way to implement this is:\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x1 = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x2 = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x1)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x2)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.add_loss(tf.reduce_sum(x1) * 0.1)\n",
    "\n",
    "model.add_metric(keras.backend.std(x1), name=\"std_of_activation\", aggregation=\"mean\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0913 - binary_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x236e0ea61c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consider a last layer which has metric and loss function in it. It takes logits and target as input \n",
    "\n",
    "class LogisticEndpoint(keras.layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super(LogisticEndpoint, self).__init__(name=name)\n",
    "        self.loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        self.accuracy_fn = keras.metrics.BinaryAccuracy()\n",
    "\n",
    "    def call(self, targets, logits, sample_weights=None):\n",
    "        # Compute the training-time loss value and add it\n",
    "        # to the layer using `self.add_loss()`.\n",
    "        loss = self.loss_fn(targets, logits, sample_weights)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        # Log accuracy as a metric and add it\n",
    "        # to the layer using `self.add_metric()`.\n",
    "        acc = self.accuracy_fn(targets, logits, sample_weights)\n",
    "        self.add_metric(acc, name=\"accuracy\")\n",
    "\n",
    "        # Return the inference-time prediction tensor (for `.predict()`).\n",
    "        return tf.nn.softmax(logits)\n",
    "    \n",
    "import numpy as np\n",
    "\n",
    "inputs = keras.Input(shape=(3,), name=\"inputs\")\n",
    "targets = keras.Input(shape=(10,), name=\"targets\")\n",
    "logits = keras.layers.Dense(10)(inputs)\n",
    "# Next us\n",
    "predictions = LogisticEndpoint(name=\"predictions\")(logits, targets)\n",
    "\n",
    "model = keras.Model(inputs=[inputs, targets], outputs=predictions)\n",
    "model.compile(optimizer=\"adam\")  # No loss argument!\n",
    "\n",
    "data = {\n",
    "    \"inputs\": np.random.random((3, 3)),\n",
    "    \"targets\": np.random.random((3, 10)),\n",
    "}\n",
    "model.fit(data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 2s 3ms/step - loss: 0.3722 - sparse_categorical_accuracy: 0.8943 - val_loss: 0.2492 - val_sparse_categorical_accuracy: 0.9245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x236e116a7c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you use NumPy, you can use validation_split, else validation data option always available\n",
    "model = get_compiled_model()\n",
    "model.fit(x_train, y_train, batch_size=64, validation_split=0.2, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "771/782 [============================>.] - ETA: 0s - loss: 0.3441 - sparse_categorical_accuracy: 0.9023WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0081s). Check your callbacks.\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 0.3425 - sparse_categorical_accuracy: 0.9027 - val_loss: 0.2065 - val_sparse_categorical_accuracy: 0.9418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x236e24ae820>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.2147 - sparse_categorical_accuracy: 0.9337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.21471908688545227,\n",
       " 'sparse_categorical_accuracy': 0.9337000250816345}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.8293 - sparse_categorical_accuracy: 0.7909\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3830 - sparse_categorical_accuracy: 0.8922\n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.3095 - sparse_categorical_accuracy: 0.9075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x236dffeb430>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.data API\n",
    "# Using tf.data.Dataset objects data\n",
    "model = get_compiled_model()\n",
    "\n",
    "# First, let's create a training Dataset instance.\n",
    "# For the sake of our example, we'll use the same MNIST data as before.\n",
    "# NumPy to tf.data.Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "# Shuffle and slice the dataset. datasets keeps getting reset at the end of epoch\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Prepare the validation dataset\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(64)\n",
    "\n",
    "# Now we get a test dataset.\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.batch(64)\n",
    "\n",
    "# Since the dataset already takes care of batching,\n",
    "# we don't pass a `batch_size` argument.\n",
    "#model.fit(train_dataset, epochs=3)\n",
    "model.fit(train_dataset, epochs=1, validation_data=val_dataset)\n",
    "# validation_steps=10 can be used but not validation_split for tf.data.Dataset\n",
    "\n",
    "# You can also evaluate or predict on a dataset.\n",
    "print(\"Evaluate\")\n",
    "result = model.evaluate(test_dataset)\n",
    "dict(zip(model.metrics_names, result))\n",
    "\n",
    "### Use only 100 batches per epoch -> steps_per_epoch\n",
    "model = get_compiled_model()\n",
    "\n",
    "# Prepare the training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Only use the 100 batches per epoch (that's 64 * 100 samples)\n",
    "model.fit(train_dataset, epochs=3, steps_per_epoch=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filenames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-25bcfd32fba5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m                for filename in batch_x]), np.array(batch_y)\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0msequence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCIFAR10Sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filenames' is not defined"
     ]
    }
   ],
   "source": [
    "# keras.utils.Sequence object as input -> multiprocessing and shuffle!\n",
    "# subclass it to get python generator with '__getitem__' and '__len__'\n",
    "# __getitem__ should return complete batch\n",
    "# if you want to modify data in between, implement on_epoch_end\n",
    "# example: \n",
    "# Here, `filenames` is list of path to the images\n",
    "# and `labels` are the associated labels.\n",
    "\n",
    "class CIFAR10Sequence(tf.keras.utils.Sequence):\n",
    "    def __init__(self, filenames, labels, batch_size):\n",
    "        self.filenames, self.labels = filenames, labels\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.filenames) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return np.array([\n",
    "            resize(imread(filename), (200, 200))\n",
    "               for filename in batch_x]), np.array(batch_y)\n",
    "\n",
    "sequence = CIFAR10Sequence(filenames, labels, batch_size)\n",
    "model.fit(sequence, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit with class weight\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.3678 - sparse_categorical_accuracy: 0.9037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x236810e9430>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit with sample weight\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.3657 - sparse_categorical_accuracy: 0.9040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2368243cbb0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 3s 3ms/step - loss: 0.3634 - sparse_categorical_accuracy: 0.9040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2368278ac40>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample weights and class weights in model.fit(..class_weight={0:0.5})\n",
    "#---------------------------------\n",
    "\n",
    "# Need of class weights: give more imp, no need for balancing classes without respampling\n",
    "# NumPy example of class weights:\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class_weight = {\n",
    "    0: 1.0,\n",
    "    1: 1.0,\n",
    "    2: 1.0,\n",
    "    3: 1.0,\n",
    "    4: 1.0,\n",
    "    # Set weight \"2\" for class \"5\",\n",
    "    # making this class 2x more important\n",
    "    5: 2.0,\n",
    "    6: 1.0,\n",
    "    7: 1.0,\n",
    "    8: 1.0,\n",
    "    9: 1.0,\n",
    "}\n",
    "\n",
    "print(\"Fit with class weight\")\n",
    "model = get_compiled_model()\n",
    "model.fit(x_train, y_train, class_weight=class_weight, batch_size=64, epochs=1)\n",
    "\n",
    "#---------------------------------\n",
    "\n",
    "# Sample weights (array of numbers on how much weight each sample gets)\n",
    "# NumPy data -> Model.fit(sample_weight)\n",
    "# tf.data or any other iterator -> yield (input_batch, label_batch, sample_weights)\n",
    "\n",
    "# Use: class imbalance, masking particular samples or classes in loss!\n",
    "\n",
    "# NumPy input example:\n",
    "sample_weight = np.ones(shape=(len(y_train),))\n",
    "sample_weight[y_train == 5] = 2.0\n",
    "\n",
    "print(\"Fit with sample weight\")\n",
    "model = get_compiled_model()\n",
    "model.fit(x_train, y_train, sample_weight=sample_weight, batch_size=64, epochs=1)\n",
    "\n",
    "# tf.data.Dataset example:\n",
    "sample_weight = np.ones(shape=(len(y_train),))\n",
    "sample_weight[y_train == 5] = 2.0\n",
    "\n",
    "# Create a Dataset that includes sample weights\n",
    "# (3rd element in the return tuple).\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train, sample_weight))\n",
    "\n",
    "# Shuffle and slice the dataset.\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "model = get_compiled_model()\n",
    "model.fit(train_dataset, epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 19.3151 - score_output_loss: 1.5346 - class_output_loss: 17.7805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x236e258fdf0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 18.6697 - score_output_loss: 0.9466 - class_output_loss: 17.7231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x236840c54f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multi-input multi-output end-to-end example\n",
    "# single input (764,) and single output example seen (10,)\n",
    "# what if input is image (32,32,3) and timeseries steps (None, 10)..None=timesteps 10=features\n",
    "# and output is score (1,) and probability distribution over 5 classes (5,)\n",
    "\n",
    "#---------------------------------\n",
    "image_input = keras.Input(shape=(32, 32, 3), name=\"img_input\")\n",
    "timeseries_input = keras.Input(shape=(None, 10), name=\"ts_input\")\n",
    "\n",
    "x1 = layers.Conv2D(3, 3)(image_input)\n",
    "x1 = layers.GlobalMaxPooling2D()(x1)\n",
    "\n",
    "x2 = layers.Conv1D(3, 3)(timeseries_input)\n",
    "x2 = layers.GlobalMaxPooling1D()(x2)\n",
    "\n",
    "x = layers.concatenate([x1, x2])\n",
    "\n",
    "score_output = layers.Dense(1, name=\"score_output\")(x)\n",
    "class_output = layers.Dense(5, name=\"class_output\")(x)\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs=[image_input, timeseries_input], outputs=[score_output, class_output]\n",
    ")\n",
    "keras.utils.plot_model(model, \"multi_input_and_output_model.png\", show_shapes=True)\n",
    "\n",
    "#---------------------------------\n",
    "# List Version\n",
    "#model.compile(\n",
    "#    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "#    loss=[keras.losses.MeanSquaredError(), keras.losses.CategoricalCrossentropy()],\n",
    "#    metrics=[\n",
    "#        [\n",
    "#            keras.metrics.MeanAbsolutePercentageError(),\n",
    "#            keras.metrics.MeanAbsoluteError(),\n",
    "#        ],\n",
    "#        [keras.metrics.CategoricalAccuracy()],\n",
    "#    ],\n",
    "#)\n",
    "\n",
    "# Dict version!\n",
    "# better way since we gave names to output layer\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss={\n",
    "        \"score_output\": keras.losses.MeanSquaredError(),\n",
    "        \"class_output\": keras.losses.CategoricalCrossentropy(),\n",
    "    },\n",
    "    metrics={\n",
    "        \"score_output\": [\n",
    "            keras.metrics.MeanAbsolutePercentageError(),\n",
    "            keras.metrics.MeanAbsoluteError(),\n",
    "        ],\n",
    "        \"class_output\": [keras.metrics.CategoricalAccuracy()],\n",
    "    },\n",
    "    # GIVING weights to different losses in total loss!!\n",
    "    loss_weights={\"score_output\": 2.0, \"class_output\": 1.0},\n",
    ")\n",
    "\n",
    "#---------------------------------\n",
    "# If you don't want to train some particular output node:\n",
    "\n",
    "# List loss version\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=[None, keras.losses.CategoricalCrossentropy()],\n",
    ")\n",
    "\n",
    "# Or dict loss version\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss={\"class_output\": keras.losses.CategoricalCrossentropy()},\n",
    ")\n",
    "\n",
    "#--------------------------------\n",
    "# Passing data either as dict names as named in the layers or as list\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=[keras.losses.MeanSquaredError(), keras.losses.CategoricalCrossentropy()],\n",
    ")\n",
    "\n",
    "# Generate dummy NumPy data\n",
    "img_data = np.random.random_sample(size=(100, 32, 32, 3))\n",
    "ts_data = np.random.random_sample(size=(100, 20, 10))\n",
    "score_targets = np.random.random_sample(size=(100, 1))\n",
    "class_targets = np.random.random_sample(size=(100, 5))\n",
    "\n",
    "# Fit on lists\n",
    "model.fit([img_data, ts_data], [score_targets, class_targets], batch_size=32, epochs=1)\n",
    "\n",
    "# Alternatively, fit on dicts\n",
    "model.fit(\n",
    "    {\"img_input\": img_data, \"ts_input\": ts_data},\n",
    "    {\"score_output\": score_targets, \"class_output\": class_targets},\n",
    "    batch_size=32,\n",
    "    epochs=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.3814 - sparse_categorical_accuracy: 0.8923 - val_loss: 0.2377 - val_sparse_categorical_accuracy: 0.9295\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.1814 - sparse_categorical_accuracy: 0.9459 - val_loss: 0.1880 - val_sparse_categorical_accuracy: 0.9427\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.1297 - sparse_categorical_accuracy: 0.9608 - val_loss: 0.1606 - val_sparse_categorical_accuracy: 0.9513\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.0997 - sparse_categorical_accuracy: 0.9706 - val_loss: 0.1626 - val_sparse_categorical_accuracy: 0.9521\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.0834 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1422 - val_sparse_categorical_accuracy: 0.9570\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.0705 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.1526 - val_sparse_categorical_accuracy: 0.9567\n",
      "Epoch 7/20\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.0607 - sparse_categorical_accuracy: 0.9814 - val_loss: 0.1441 - val_sparse_categorical_accuracy: 0.9608\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x236854faa00>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "623/625 [============================>.] - ETA: 0s - loss: 0.3769 - sparse_categorical_accuracy: 0.8940\n",
      "Epoch 00001: val_loss improved from inf to 0.26152, saving model to mymodel_1\n",
      "WARNING:tensorflow:From c:\\users\\kbged\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From c:\\users\\kbged\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: mymodel_1\\assets\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 0.3767 - sparse_categorical_accuracy: 0.8940 - val_loss: 0.2615 - val_sparse_categorical_accuracy: 0.9239\n",
      "Epoch 2/2\n",
      "608/625 [============================>.] - ETA: 0s - loss: 0.1838 - sparse_categorical_accuracy: 0.9460\n",
      "Epoch 00002: val_loss improved from 0.26152 to 0.19222, saving model to mymodel_2\n",
      "INFO:tensorflow:Assets written to: mymodel_2\\assets\n",
      "625/625 [==============================] - 5s 7ms/step - loss: 0.1830 - sparse_categorical_accuracy: 0.9463 - val_loss: 0.1922 - val_sparse_categorical_accuracy: 0.9413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23685940370>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring from ./ckpt/ckpt-loss=0.31\n",
      "  87/1563 [>.............................] - ETA: 3s - loss: 0.1677 - sparse_categorical_accuracy: 0.9461INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.17\\assets\n",
      " 196/1563 [==>...........................] - ETA: 19s - loss: 0.1711 - sparse_categorical_accuracy: 0.9474INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.17\\assets\n",
      " 291/1563 [====>.........................] - ETA: 24s - loss: 0.1778 - sparse_categorical_accuracy: 0.9462INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.18\\assets\n",
      " 388/1563 [======>.......................] - ETA: 23s - loss: 0.1730 - sparse_categorical_accuracy: 0.9477INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.17\\assets\n",
      " 485/1563 [========>.....................] - ETA: 22s - loss: 0.1699 - sparse_categorical_accuracy: 0.9492INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.17\\assets\n",
      " 597/1563 [==========>...................] - ETA: 19s - loss: 0.1673 - sparse_categorical_accuracy: 0.9501INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.17\\assets\n",
      " 683/1563 [============>.................] - ETA: 18s - loss: 0.1659 - sparse_categorical_accuracy: 0.9506INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.16\\assets\n",
      " 788/1563 [==============>...............] - ETA: 16s - loss: 0.1623 - sparse_categorical_accuracy: 0.9517INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.16\\assets\n",
      " 889/1563 [================>.............] - ETA: 14s - loss: 0.1600 - sparse_categorical_accuracy: 0.9523INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.16\\assets\n",
      " 988/1563 [=================>............] - ETA: 12s - loss: 0.1568 - sparse_categorical_accuracy: 0.9533INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.16\\assets\n",
      "1087/1563 [===================>..........] - ETA: 10s - loss: 0.1564 - sparse_categorical_accuracy: 0.9535INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.16\\assets\n",
      "1191/1563 [=====================>........] - ETA: 8s - loss: 0.1528 - sparse_categorical_accuracy: 0.9548INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.15\\assets\n",
      "1299/1563 [=======================>......] - ETA: 6s - loss: 0.1521 - sparse_categorical_accuracy: 0.9549INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.15\\assets\n",
      "1382/1563 [=========================>....] - ETA: 4s - loss: 0.1506 - sparse_categorical_accuracy: 0.9556INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.15\\assets\n",
      "1486/1563 [===========================>..] - ETA: 1s - loss: 0.1488 - sparse_categorical_accuracy: 0.9559INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.15\\assets\n",
      "1563/1563 [==============================] - 38s 24ms/step - loss: 0.1482 - sparse_categorical_accuracy: 0.9561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x236824d87c0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Callbacks: Objects that are called at different points during training (start of epoch, end of batch, end of epoch)\n",
    "# Need: validation at different points, checkpoint at some threshold crossing, changing learing rates in between, fine-tune layers in between, e=send email when done!!\n",
    "# send it in Model.fit()\n",
    "\n",
    "#-------------------------\n",
    "# eg: EarlyStopping\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        # Stop training when `val_loss` is no longer improving\n",
    "        monitor=\"val_loss\",\n",
    "        # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
    "        min_delta=1e-2,\n",
    "        # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n",
    "        patience=2,\n",
    "        verbose=1,\n",
    "    )\n",
    "]\n",
    "model = get_compiled_model()\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "\n",
    "#---------------\n",
    "# eg: checkpoint model when some metric improves\n",
    "\n",
    "model = get_compiled_model()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        # The saved model name will include the current epoch.\n",
    "        filepath=\"mymodel_{epoch}\",\n",
    "        save_best_only=True,  # Only save a model if `val_loss` has improved.\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=1,\n",
    "    )\n",
    "]\n",
    "model.fit(\n",
    "    x_train, y_train, epochs=2, batch_size=64, callbacks=callbacks, validation_split=0.2\n",
    ")\n",
    "\n",
    "#----------------------------------------\n",
    "# eg: checkpoint for fault-tolerance i.e restart if training stopped mid-way\n",
    "import os\n",
    "\n",
    "# Prepare a directory to store all the checkpoints.\n",
    "checkpoint_dir = \"./ckpt\"\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "\n",
    "def make_or_restore_model():\n",
    "    # Either restore the latest model, or create a fresh one\n",
    "    # if there is no checkpoint available.\n",
    "    checkpoints = [checkpoint_dir + \"/\" + name for name in os.listdir(checkpoint_dir)]\n",
    "    if checkpoints:\n",
    "        latest_checkpoint = max(checkpoints, key=os.path.getctime)\n",
    "        print(\"Restoring from\", latest_checkpoint)\n",
    "        return keras.models.load_model(latest_checkpoint)\n",
    "    print(\"Creating a new model\")\n",
    "    return get_compiled_model()\n",
    "\n",
    "\n",
    "model = make_or_restore_model()\n",
    "callbacks = [\n",
    "    # This callback saves a SavedModel every 100 batches.\n",
    "    # We include the training loss in the saved model name.\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_dir + \"/ckpt-loss={loss:.2f}\", save_freq=100\n",
    "    )\n",
    "]\n",
    "model.fit(x_train, y_train, epochs=1, callbacks=callbacks)\n",
    "\n",
    "\n",
    "#--------------------\n",
    "# eg: writing your own callback for saving a list of per-batch loss values\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------\n",
    "# Learning rates -> Static (scheduler method)and dynamic (callback method)\n",
    "# static decay : Pass schedule to an optimizer\n",
    "initial_learning_rate = 0.1\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=lr_schedule)\n",
    "\n",
    "# dynamic decay: implement call back (ReduceLROnPlateau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.TensorBoard at 0x23681250a00>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  43/1563 [..............................] - ETA: 3s - loss: 0.0581 - sparse_categorical_accuracy: 0.9826INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.06\\assets\n",
      " 122/1563 [=>............................] - ETA: 24s - loss: 0.0633 - sparse_categorical_accuracy: 0.9826INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.07\\assets\n",
      " 239/1563 [===>..........................] - ETA: 25s - loss: 0.0600 - sparse_categorical_accuracy: 0.9831INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.06\\assets\n",
      " 334/1563 [=====>........................] - ETA: 25s - loss: 0.0598 - sparse_categorical_accuracy: 0.9830INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.06\\assets\n",
      " 439/1563 [=======>......................] - ETA: 24s - loss: 0.0575 - sparse_categorical_accuracy: 0.9837INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.06\\assets\n",
      " 527/1563 [=========>....................] - ETA: 23s - loss: 0.0585 - sparse_categorical_accuracy: 0.9832INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.06\\assets\n",
      " 646/1563 [===========>..................] - ETA: 20s - loss: 0.0614 - sparse_categorical_accuracy: 0.9821INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.06\\assets\n",
      " 730/1563 [=============>................] - ETA: 18s - loss: 0.0621 - sparse_categorical_accuracy: 0.9820INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.06\\assets\n",
      " 847/1563 [===============>..............] - ETA: 17s - loss: 0.0613 - sparse_categorical_accuracy: 0.9824INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.06\\assets\n",
      " 942/1563 [=================>............] - ETA: 16s - loss: 0.0638 - sparse_categorical_accuracy: 0.9814INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.06\\assets\n",
      "1019/1563 [==================>...........] - ETA: 15s - loss: 0.0628 - sparse_categorical_accuracy: 0.9816INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.06\\assets\n",
      "1136/1563 [====================>.........] - ETA: 11s - loss: 0.0638 - sparse_categorical_accuracy: 0.9815INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.06\\assets\n",
      "1230/1563 [======================>.......] - ETA: 9s - loss: 0.0653 - sparse_categorical_accuracy: 0.9812 INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.07\\assets\n",
      "1331/1563 [========================>.....] - ETA: 6s - loss: 0.0660 - sparse_categorical_accuracy: 0.9810INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.07\\assets\n",
      "1440/1563 [==========================>...] - ETA: 3s - loss: 0.0669 - sparse_categorical_accuracy: 0.9807INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.07\\assets\n",
      "1544/1563 [============================>.] - ETA: 0s - loss: 0.0676 - sparse_categorical_accuracy: 0.9808INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.07\\assets\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.0685 - sparse_categorical_accuracy: 0.9806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23686e29fd0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 17644), started 0:23:57 ago. (Use '!kill 17644' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-64ef3958675f7363\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-64ef3958675f7363\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize loss and metric during training\n",
    "# Tensorboard callback:\n",
    "#%tensorboard --logdir logs/func\n",
    "\n",
    "#logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#stamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "stamp = 'test'\n",
    "logdir = \"logs/scalars/%s\" % stamp\n",
    "writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "keras.callbacks.TensorBoard(\n",
    "    log_dir=logdir,\n",
    "    histogram_freq=0,  # How often to log histogram visualizations\n",
    "    embeddings_freq=0,  # How often to log embedding visualizations\n",
    "    update_freq=\"epoch\",\n",
    ")  # How often to write logs (default: once per epoch)\n",
    "model.fit(x_train, y_train, epochs=1, callbacks=callbacks)\n",
    "\n",
    "%tensorboard --logdir logs/scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 14136), started 0:01:19 ago. (Use '!kill 14136' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-263d03cea304fecf\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-263d03cea304fecf\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=\"C:\\Users\\kbged\\Downloads\\tf guide\\logs\\scalars\\test\\events.out.tfevents.1610274084.DESKTOP-5DU3UD3.22204.305376.v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard 2.3.0\n",
      "tensorboard-plugin-wit 1.6.0\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "\n",
    "for entry_point in pkg_resources.iter_entry_points('tensorboard_plugins'):\n",
    "    print(entry_point.dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
