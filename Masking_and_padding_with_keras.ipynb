{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "Using TensorFlow version 2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "import timeit\n",
    "from datetime import datetime\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import array\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "print(\"Using TensorFlow version %s\" % tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 711  632   71    0    0    0]\n",
      " [  73    8 3215   55  927    0]\n",
      " [  83   91    1  645 1253  927]]\n"
     ]
    }
   ],
   "source": [
    "# padding\n",
    "raw_inputs = [\n",
    "    [711, 632, 71],\n",
    "    [73, 8, 3215, 55, 927],\n",
    "    [83, 91, 1, 645, 1253, 927],\n",
    "]\n",
    "\n",
    "# By default, this will pad using 0s; it is configurable via the\n",
    "# \"value\" parameter.\n",
    "# Note that you could \"pre\" padding (at the beginning) or\n",
    "# \"post\" padding (at the end).\n",
    "# We recommend using \"post\" padding when working with RNN layers\n",
    "# (in order to be able to use the\n",
    "# CuDNN implementation of the layers).\n",
    "padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    raw_inputs, padding=\"post\"\n",
    ")\n",
    "print(padded_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 1.8644333e-03 -4.2547870e-02  3.1563725e-02  4.9641617e-03\n",
      "   -5.5298917e-03 -4.7941137e-02  3.1341378e-02  1.6163591e-02\n",
      "   -2.0095600e-02 -3.2767653e-03  9.6793175e-03  4.6932686e-02\n",
      "    1.7245412e-03  2.6263747e-02 -3.7171770e-02  2.3374334e-03]\n",
      "  [ 1.2230683e-02 -2.4099840e-02 -3.5484720e-02 -1.6741179e-02\n",
      "    1.1204578e-02  6.8305843e-03 -3.5956550e-02 -4.1473173e-02\n",
      "    4.4587795e-02  2.3508668e-03 -2.0592213e-03 -4.9225748e-02\n",
      "    1.0493267e-02 -2.8892606e-04  1.7629776e-02 -2.5625562e-02]\n",
      "  [-3.0196786e-02 -1.5295614e-02  2.7550314e-02  1.6206790e-02\n",
      "   -3.5814047e-02 -1.8701386e-02 -1.8178247e-02 -3.6727883e-02\n",
      "   -2.4148751e-02  1.1653304e-02 -2.4332022e-02  2.6472118e-02\n",
      "    2.9094789e-02 -2.6530469e-02 -4.3845393e-02 -1.9853700e-02]\n",
      "  [ 4.7012497e-02 -5.4558143e-03 -9.2979558e-03 -3.6697555e-02\n",
      "   -4.3919802e-02  1.7334830e-02  2.9253129e-02 -1.9433126e-03\n",
      "   -1.5680861e-02  2.3198929e-02 -1.0682009e-02  4.6916034e-02\n",
      "    4.2791020e-02 -6.0172193e-03  3.7966598e-02  3.4942515e-03]\n",
      "  [ 4.7012497e-02 -5.4558143e-03 -9.2979558e-03 -3.6697555e-02\n",
      "   -4.3919802e-02  1.7334830e-02  2.9253129e-02 -1.9433126e-03\n",
      "   -1.5680861e-02  2.3198929e-02 -1.0682009e-02  4.6916034e-02\n",
      "    4.2791020e-02 -6.0172193e-03  3.7966598e-02  3.4942515e-03]\n",
      "  [ 4.7012497e-02 -5.4558143e-03 -9.2979558e-03 -3.6697555e-02\n",
      "   -4.3919802e-02  1.7334830e-02  2.9253129e-02 -1.9433126e-03\n",
      "   -1.5680861e-02  2.3198929e-02 -1.0682009e-02  4.6916034e-02\n",
      "    4.2791020e-02 -6.0172193e-03  3.7966598e-02  3.4942515e-03]]\n",
      "\n",
      " [[ 1.1086047e-02 -1.0744106e-02 -3.1469181e-02  3.3658631e-03\n",
      "    4.0743817e-02  4.5282308e-02  9.2195049e-03  1.6110804e-02\n",
      "   -4.2925965e-02 -3.9086867e-02 -3.5972036e-02 -1.4558397e-02\n",
      "    2.5696520e-02  3.7048090e-02  1.5055183e-02 -1.7172553e-02]\n",
      "  [ 4.2286027e-02  1.4010910e-02 -3.5856616e-02  4.6281967e-02\n",
      "    3.5308328e-02 -1.2679242e-02  2.9447351e-02  5.5487044e-03\n",
      "   -2.9109096e-02  1.5844081e-02  2.8017107e-02  3.5805631e-02\n",
      "   -1.4904965e-02  3.1148005e-02  1.0645665e-02 -6.2049851e-03]\n",
      "  [-3.6721718e-02 -6.4661391e-03 -3.4210552e-02  2.7941871e-02\n",
      "    3.6712538e-02 -4.3104541e-02  3.4665439e-02  2.5092635e-02\n",
      "   -3.5889521e-03 -4.6047140e-02  4.2938475e-02  3.2493282e-02\n",
      "    5.0657168e-03 -3.8341057e-02 -2.7876938e-02 -1.1268031e-02]\n",
      "  [ 1.1025369e-02 -4.0576793e-02 -4.1697063e-02 -2.8872121e-02\n",
      "   -3.8965881e-02  6.9435462e-03 -3.6328971e-02 -1.5392374e-02\n",
      "   -1.4226913e-02  6.2467903e-04 -4.4661224e-02  4.7609571e-02\n",
      "    1.4976155e-02  3.8990665e-02 -4.9942244e-02 -9.1280788e-04]\n",
      "  [-1.6678296e-02 -4.8965253e-02 -2.2283269e-02 -4.0318370e-02\n",
      "   -4.7271874e-02 -3.2663547e-02 -3.8816821e-02 -2.1342898e-02\n",
      "   -1.1359107e-02  4.2222366e-03  3.2539736e-02  4.9757566e-02\n",
      "    5.4473765e-03 -3.3637930e-02 -3.9339773e-03  3.1732805e-03]\n",
      "  [ 4.7012497e-02 -5.4558143e-03 -9.2979558e-03 -3.6697555e-02\n",
      "   -4.3919802e-02  1.7334830e-02  2.9253129e-02 -1.9433126e-03\n",
      "   -1.5680861e-02  2.3198929e-02 -1.0682009e-02  4.6916034e-02\n",
      "    4.2791020e-02 -6.0172193e-03  3.7966598e-02  3.4942515e-03]]\n",
      "\n",
      " [[-3.5024833e-02  2.6573393e-02  1.9384790e-02 -3.0269850e-02\n",
      "   -2.4700379e-02 -3.7488341e-03 -4.2538166e-02  5.3824559e-03\n",
      "   -4.7451403e-02  1.1713468e-02 -1.7278362e-02  3.6895756e-02\n",
      "   -1.7769527e-02 -3.0596185e-02 -4.1076530e-02 -3.2316223e-03]\n",
      "  [ 3.9272357e-02 -3.0825114e-02  2.7911935e-02 -3.8207375e-02\n",
      "   -2.6891381e-04 -2.5847852e-02 -3.0372834e-02 -4.1344874e-03\n",
      "   -5.3733587e-03  9.6327551e-03 -4.0780462e-02 -2.3908257e-02\n",
      "    2.3634683e-02 -6.5943114e-03  4.7075395e-02 -8.0389269e-03]\n",
      "  [-3.7927926e-02 -1.1343561e-02  1.2053907e-02 -2.9954202e-03\n",
      "   -4.4169784e-02 -2.1996617e-02  3.8153004e-02  1.1697784e-03\n",
      "   -2.3051405e-02 -2.9173911e-02 -1.9731676e-02 -1.6320277e-02\n",
      "    6.6160038e-04 -2.7591718e-02 -4.3443084e-02 -3.6777221e-02]\n",
      "  [-4.5711864e-02 -4.0136337e-02 -1.2940012e-02  1.1498321e-02\n",
      "   -2.8680468e-02 -1.0831036e-02  5.7862028e-03  4.3429684e-02\n",
      "    2.8056875e-03  4.4959188e-03 -4.5706786e-02 -4.8598804e-02\n",
      "    4.7800485e-02  3.0967180e-02  3.0169461e-02  1.0740567e-02]\n",
      "  [-4.9217939e-03 -2.9947555e-02 -8.5864775e-03 -2.1999156e-02\n",
      "   -2.3890126e-02 -2.5997913e-02  4.0736903e-02  3.2736730e-02\n",
      "   -9.9173300e-03  1.5995029e-02  3.1036567e-02  3.6686454e-02\n",
      "    4.7601759e-05  1.4330041e-02  3.0370299e-02  3.8051594e-02]\n",
      "  [-1.6678296e-02 -4.8965253e-02 -2.2283269e-02 -4.0318370e-02\n",
      "   -4.7271874e-02 -3.2663547e-02 -3.8816821e-02 -2.1342898e-02\n",
      "   -1.1359107e-02  4.2222366e-03  3.2539736e-02  4.9757566e-02\n",
      "    5.4473765e-03 -3.3637930e-02 -3.9339773e-03  3.1732805e-03]]], shape=(3, 6, 16), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ True  True  True False False False]\n",
      " [ True  True  True  True  True False]\n",
      " [ True  True  True  True  True  True]], shape=(3, 6), dtype=bool)\n",
      "tf.Tensor(\n",
      "[[ True  True  True False False False]\n",
      " [ True  True  True  True  True False]\n",
      " [ True  True  True  True  True  True]], shape=(3, 6), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "# three ways of masking\n",
    "# keras.layers.Masking, keras.layers.Embedding with mask_zero=True, mask argument in RNN layers\n",
    "\n",
    "embedding = layers.Embedding(input_dim=5000, output_dim=16, mask_zero=True)\n",
    "masked_output = embedding(padded_inputs)\n",
    "\n",
    "print(masked_output)\n",
    "print(masked_output._keras_mask)\n",
    "\n",
    "# all these False entries corresponding to some given timestep are ignored\n",
    "\n",
    "masking_layer = layers.Masking()\n",
    "# Simulate the embedding lookup by expanding the 2D input to 3D,\n",
    "# with embedding dimension of 10.\n",
    "unmasked_embedding = tf.cast(\n",
    "    tf.tile(tf.expand_dims(padded_inputs, axis=-1), [1, 1, 10]), tf.float32\n",
    ")\n",
    "\n",
    "masked_embedding = masking_layer(unmasked_embedding)\n",
    "print(masked_embedding._keras_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask propagation in Functional or Sequential API\n",
    "# Sequential:\n",
    "model = keras.Sequential(\n",
    "    [layers.Embedding(input_dim=5000, output_dim=16, mask_zero=True), layers.LSTM(32),])\n",
    "\n",
    "#Functional API model:\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "x = layers.Embedding(input_dim=5000, output_dim=16, mask_zero=True)(inputs)\n",
    "outputs = layers.LSTM(32)(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passing mask tensors directly to layer\n",
    "# subclassing layer.Layer example:\n",
    "# pass mask producing layer o/p (layer like keras.Embedding or keras.Masking) to mask consuming layer (like LSTM)\n",
    "# mask producing layer has compute_mask(input, previous_mask) method while mask consuming layer has mask argument in __call__ method\n",
    "\n",
    "class MyLayer(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "        self.embedding = layers.Embedding(input_dim=5000, output_dim=16, mask_zero=True)\n",
    "        self.lstm = layers.LSTM(32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.embedding(inputs)\n",
    "        # Note that you could also prepare a `mask` tensor manually.\n",
    "        # It only needs to be a boolean tensor\n",
    "        # with the right shape, i.e. (batch_size, timesteps).\n",
    "        mask = self.embedding.compute_mask(inputs)\n",
    "        output = self.lstm(x, mask=mask)  # The layer will ignore the masked values\n",
    "        return output\n",
    "\n",
    "\n",
    "layer = MyLayer()\n",
    "x = np.random.random((32, 10)) * 100\n",
    "x = x.astype(\"int32\")\n",
    "layer(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded_inputs:  [[ 711  632   71    0    0    0]\n",
      " [  73    8 3215   55  927    0]\n",
      " [  83   91    1  645 1253  927]]\n",
      "tf.expand_dims(padded_inputs, axis=-1):  [3, 6, 1]\n",
      "unmasked_embedding  tf.Tensor(\n",
      "[[[7.110e+02 7.110e+02 7.110e+02 7.110e+02 7.110e+02 7.110e+02 7.110e+02\n",
      "   7.110e+02 7.110e+02 7.110e+02]\n",
      "  [6.320e+02 6.320e+02 6.320e+02 6.320e+02 6.320e+02 6.320e+02 6.320e+02\n",
      "   6.320e+02 6.320e+02 6.320e+02]\n",
      "  [7.100e+01 7.100e+01 7.100e+01 7.100e+01 7.100e+01 7.100e+01 7.100e+01\n",
      "   7.100e+01 7.100e+01 7.100e+01]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00 0.000e+00 0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00 0.000e+00 0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00 0.000e+00 0.000e+00]]\n",
      "\n",
      " [[7.300e+01 7.300e+01 7.300e+01 7.300e+01 7.300e+01 7.300e+01 7.300e+01\n",
      "   7.300e+01 7.300e+01 7.300e+01]\n",
      "  [8.000e+00 8.000e+00 8.000e+00 8.000e+00 8.000e+00 8.000e+00 8.000e+00\n",
      "   8.000e+00 8.000e+00 8.000e+00]\n",
      "  [3.215e+03 3.215e+03 3.215e+03 3.215e+03 3.215e+03 3.215e+03 3.215e+03\n",
      "   3.215e+03 3.215e+03 3.215e+03]\n",
      "  [5.500e+01 5.500e+01 5.500e+01 5.500e+01 5.500e+01 5.500e+01 5.500e+01\n",
      "   5.500e+01 5.500e+01 5.500e+01]\n",
      "  [9.270e+02 9.270e+02 9.270e+02 9.270e+02 9.270e+02 9.270e+02 9.270e+02\n",
      "   9.270e+02 9.270e+02 9.270e+02]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00 0.000e+00 0.000e+00]]\n",
      "\n",
      " [[8.300e+01 8.300e+01 8.300e+01 8.300e+01 8.300e+01 8.300e+01 8.300e+01\n",
      "   8.300e+01 8.300e+01 8.300e+01]\n",
      "  [9.100e+01 9.100e+01 9.100e+01 9.100e+01 9.100e+01 9.100e+01 9.100e+01\n",
      "   9.100e+01 9.100e+01 9.100e+01]\n",
      "  [1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00\n",
      "   1.000e+00 1.000e+00 1.000e+00]\n",
      "  [6.450e+02 6.450e+02 6.450e+02 6.450e+02 6.450e+02 6.450e+02 6.450e+02\n",
      "   6.450e+02 6.450e+02 6.450e+02]\n",
      "  [1.253e+03 1.253e+03 1.253e+03 1.253e+03 1.253e+03 1.253e+03 1.253e+03\n",
      "   1.253e+03 1.253e+03 1.253e+03]\n",
      "  [9.270e+02 9.270e+02 9.270e+02 9.270e+02 9.270e+02 9.270e+02 9.270e+02\n",
      "   9.270e+02 9.270e+02 9.270e+02]]], shape=(3, 6, 10), dtype=float32)\n",
      "masked_embedding:  tf.Tensor(\n",
      "[[[7.110e+02 7.110e+02 7.110e+02 7.110e+02 7.110e+02 7.110e+02 7.110e+02\n",
      "   7.110e+02 7.110e+02 7.110e+02]\n",
      "  [6.320e+02 6.320e+02 6.320e+02 6.320e+02 6.320e+02 6.320e+02 6.320e+02\n",
      "   6.320e+02 6.320e+02 6.320e+02]\n",
      "  [7.100e+01 7.100e+01 7.100e+01 7.100e+01 7.100e+01 7.100e+01 7.100e+01\n",
      "   7.100e+01 7.100e+01 7.100e+01]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00 0.000e+00 0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00 0.000e+00 0.000e+00]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00 0.000e+00 0.000e+00]]\n",
      "\n",
      " [[7.300e+01 7.300e+01 7.300e+01 7.300e+01 7.300e+01 7.300e+01 7.300e+01\n",
      "   7.300e+01 7.300e+01 7.300e+01]\n",
      "  [8.000e+00 8.000e+00 8.000e+00 8.000e+00 8.000e+00 8.000e+00 8.000e+00\n",
      "   8.000e+00 8.000e+00 8.000e+00]\n",
      "  [3.215e+03 3.215e+03 3.215e+03 3.215e+03 3.215e+03 3.215e+03 3.215e+03\n",
      "   3.215e+03 3.215e+03 3.215e+03]\n",
      "  [5.500e+01 5.500e+01 5.500e+01 5.500e+01 5.500e+01 5.500e+01 5.500e+01\n",
      "   5.500e+01 5.500e+01 5.500e+01]\n",
      "  [9.270e+02 9.270e+02 9.270e+02 9.270e+02 9.270e+02 9.270e+02 9.270e+02\n",
      "   9.270e+02 9.270e+02 9.270e+02]\n",
      "  [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
      "   0.000e+00 0.000e+00 0.000e+00]]\n",
      "\n",
      " [[8.300e+01 8.300e+01 8.300e+01 8.300e+01 8.300e+01 8.300e+01 8.300e+01\n",
      "   8.300e+01 8.300e+01 8.300e+01]\n",
      "  [9.100e+01 9.100e+01 9.100e+01 9.100e+01 9.100e+01 9.100e+01 9.100e+01\n",
      "   9.100e+01 9.100e+01 9.100e+01]\n",
      "  [1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00 1.000e+00\n",
      "   1.000e+00 1.000e+00 1.000e+00]\n",
      "  [6.450e+02 6.450e+02 6.450e+02 6.450e+02 6.450e+02 6.450e+02 6.450e+02\n",
      "   6.450e+02 6.450e+02 6.450e+02]\n",
      "  [1.253e+03 1.253e+03 1.253e+03 1.253e+03 1.253e+03 1.253e+03 1.253e+03\n",
      "   1.253e+03 1.253e+03 1.253e+03]\n",
      "  [9.270e+02 9.270e+02 9.270e+02 9.270e+02 9.270e+02 9.270e+02 9.270e+02\n",
      "   9.270e+02 9.270e+02 9.270e+02]]], shape=(3, 6, 10), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]], shape=(3, 3), dtype=bool)\n",
      "tf.Tensor(\n",
      "[[False False False]\n",
      " [ True  True False]\n",
      " [ True  True  True]], shape=(3, 3), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "# this is just a custom special layer which breaks input into 2 in temporal dimension. But here, this would mean that we need to break even the correposnding initial masking into two.\n",
    "# this is what is dine below in compute_mask (this function gerenartes mask)\n",
    "\n",
    "class TemporalSplit(keras.layers.Layer):\n",
    "    \"\"\"Split the input tensor into 2 tensors along the time dimension.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Expect the input to be 3D and mask to be 2D, split the input tensor into 2\n",
    "        # subtensors along the time axis (axis 1).\n",
    "        return tf.split(inputs, 2, axis=1)\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        # Also split the mask into 2 if it presents.\n",
    "        if mask is None:\n",
    "            return None\n",
    "        return tf.split(mask, 2, axis=1)\n",
    "\n",
    "print(\"padded_inputs: \",padded_inputs)\n",
    "print(\"tf.expand_dims(padded_inputs, axis=-1): \", tf.expand_dims(padded_inputs, axis=-1).shape.as_list())\n",
    "print(\"unmasked_embedding \",unmasked_embedding)\n",
    "print(\"masked_embedding: \",masked_embedding)\n",
    "first_half, second_half = TemporalSplit()(masked_embedding)\n",
    "print(first_half._keras_mask)\n",
    "print(second_half._keras_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 4 0 3 1 5 6 2 2 5]\n",
      " [3 7 0 2 0 2 6 6 8 7]\n",
      " [8 7 0 0 6 1 8 2 4 7]]\n",
      "tf.Tensor(\n",
      "[[[ 4.13454995e-02  2.81021427e-02  2.26016715e-02  6.42389283e-02\n",
      "   -3.23462002e-02 -4.42980342e-02 -2.27454957e-02 -2.91165058e-02\n",
      "    5.44538982e-02  8.35291576e-05  6.42639622e-02  3.31923887e-02\n",
      "    3.04439403e-02  5.26229516e-02  1.24696814e-01  9.28672627e-02\n",
      "   -4.00146917e-02 -3.49870659e-02 -2.29416844e-02  1.63964462e-02\n",
      "    4.85911779e-02  3.69289778e-02 -3.32369166e-03 -2.82045156e-02\n",
      "   -1.81165636e-02  2.23863740e-02  7.40339831e-02  6.03724131e-03\n",
      "   -6.53247461e-02 -7.41132721e-02  5.03686629e-03  2.99828202e-02]\n",
      "  [ 4.62367274e-02 -2.31569330e-03  1.26677454e-02 -6.43004775e-02\n",
      "   -1.84597075e-02 -3.14814299e-02  2.62522455e-02 -6.01142757e-02\n",
      "   -2.25735269e-02  8.46739411e-02  3.78728360e-02 -4.62870039e-02\n",
      "    7.70708686e-03  4.48298175e-03  1.32348416e-02 -1.82713345e-02\n",
      "   -9.80684757e-02 -4.85746516e-03 -2.42117178e-02  1.23369507e-01\n",
      "    1.90173667e-02 -8.59398842e-02 -3.05462535e-02 -2.32563559e-02\n",
      "    6.05763262e-03 -8.12429469e-03  4.81820293e-02  4.32055555e-02\n",
      "    6.34215015e-04  7.88415875e-03 -4.71657850e-02 -1.98365338e-02]\n",
      "  [ 1.35717392e-02  3.10533177e-02 -2.87006628e-02 -5.42014241e-02\n",
      "    2.12054793e-02  3.27117853e-02  3.64690158e-03  6.86601400e-02\n",
      "    1.86131727e-02 -7.34819323e-02  5.45605794e-02  3.46397161e-02\n",
      "    3.75345871e-02 -2.91518029e-02  6.42436966e-02 -1.87214985e-02\n",
      "    7.17179999e-02 -8.84961411e-02  7.14409957e-03  7.32961074e-02\n",
      "    2.12262627e-02 -2.82036755e-02 -4.15914319e-02  2.81427652e-02\n",
      "   -5.56802452e-02  5.68620153e-02  6.72624782e-02 -2.24676616e-02\n",
      "   -6.19942546e-02  9.35922340e-02  7.28190178e-03  8.31640617e-04]\n",
      "  [ 4.13454995e-02  2.81021427e-02  2.26016715e-02  6.42389283e-02\n",
      "   -3.23462002e-02 -4.42980342e-02 -2.27454957e-02 -2.91165058e-02\n",
      "    5.44538982e-02  8.35291576e-05  6.42639622e-02  3.31923887e-02\n",
      "    3.04439403e-02  5.26229516e-02  1.24696814e-01  9.28672627e-02\n",
      "   -4.00146917e-02 -3.49870659e-02 -2.29416844e-02  1.63964462e-02\n",
      "    4.85911779e-02  3.69289778e-02 -3.32369166e-03 -2.82045156e-02\n",
      "   -1.81165636e-02  2.23863740e-02  7.40339831e-02  6.03724131e-03\n",
      "   -6.53247461e-02 -7.41132721e-02  5.03686629e-03  2.99828202e-02]\n",
      "  [-8.48572701e-02  2.85037588e-02 -4.85348180e-02  9.54163447e-03\n",
      "   -2.86695212e-02 -3.64828408e-02 -4.95103793e-03 -7.34272227e-02\n",
      "    3.47384922e-02 -1.38116004e-02 -2.97940057e-03 -8.63204673e-02\n",
      "    8.75620767e-02  3.77539359e-02  4.84868698e-02 -7.92210028e-02\n",
      "    5.81986783e-03  5.85158169e-02  5.41857854e-02  5.38827255e-02\n",
      "   -8.23000669e-02  1.17870905e-01 -9.23443586e-02 -7.00439066e-02\n",
      "    7.21709952e-02  5.86936176e-02 -9.55147669e-02 -8.09987336e-02\n",
      "    2.17773207e-02 -6.87801763e-02  1.85057279e-02  3.04989051e-02]\n",
      "  [-2.65690237e-02  3.32149724e-03 -2.33881958e-02  2.55847573e-02\n",
      "    6.67244419e-02 -9.17320475e-02 -1.04687892e-01  4.19958420e-02\n",
      "   -7.15172887e-02 -2.40732711e-02  4.26019765e-02 -8.97120778e-03\n",
      "    5.94165288e-02 -1.03424843e-02 -1.09218575e-01 -6.01720288e-02\n",
      "   -7.87192136e-02  1.29415886e-02  3.41367349e-02 -1.88651811e-02\n",
      "   -8.07073712e-02 -4.87723090e-02 -1.23097084e-01  2.47486476e-02\n",
      "   -1.26194498e-02 -7.95099884e-02 -6.61446601e-02 -7.37611800e-02\n",
      "   -5.58857433e-03  7.01834410e-02  6.97572902e-02  4.55252230e-02]\n",
      "  [-2.08704341e-02  3.05773374e-02 -6.85271574e-03 -3.09929047e-02\n",
      "   -8.68335888e-02 -7.79358763e-03  7.86535721e-03 -1.14693474e-02\n",
      "   -8.11347272e-03  2.27975454e-02  1.06501142e-02  2.83420179e-02\n",
      "   -7.40741342e-02 -7.92092606e-02  2.55665276e-02 -3.80163430e-03\n",
      "   -1.92911681e-02  4.99436446e-03 -1.47718787e-02  6.09457307e-02\n",
      "   -4.71287407e-02 -8.30089301e-02 -4.10447381e-02  2.61352398e-02\n",
      "   -1.09884767e-02 -7.65597150e-02  1.56374369e-02 -7.28586242e-02\n",
      "    3.40072401e-02  7.13033080e-02  2.48320098e-03 -3.93518619e-02]\n",
      "  [-1.16715571e-02  4.18670066e-02 -5.20669706e-02 -1.74741428e-02\n",
      "    7.88390338e-02  7.99821466e-02  2.19711438e-02  5.37260547e-02\n",
      "   -7.74526363e-03  3.57622728e-02  5.86096942e-02 -8.58202111e-03\n",
      "    2.57613184e-03 -2.65251547e-02 -5.17753921e-02  3.16786282e-02\n",
      "   -1.54983047e-02  6.80188388e-02 -2.92977598e-02  5.30115031e-02\n",
      "    2.09694058e-02 -3.90949510e-02  1.00648858e-01  1.00246472e-02\n",
      "    3.43213268e-02 -6.51713163e-02  2.54190359e-02  1.30023723e-02\n",
      "   -1.77344624e-02  2.96334606e-02 -4.98340093e-02 -4.39905412e-02]\n",
      "  [-1.16715571e-02  4.18670066e-02 -5.20669706e-02 -1.74741428e-02\n",
      "    7.88390338e-02  7.99821466e-02  2.19711438e-02  5.37260547e-02\n",
      "   -7.74526363e-03  3.57622728e-02  5.86096942e-02 -8.58202111e-03\n",
      "    2.57613184e-03 -2.65251547e-02 -5.17753921e-02  3.16786282e-02\n",
      "   -1.54983047e-02  6.80188388e-02 -2.92977598e-02  5.30115031e-02\n",
      "    2.09694058e-02 -3.90949510e-02  1.00648858e-01  1.00246472e-02\n",
      "    3.43213268e-02 -6.51713163e-02  2.54190359e-02  1.30023723e-02\n",
      "   -1.77344624e-02  2.96334606e-02 -4.98340093e-02 -4.39905412e-02]\n",
      "  [-2.65690237e-02  3.32149724e-03 -2.33881958e-02  2.55847573e-02\n",
      "    6.67244419e-02 -9.17320475e-02 -1.04687892e-01  4.19958420e-02\n",
      "   -7.15172887e-02 -2.40732711e-02  4.26019765e-02 -8.97120778e-03\n",
      "    5.94165288e-02 -1.03424843e-02 -1.09218575e-01 -6.01720288e-02\n",
      "   -7.87192136e-02  1.29415886e-02  3.41367349e-02 -1.88651811e-02\n",
      "   -8.07073712e-02 -4.87723090e-02 -1.23097084e-01  2.47486476e-02\n",
      "   -1.26194498e-02 -7.95099884e-02 -6.61446601e-02 -7.37611800e-02\n",
      "   -5.58857433e-03  7.01834410e-02  6.97572902e-02  4.55252230e-02]]\n",
      "\n",
      " [[ 4.13454995e-02  2.81021427e-02  2.26016715e-02  6.42389283e-02\n",
      "   -3.23462002e-02 -4.42980342e-02 -2.27454957e-02 -2.91165058e-02\n",
      "    5.44538982e-02  8.35291576e-05  6.42639622e-02  3.31923887e-02\n",
      "    3.04439403e-02  5.26229516e-02  1.24696814e-01  9.28672627e-02\n",
      "   -4.00146917e-02 -3.49870659e-02 -2.29416844e-02  1.63964462e-02\n",
      "    4.85911779e-02  3.69289778e-02 -3.32369166e-03 -2.82045156e-02\n",
      "   -1.81165636e-02  2.23863740e-02  7.40339831e-02  6.03724131e-03\n",
      "   -6.53247461e-02 -7.41132721e-02  5.03686629e-03  2.99828202e-02]\n",
      "  [-5.96916974e-02 -1.53429538e-01 -1.11944117e-01  3.61037441e-03\n",
      "    3.63226165e-03 -4.10352312e-02  4.35778080e-03  5.12921298e-03\n",
      "    5.80909923e-02  3.43500040e-02  7.47025013e-02  2.12048870e-02\n",
      "   -8.22137222e-02  2.63022929e-02 -6.40635937e-02  2.70947348e-02\n",
      "   -3.26390415e-02 -2.71915086e-02  1.22251488e-01 -3.08301463e-03\n",
      "    1.40415272e-02  1.99794620e-02 -1.43571794e-02  3.77281792e-02\n",
      "    4.74422099e-03  6.68834671e-02  4.85254489e-02 -1.24461375e-01\n",
      "   -7.81990886e-02  1.28866425e-02  1.85274112e-03  2.12836824e-02]\n",
      "  [ 1.35717392e-02  3.10533177e-02 -2.87006628e-02 -5.42014241e-02\n",
      "    2.12054793e-02  3.27117853e-02  3.64690158e-03  6.86601400e-02\n",
      "    1.86131727e-02 -7.34819323e-02  5.45605794e-02  3.46397161e-02\n",
      "    3.75345871e-02 -2.91518029e-02  6.42436966e-02 -1.87214985e-02\n",
      "    7.17179999e-02 -8.84961411e-02  7.14409957e-03  7.32961074e-02\n",
      "    2.12262627e-02 -2.82036755e-02 -4.15914319e-02  2.81427652e-02\n",
      "   -5.56802452e-02  5.68620153e-02  6.72624782e-02 -2.24676616e-02\n",
      "   -6.19942546e-02  9.35922340e-02  7.28190178e-03  8.31640617e-04]\n",
      "  [-1.16715571e-02  4.18670066e-02 -5.20669706e-02 -1.74741428e-02\n",
      "    7.88390338e-02  7.99821466e-02  2.19711438e-02  5.37260547e-02\n",
      "   -7.74526363e-03  3.57622728e-02  5.86096942e-02 -8.58202111e-03\n",
      "    2.57613184e-03 -2.65251547e-02 -5.17753921e-02  3.16786282e-02\n",
      "   -1.54983047e-02  6.80188388e-02 -2.92977598e-02  5.30115031e-02\n",
      "    2.09694058e-02 -3.90949510e-02  1.00648858e-01  1.00246472e-02\n",
      "    3.43213268e-02 -6.51713163e-02  2.54190359e-02  1.30023723e-02\n",
      "   -1.77344624e-02  2.96334606e-02 -4.98340093e-02 -4.39905412e-02]\n",
      "  [ 1.35717392e-02  3.10533177e-02 -2.87006628e-02 -5.42014241e-02\n",
      "    2.12054793e-02  3.27117853e-02  3.64690158e-03  6.86601400e-02\n",
      "    1.86131727e-02 -7.34819323e-02  5.45605794e-02  3.46397161e-02\n",
      "    3.75345871e-02 -2.91518029e-02  6.42436966e-02 -1.87214985e-02\n",
      "    7.17179999e-02 -8.84961411e-02  7.14409957e-03  7.32961074e-02\n",
      "    2.12262627e-02 -2.82036755e-02 -4.15914319e-02  2.81427652e-02\n",
      "   -5.56802452e-02  5.68620153e-02  6.72624782e-02 -2.24676616e-02\n",
      "   -6.19942546e-02  9.35922340e-02  7.28190178e-03  8.31640617e-04]\n",
      "  [-1.16715571e-02  4.18670066e-02 -5.20669706e-02 -1.74741428e-02\n",
      "    7.88390338e-02  7.99821466e-02  2.19711438e-02  5.37260547e-02\n",
      "   -7.74526363e-03  3.57622728e-02  5.86096942e-02 -8.58202111e-03\n",
      "    2.57613184e-03 -2.65251547e-02 -5.17753921e-02  3.16786282e-02\n",
      "   -1.54983047e-02  6.80188388e-02 -2.92977598e-02  5.30115031e-02\n",
      "    2.09694058e-02 -3.90949510e-02  1.00648858e-01  1.00246472e-02\n",
      "    3.43213268e-02 -6.51713163e-02  2.54190359e-02  1.30023723e-02\n",
      "   -1.77344624e-02  2.96334606e-02 -4.98340093e-02 -4.39905412e-02]\n",
      "  [-2.08704341e-02  3.05773374e-02 -6.85271574e-03 -3.09929047e-02\n",
      "   -8.68335888e-02 -7.79358763e-03  7.86535721e-03 -1.14693474e-02\n",
      "   -8.11347272e-03  2.27975454e-02  1.06501142e-02  2.83420179e-02\n",
      "   -7.40741342e-02 -7.92092606e-02  2.55665276e-02 -3.80163430e-03\n",
      "   -1.92911681e-02  4.99436446e-03 -1.47718787e-02  6.09457307e-02\n",
      "   -4.71287407e-02 -8.30089301e-02 -4.10447381e-02  2.61352398e-02\n",
      "   -1.09884767e-02 -7.65597150e-02  1.56374369e-02 -7.28586242e-02\n",
      "    3.40072401e-02  7.13033080e-02  2.48320098e-03 -3.93518619e-02]\n",
      "  [-2.08704341e-02  3.05773374e-02 -6.85271574e-03 -3.09929047e-02\n",
      "   -8.68335888e-02 -7.79358763e-03  7.86535721e-03 -1.14693474e-02\n",
      "   -8.11347272e-03  2.27975454e-02  1.06501142e-02  2.83420179e-02\n",
      "   -7.40741342e-02 -7.92092606e-02  2.55665276e-02 -3.80163430e-03\n",
      "   -1.92911681e-02  4.99436446e-03 -1.47718787e-02  6.09457307e-02\n",
      "   -4.71287407e-02 -8.30089301e-02 -4.10447381e-02  2.61352398e-02\n",
      "   -1.09884767e-02 -7.65597150e-02  1.56374369e-02 -7.28586242e-02\n",
      "    3.40072401e-02  7.13033080e-02  2.48320098e-03 -3.93518619e-02]\n",
      "  [-3.60190943e-02  6.24367781e-02  8.95934831e-03  9.19256732e-02\n",
      "   -6.17976151e-02 -5.80726862e-02  6.46343976e-02 -7.88360909e-02\n",
      "   -2.65982505e-02 -3.82359559e-03 -2.90852133e-02  7.35905245e-02\n",
      "    1.27853202e-02  4.59664054e-02 -2.78036594e-02  2.07176711e-02\n",
      "    1.54113478e-03 -6.63584694e-02  4.84917611e-02  1.13178892e-02\n",
      "    6.83818385e-03  7.90461525e-02 -5.50246015e-02  1.16294529e-02\n",
      "   -4.52410094e-02 -2.09324639e-02  2.34188344e-02 -6.39155880e-02\n",
      "    2.20822524e-02  8.13285932e-02 -3.23122069e-02  4.93579656e-02]\n",
      "  [-5.96916974e-02 -1.53429538e-01 -1.11944117e-01  3.61037441e-03\n",
      "    3.63226165e-03 -4.10352312e-02  4.35778080e-03  5.12921298e-03\n",
      "    5.80909923e-02  3.43500040e-02  7.47025013e-02  2.12048870e-02\n",
      "   -8.22137222e-02  2.63022929e-02 -6.40635937e-02  2.70947348e-02\n",
      "   -3.26390415e-02 -2.71915086e-02  1.22251488e-01 -3.08301463e-03\n",
      "    1.40415272e-02  1.99794620e-02 -1.43571794e-02  3.77281792e-02\n",
      "    4.74422099e-03  6.68834671e-02  4.85254489e-02 -1.24461375e-01\n",
      "   -7.81990886e-02  1.28866425e-02  1.85274112e-03  2.12836824e-02]]\n",
      "\n",
      " [[-3.60190943e-02  6.24367781e-02  8.95934831e-03  9.19256732e-02\n",
      "   -6.17976151e-02 -5.80726862e-02  6.46343976e-02 -7.88360909e-02\n",
      "   -2.65982505e-02 -3.82359559e-03 -2.90852133e-02  7.35905245e-02\n",
      "    1.27853202e-02  4.59664054e-02 -2.78036594e-02  2.07176711e-02\n",
      "    1.54113478e-03 -6.63584694e-02  4.84917611e-02  1.13178892e-02\n",
      "    6.83818385e-03  7.90461525e-02 -5.50246015e-02  1.16294529e-02\n",
      "   -4.52410094e-02 -2.09324639e-02  2.34188344e-02 -6.39155880e-02\n",
      "    2.20822524e-02  8.13285932e-02 -3.23122069e-02  4.93579656e-02]\n",
      "  [-5.96916974e-02 -1.53429538e-01 -1.11944117e-01  3.61037441e-03\n",
      "    3.63226165e-03 -4.10352312e-02  4.35778080e-03  5.12921298e-03\n",
      "    5.80909923e-02  3.43500040e-02  7.47025013e-02  2.12048870e-02\n",
      "   -8.22137222e-02  2.63022929e-02 -6.40635937e-02  2.70947348e-02\n",
      "   -3.26390415e-02 -2.71915086e-02  1.22251488e-01 -3.08301463e-03\n",
      "    1.40415272e-02  1.99794620e-02 -1.43571794e-02  3.77281792e-02\n",
      "    4.74422099e-03  6.68834671e-02  4.85254489e-02 -1.24461375e-01\n",
      "   -7.81990886e-02  1.28866425e-02  1.85274112e-03  2.12836824e-02]\n",
      "  [ 1.35717392e-02  3.10533177e-02 -2.87006628e-02 -5.42014241e-02\n",
      "    2.12054793e-02  3.27117853e-02  3.64690158e-03  6.86601400e-02\n",
      "    1.86131727e-02 -7.34819323e-02  5.45605794e-02  3.46397161e-02\n",
      "    3.75345871e-02 -2.91518029e-02  6.42436966e-02 -1.87214985e-02\n",
      "    7.17179999e-02 -8.84961411e-02  7.14409957e-03  7.32961074e-02\n",
      "    2.12262627e-02 -2.82036755e-02 -4.15914319e-02  2.81427652e-02\n",
      "   -5.56802452e-02  5.68620153e-02  6.72624782e-02 -2.24676616e-02\n",
      "   -6.19942546e-02  9.35922340e-02  7.28190178e-03  8.31640617e-04]\n",
      "  [ 1.35717392e-02  3.10533177e-02 -2.87006628e-02 -5.42014241e-02\n",
      "    2.12054793e-02  3.27117853e-02  3.64690158e-03  6.86601400e-02\n",
      "    1.86131727e-02 -7.34819323e-02  5.45605794e-02  3.46397161e-02\n",
      "    3.75345871e-02 -2.91518029e-02  6.42436966e-02 -1.87214985e-02\n",
      "    7.17179999e-02 -8.84961411e-02  7.14409957e-03  7.32961074e-02\n",
      "    2.12262627e-02 -2.82036755e-02 -4.15914319e-02  2.81427652e-02\n",
      "   -5.56802452e-02  5.68620153e-02  6.72624782e-02 -2.24676616e-02\n",
      "   -6.19942546e-02  9.35922340e-02  7.28190178e-03  8.31640617e-04]\n",
      "  [-2.08704341e-02  3.05773374e-02 -6.85271574e-03 -3.09929047e-02\n",
      "   -8.68335888e-02 -7.79358763e-03  7.86535721e-03 -1.14693474e-02\n",
      "   -8.11347272e-03  2.27975454e-02  1.06501142e-02  2.83420179e-02\n",
      "   -7.40741342e-02 -7.92092606e-02  2.55665276e-02 -3.80163430e-03\n",
      "   -1.92911681e-02  4.99436446e-03 -1.47718787e-02  6.09457307e-02\n",
      "   -4.71287407e-02 -8.30089301e-02 -4.10447381e-02  2.61352398e-02\n",
      "   -1.09884767e-02 -7.65597150e-02  1.56374369e-02 -7.28586242e-02\n",
      "    3.40072401e-02  7.13033080e-02  2.48320098e-03 -3.93518619e-02]\n",
      "  [-8.48572701e-02  2.85037588e-02 -4.85348180e-02  9.54163447e-03\n",
      "   -2.86695212e-02 -3.64828408e-02 -4.95103793e-03 -7.34272227e-02\n",
      "    3.47384922e-02 -1.38116004e-02 -2.97940057e-03 -8.63204673e-02\n",
      "    8.75620767e-02  3.77539359e-02  4.84868698e-02 -7.92210028e-02\n",
      "    5.81986783e-03  5.85158169e-02  5.41857854e-02  5.38827255e-02\n",
      "   -8.23000669e-02  1.17870905e-01 -9.23443586e-02 -7.00439066e-02\n",
      "    7.21709952e-02  5.86936176e-02 -9.55147669e-02 -8.09987336e-02\n",
      "    2.17773207e-02 -6.87801763e-02  1.85057279e-02  3.04989051e-02]\n",
      "  [-3.60190943e-02  6.24367781e-02  8.95934831e-03  9.19256732e-02\n",
      "   -6.17976151e-02 -5.80726862e-02  6.46343976e-02 -7.88360909e-02\n",
      "   -2.65982505e-02 -3.82359559e-03 -2.90852133e-02  7.35905245e-02\n",
      "    1.27853202e-02  4.59664054e-02 -2.78036594e-02  2.07176711e-02\n",
      "    1.54113478e-03 -6.63584694e-02  4.84917611e-02  1.13178892e-02\n",
      "    6.83818385e-03  7.90461525e-02 -5.50246015e-02  1.16294529e-02\n",
      "   -4.52410094e-02 -2.09324639e-02  2.34188344e-02 -6.39155880e-02\n",
      "    2.20822524e-02  8.13285932e-02 -3.23122069e-02  4.93579656e-02]\n",
      "  [-1.16715571e-02  4.18670066e-02 -5.20669706e-02 -1.74741428e-02\n",
      "    7.88390338e-02  7.99821466e-02  2.19711438e-02  5.37260547e-02\n",
      "   -7.74526363e-03  3.57622728e-02  5.86096942e-02 -8.58202111e-03\n",
      "    2.57613184e-03 -2.65251547e-02 -5.17753921e-02  3.16786282e-02\n",
      "   -1.54983047e-02  6.80188388e-02 -2.92977598e-02  5.30115031e-02\n",
      "    2.09694058e-02 -3.90949510e-02  1.00648858e-01  1.00246472e-02\n",
      "    3.43213268e-02 -6.51713163e-02  2.54190359e-02  1.30023723e-02\n",
      "   -1.77344624e-02  2.96334606e-02 -4.98340093e-02 -4.39905412e-02]\n",
      "  [ 4.62367274e-02 -2.31569330e-03  1.26677454e-02 -6.43004775e-02\n",
      "   -1.84597075e-02 -3.14814299e-02  2.62522455e-02 -6.01142757e-02\n",
      "   -2.25735269e-02  8.46739411e-02  3.78728360e-02 -4.62870039e-02\n",
      "    7.70708686e-03  4.48298175e-03  1.32348416e-02 -1.82713345e-02\n",
      "   -9.80684757e-02 -4.85746516e-03 -2.42117178e-02  1.23369507e-01\n",
      "    1.90173667e-02 -8.59398842e-02 -3.05462535e-02 -2.32563559e-02\n",
      "    6.05763262e-03 -8.12429469e-03  4.81820293e-02  4.32055555e-02\n",
      "    6.34215015e-04  7.88415875e-03 -4.71657850e-02 -1.98365338e-02]\n",
      "  [-5.96916974e-02 -1.53429538e-01 -1.11944117e-01  3.61037441e-03\n",
      "    3.63226165e-03 -4.10352312e-02  4.35778080e-03  5.12921298e-03\n",
      "    5.80909923e-02  3.43500040e-02  7.47025013e-02  2.12048870e-02\n",
      "   -8.22137222e-02  2.63022929e-02 -6.40635937e-02  2.70947348e-02\n",
      "   -3.26390415e-02 -2.71915086e-02  1.22251488e-01 -3.08301463e-03\n",
      "    1.40415272e-02  1.99794620e-02 -1.43571794e-02  3.77281792e-02\n",
      "    4.74422099e-03  6.68834671e-02  4.85254489e-02 -1.24461375e-01\n",
      "   -7.81990886e-02  1.28866425e-02  1.85274112e-03  2.12836824e-02]]], shape=(3, 10, 32), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ True  True False  True  True  True  True  True  True  True]\n",
      " [ True  True False  True False  True  True  True  True  True]\n",
      " [ True  True False False  True  True  True  True  True  True]], shape=(3, 10), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "# another example where \n",
    "class CustomEmbedding(keras.layers.Layer):\n",
    "    def __init__(self, input_dim, output_dim, mask_zero=False, **kwargs):\n",
    "        super(CustomEmbedding, self).__init__(**kwargs)\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.mask_zero = mask_zero\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.embeddings = self.add_weight(\n",
    "            shape=(self.input_dim, self.output_dim),\n",
    "            initializer=\"random_normal\",\n",
    "            dtype=\"float32\",\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.nn.embedding_lookup(self.embeddings, inputs)\n",
    "        #return inputs\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        if not self.mask_zero:\n",
    "            return None\n",
    "        return tf.not_equal(inputs, 0)\n",
    "\n",
    "\n",
    "layer = CustomEmbedding(10, 32, mask_zero=True)\n",
    "x = np.random.random((3, 10)) * 9\n",
    "x = x.astype(\"int32\")\n",
    "print(x)\n",
    "\n",
    "y = layer(x)\n",
    "print(y)\n",
    "mask = layer.compute_mask(x)\n",
    "\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask found: Tensor(\"embedding_6/NotEqual:0\", shape=(None, None), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "# by default any custom layer would destroy the current mask. In order to force it not to:\n",
    "# you need to set self.supports_masking=True in the constructor.\n",
    "\n",
    "class MyActivation(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyActivation, self).__init__(**kwargs)\n",
    "        # Signal that the layer is safe for mask propagation\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.nn.relu(inputs)\n",
    "    \n",
    "    \n",
    "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "x = layers.Embedding(input_dim=5000, output_dim=16, mask_zero=True)(inputs)\n",
    "x = MyActivation()(x)  # Will pass the mask along\n",
    "print(\"Mask found:\", x._keras_mask)\n",
    "outputs = layers.LSTM(32)(x)  # Will receive the mask\n",
    "\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing layers that do masking:\n",
    "class TemporalSoftmax(keras.layers.Layer):\n",
    "    def call(self, inputs, mask=None):\n",
    "        broadcast_float_mask = tf.expand_dims(tf.cast(mask, \"float32\"), -1)\n",
    "        inputs_exp = tf.exp(inputs) * broadcast_float_mask\n",
    "        inputs_sum = tf.reduce_sum(\n",
    "            inputs_exp * broadcast_float_mask, axis=-1, keepdims=True\n",
    "        )\n",
    "        return inputs_exp / inputs_sum\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "x = layers.Embedding(input_dim=10, output_dim=32, mask_zero=True)(inputs)\n",
    "x = layers.Dense(1)(x)\n",
    "outputs = TemporalSoftmax()(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "y = model(np.random.randint(0, 10, size=(32, 100)), np.random.random((32, 100, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
