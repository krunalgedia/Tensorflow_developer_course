{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow version 2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "import timeit\n",
    "from datetime import datetime\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import array\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "print(\"Using TensorFlow version %s\" % tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Dense\n",
    "from tensorflow.keras.layers import Flatten, LSTM\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "#from tensorflow.keras.layers.Embedding import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Input\n",
    "#from tensorflow.keras.layers.merge import Concatenate\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "[ 15  30  45  60  75  90 105 120 135 150 165 180 195 210 225 240 255 270\n",
      " 285 300]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([x+1 for x in range(20)])\n",
    "Y = np.array([y * 15 for y in X])\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = array(X).reshape(20, 1, 1) #batch_size, time-steps, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 50)                10400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 10,451\n",
      "Trainable params: 10,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(1, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "4/4 [==============================] - 1s 160ms/step - loss: 21102.3730 - val_loss: 77416.6016\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 21072.6367 - val_loss: 77298.1406\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 21044.7734 - val_loss: 77185.8203\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 21016.7734 - val_loss: 77072.2188\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 20989.8906 - val_loss: 76960.0859\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 20960.9023 - val_loss: 76849.7656\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 20931.7500 - val_loss: 76732.8828\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 20902.2051 - val_loss: 76609.8672\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 20871.9863 - val_loss: 76492.4062\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 20841.6113 - val_loss: 76372.5000\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 20811.6055 - val_loss: 76238.1406\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 20778.4727 - val_loss: 76100.9688\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 20745.5059 - val_loss: 75960.5234\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 20710.8125 - val_loss: 75810.4141\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 20671.8789 - val_loss: 75663.5312\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 20635.0000 - val_loss: 75513.4219\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 20595.9668 - val_loss: 75352.8984\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 20556.1934 - val_loss: 75178.1797\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 20508.8691 - val_loss: 74992.0078\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 20463.4043 - val_loss: 74792.2031\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 20410.4219 - val_loss: 74578.0938\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 20355.7441 - val_loss: 74354.5469\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 20303.6895 - val_loss: 74123.7188\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 20238.6797 - val_loss: 73889.3125\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 20180.3887 - val_loss: 73620.6406\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 20117.5762 - val_loss: 73341.7812\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 20047.6719 - val_loss: 73058.6875\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 19973.2090 - val_loss: 72766.3125\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 19902.3613 - val_loss: 72455.9375\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 19820.1680 - val_loss: 72118.3281\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 19731.9922 - val_loss: 71778.0938\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 19644.0820 - val_loss: 71407.7500\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 19547.8535 - val_loss: 70990.1094\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 19435.9199 - val_loss: 70548.4219\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 19330.8105 - val_loss: 70093.8828\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 19213.9844 - val_loss: 69671.6406\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 19102.9531 - val_loss: 69269.9062\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 19005.8730 - val_loss: 68860.8594\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 18889.9043 - val_loss: 68424.0547\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 18779.6426 - val_loss: 67956.7266\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 18654.4902 - val_loss: 67467.4062\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 18532.1836 - val_loss: 66958.4844\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 18386.5625 - val_loss: 66504.1875\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 18277.7695 - val_loss: 66060.8516\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 18154.3848 - val_loss: 65635.2969\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 18030.6875 - val_loss: 65205.3516\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 17923.9141 - val_loss: 64732.0938\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 17787.3008 - val_loss: 64266.4453\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 17649.1426 - val_loss: 63754.7188\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 17520.9004 - val_loss: 63209.0469\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 17372.6152 - val_loss: 62703.0117\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 17237.0273 - val_loss: 62206.4766\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 17089.5430 - val_loss: 61726.2500\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 16953.2480 - val_loss: 61183.7109\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 16812.5703 - val_loss: 60616.6328\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 16634.6465 - val_loss: 60087.7070\n",
      "Epoch 57/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 16490.6973 - val_loss: 59520.9766\n",
      "Epoch 58/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 16345.3535 - val_loss: 58967.6641\n",
      "Epoch 59/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 16194.9141 - val_loss: 58456.4531\n",
      "Epoch 60/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 16046.6455 - val_loss: 57973.5117\n",
      "Epoch 61/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 15902.4385 - val_loss: 57521.6875\n",
      "Epoch 62/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 15787.4189 - val_loss: 57057.7578\n",
      "Epoch 63/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 15642.8105 - val_loss: 56607.4375\n",
      "Epoch 64/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 15519.2031 - val_loss: 56141.5625\n",
      "Epoch 65/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 15389.3096 - val_loss: 55650.4609\n",
      "Epoch 66/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 15247.0605 - val_loss: 55160.9688\n",
      "Epoch 67/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 15117.3203 - val_loss: 54627.7070\n",
      "Epoch 68/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 14947.2402 - val_loss: 54103.0938\n",
      "Epoch 69/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 14789.0078 - val_loss: 53544.3594\n",
      "Epoch 70/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 14649.4395 - val_loss: 52974.1016\n",
      "Epoch 71/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 14486.4033 - val_loss: 52433.9766\n",
      "Epoch 72/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 14336.1064 - val_loss: 51869.8906\n",
      "Epoch 73/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 14167.5811 - val_loss: 51282.2188\n",
      "Epoch 74/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 13997.5283 - val_loss: 50667.9062\n",
      "Epoch 75/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 13822.8643 - val_loss: 50047.0312\n",
      "Epoch 76/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 13654.4189 - val_loss: 49409.8594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 13477.8916 - val_loss: 48811.4609\n",
      "Epoch 78/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 13311.8389 - val_loss: 48213.2109\n",
      "Epoch 79/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 13132.6797 - val_loss: 47590.3672\n",
      "Epoch 80/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 12958.2461 - val_loss: 46945.1875\n",
      "Epoch 81/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 12774.5342 - val_loss: 46309.1562\n",
      "Epoch 82/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 12588.9492 - val_loss: 45648.3281\n",
      "Epoch 83/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 12409.9199 - val_loss: 44999.0586\n",
      "Epoch 84/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 12217.7256 - val_loss: 44391.3320\n",
      "Epoch 85/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 12059.1406 - val_loss: 43781.6484\n",
      "Epoch 86/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 11887.0215 - val_loss: 43190.5859\n",
      "Epoch 87/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 11728.0186 - val_loss: 42569.5586\n",
      "Epoch 88/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 11560.9375 - val_loss: 41972.7500\n",
      "Epoch 89/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 11387.3066 - val_loss: 41395.1367\n",
      "Epoch 90/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 11228.6338 - val_loss: 40825.4688\n",
      "Epoch 91/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 11057.7939 - val_loss: 40237.3281\n",
      "Epoch 92/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 10895.2725 - val_loss: 39569.0625\n",
      "Epoch 93/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 10725.0205 - val_loss: 38881.1406\n",
      "Epoch 94/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 10511.6582 - val_loss: 38252.4297\n",
      "Epoch 95/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 10354.8809 - val_loss: 37594.2578\n",
      "Epoch 96/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 10172.7363 - val_loss: 36981.4141\n",
      "Epoch 97/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 9986.3906 - val_loss: 36392.3984\n",
      "Epoch 98/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 9834.1182 - val_loss: 35771.4609\n",
      "Epoch 99/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 9665.4473 - val_loss: 35182.2734\n",
      "Epoch 100/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 9486.8965 - val_loss: 34618.8008\n",
      "Epoch 101/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 9342.0996 - val_loss: 34003.0781\n",
      "Epoch 102/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 9169.9092 - val_loss: 33400.9648\n",
      "Epoch 103/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 8978.4082 - val_loss: 32807.4336\n",
      "Epoch 104/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 8822.0908 - val_loss: 32168.2031\n",
      "Epoch 105/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 8648.5625 - val_loss: 31544.0000\n",
      "Epoch 106/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 8459.6807 - val_loss: 30896.1035\n",
      "Epoch 107/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 8267.1152 - val_loss: 30255.3867\n",
      "Epoch 108/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 4217.67 - 0s 24ms/step - loss: 8091.2554 - val_loss: 29581.8906\n",
      "Epoch 109/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 7904.0029 - val_loss: 28902.6680\n",
      "Epoch 110/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7734.6113 - val_loss: 28197.5195\n",
      "Epoch 111/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 7515.0625 - val_loss: 27534.2344\n",
      "Epoch 112/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 7337.1313 - val_loss: 26845.7402\n",
      "Epoch 113/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 7148.8115 - val_loss: 26171.9727\n",
      "Epoch 114/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6976.6274 - val_loss: 25562.7852\n",
      "Epoch 115/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6792.2383 - val_loss: 25028.2969\n",
      "Epoch 116/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6655.2480 - val_loss: 24503.9844\n",
      "Epoch 117/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 6512.4878 - val_loss: 24012.3828\n",
      "Epoch 118/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 6379.3179 - val_loss: 23539.1523\n",
      "Epoch 119/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 6230.5454 - val_loss: 23068.8145\n",
      "Epoch 120/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6102.7158 - val_loss: 22532.6855\n",
      "Epoch 121/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5967.3491 - val_loss: 21973.9141\n",
      "Epoch 122/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5802.6392 - val_loss: 21477.2812\n",
      "Epoch 123/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5667.7129 - val_loss: 21016.1016\n",
      "Epoch 124/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5529.9692 - val_loss: 20569.9590\n",
      "Epoch 125/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5412.4814 - val_loss: 20089.5898\n",
      "Epoch 126/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5275.8677 - val_loss: 19611.7812\n",
      "Epoch 127/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5151.8198 - val_loss: 19108.2070\n",
      "Epoch 128/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5017.2295 - val_loss: 18641.9277\n",
      "Epoch 129/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4884.6133 - val_loss: 18220.1113\n",
      "Epoch 130/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4760.7412 - val_loss: 17827.1602\n",
      "Epoch 131/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4651.9604 - val_loss: 17418.7070\n",
      "Epoch 132/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4535.3252 - val_loss: 16973.5156\n",
      "Epoch 133/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4412.2168 - val_loss: 16508.4863\n",
      "Epoch 134/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4278.9072 - val_loss: 16073.3906\n",
      "Epoch 135/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4159.9424 - val_loss: 15669.8184\n",
      "Epoch 136/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 4046.2444 - val_loss: 15259.6387\n",
      "Epoch 137/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 3937.1885 - val_loss: 14855.9199\n",
      "Epoch 138/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3834.6914 - val_loss: 14477.2168\n",
      "Epoch 139/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3724.5090 - val_loss: 14130.1006\n",
      "Epoch 140/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3632.0352 - val_loss: 13780.9473\n",
      "Epoch 141/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 3542.6953 - val_loss: 13421.1494\n",
      "Epoch 142/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3438.9150 - val_loss: 13078.1533\n",
      "Epoch 143/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3348.7432 - val_loss: 12743.4766\n",
      "Epoch 144/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3257.4902 - val_loss: 12426.0156\n",
      "Epoch 145/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3166.1787 - val_loss: 12113.9512\n",
      "Epoch 146/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3071.1003 - val_loss: 11783.6689\n",
      "Epoch 147/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2982.9736 - val_loss: 11452.1875\n",
      "Epoch 148/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2899.7908 - val_loss: 11132.2959\n",
      "Epoch 149/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2815.0676 - val_loss: 10821.8477\n",
      "Epoch 150/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2730.2732 - val_loss: 10522.1689\n",
      "Epoch 151/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2647.4038 - val_loss: 10242.2422\n",
      "Epoch 152/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2572.4873 - val_loss: 9965.9561\n",
      "Epoch 153/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2500.0911 - val_loss: 9697.1719\n",
      "Epoch 154/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2426.2478 - val_loss: 9428.8809\n",
      "Epoch 155/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2353.2495 - val_loss: 9168.2354\n",
      "Epoch 156/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2280.5632 - val_loss: 8909.1816\n",
      "Epoch 157/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2209.6841 - val_loss: 8637.2832\n",
      "Epoch 158/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2139.8359 - val_loss: 8385.2383\n",
      "Epoch 159/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2071.0315 - val_loss: 8144.6777\n",
      "Epoch 160/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2005.9735 - val_loss: 7897.7480\n",
      "Epoch 161/2000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1945.6328 - val_loss: 7660.7939\n",
      "Epoch 162/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 2129.62 - 0s 20ms/step - loss: 1876.4463 - val_loss: 7434.6562\n",
      "Epoch 163/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1813.1112 - val_loss: 7183.0464\n",
      "Epoch 164/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1749.8750 - val_loss: 6929.8857\n",
      "Epoch 165/2000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1684.8450 - val_loss: 6696.1421\n",
      "Epoch 166/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1620.0134 - val_loss: 6484.3770\n",
      "Epoch 167/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1564.4612 - val_loss: 6270.7534\n",
      "Epoch 168/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1504.0378 - val_loss: 6057.8149\n",
      "Epoch 169/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1450.4939 - val_loss: 5843.2822\n",
      "Epoch 170/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1396.0258 - val_loss: 5639.3613\n",
      "Epoch 171/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1342.7028 - val_loss: 5446.2222\n",
      "Epoch 172/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1288.2040 - val_loss: 5259.0547\n",
      "Epoch 173/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1240.3281 - val_loss: 5078.2061\n",
      "Epoch 174/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1194.3590 - val_loss: 4908.0088\n",
      "Epoch 175/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1148.4612 - val_loss: 4732.7173\n",
      "Epoch 176/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1100.3247 - val_loss: 4546.9268\n",
      "Epoch 177/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1056.4320 - val_loss: 4365.3232\n",
      "Epoch 178/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1007.1617 - val_loss: 4204.8994\n",
      "Epoch 179/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 962.7443 - val_loss: 4044.2646\n",
      "Epoch 180/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 924.6964 - val_loss: 3876.7144\n",
      "Epoch 181/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 880.4321 - val_loss: 3726.3806\n",
      "Epoch 182/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 839.8304 - val_loss: 3572.4683\n",
      "Epoch 183/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 803.2983 - val_loss: 3421.3645\n",
      "Epoch 184/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 768.7377 - val_loss: 3286.7163\n",
      "Epoch 185/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 732.3008 - val_loss: 3168.6169\n",
      "Epoch 186/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 703.8196 - val_loss: 3055.4612\n",
      "Epoch 187/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 675.6331 - val_loss: 2949.1357\n",
      "Epoch 188/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 648.5164 - val_loss: 2839.1587\n",
      "Epoch 189/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 619.5125 - val_loss: 2723.2026\n",
      "Epoch 190/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 590.7811 - val_loss: 2612.5166\n",
      "Epoch 191/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 564.3987 - val_loss: 2501.9414\n",
      "Epoch 192/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 535.9425 - val_loss: 2404.0569\n",
      "Epoch 193/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 510.9968 - val_loss: 2312.5222\n",
      "Epoch 194/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 489.9812 - val_loss: 2219.1716\n",
      "Epoch 195/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 466.1476 - val_loss: 2132.2271\n",
      "Epoch 196/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 445.0335 - val_loss: 2052.3452\n",
      "Epoch 197/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 426.5256 - val_loss: 1976.7565\n",
      "Epoch 198/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 407.2240 - val_loss: 1905.8064\n",
      "Epoch 199/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 389.1265 - val_loss: 1835.2432\n",
      "Epoch 200/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 372.6845 - val_loss: 1759.7538\n",
      "Epoch 201/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 354.0899 - val_loss: 1692.3367\n",
      "Epoch 202/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 338.6547 - val_loss: 1627.0747\n",
      "Epoch 203/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 323.8628 - val_loss: 1565.5348\n",
      "Epoch 204/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 308.8250 - val_loss: 1506.7456\n",
      "Epoch 205/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 294.2649 - val_loss: 1443.6742\n",
      "Epoch 206/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 279.4487 - val_loss: 1381.9854\n",
      "Epoch 207/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 265.8274 - val_loss: 1322.1003\n",
      "Epoch 208/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 251.5303 - val_loss: 1266.6392\n",
      "Epoch 209/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 239.4308 - val_loss: 1216.4592\n",
      "Epoch 210/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 226.7751 - val_loss: 1169.2844\n",
      "Epoch 211/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 215.6567 - val_loss: 1118.9048\n",
      "Epoch 212/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 203.8005 - val_loss: 1072.2454\n",
      "Epoch 213/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 195.0518 - val_loss: 1021.6908\n",
      "Epoch 214/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 182.2554 - val_loss: 977.7629\n",
      "Epoch 215/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 173.2703 - val_loss: 933.5255\n",
      "Epoch 216/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 164.5041 - val_loss: 893.6957\n",
      "Epoch 217/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 154.0172 - val_loss: 858.2772\n",
      "Epoch 218/2000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 146.1125 - val_loss: 820.0641\n",
      "Epoch 219/2000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 139.0094 - val_loss: 783.7480\n",
      "Epoch 220/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 130.6339 - val_loss: 751.1412\n",
      "Epoch 221/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 123.9345 - val_loss: 719.3837\n",
      "Epoch 222/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 117.3828 - val_loss: 690.6162\n",
      "Epoch 223/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 111.6321 - val_loss: 664.1204\n",
      "Epoch 224/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 105.6918 - val_loss: 640.2274\n",
      "Epoch 225/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 100.7280 - val_loss: 617.3567\n",
      "Epoch 226/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 95.9304 - val_loss: 594.4828\n",
      "Epoch 227/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 91.5269 - val_loss: 570.7896\n",
      "Epoch 228/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 86.4327 - val_loss: 549.9764\n",
      "Epoch 229/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 13ms/step - loss: 82.2472 - val_loss: 530.6674\n",
      "Epoch 230/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 78.8574 - val_loss: 511.8506\n",
      "Epoch 231/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 74.6615 - val_loss: 494.3171\n",
      "Epoch 232/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 71.0640 - val_loss: 475.7943\n",
      "Epoch 233/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 67.6200 - val_loss: 457.2656\n",
      "Epoch 234/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 64.3794 - val_loss: 438.2121\n",
      "Epoch 235/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 60.4653 - val_loss: 420.5482\n",
      "Epoch 236/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 56.7532 - val_loss: 403.2802\n",
      "Epoch 237/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 54.1705 - val_loss: 385.7971\n",
      "Epoch 238/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 50.4302 - val_loss: 370.9681\n",
      "Epoch 239/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 47.9671 - val_loss: 356.2426\n",
      "Epoch 240/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 45.4077 - val_loss: 342.6591\n",
      "Epoch 241/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 42.9187 - val_loss: 329.9078\n",
      "Epoch 242/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 40.9403 - val_loss: 317.9933\n",
      "Epoch 243/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 38.8830 - val_loss: 307.1072\n",
      "Epoch 244/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 36.6808 - val_loss: 297.4892\n",
      "Epoch 245/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 35.1249 - val_loss: 288.1244\n",
      "Epoch 246/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 33.4012 - val_loss: 279.4152\n",
      "Epoch 247/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 31.9297 - val_loss: 270.2101\n",
      "Epoch 248/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 30.6673 - val_loss: 260.0678\n",
      "Epoch 249/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 28.7526 - val_loss: 250.1842\n",
      "Epoch 250/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 27.3364 - val_loss: 239.5310\n",
      "Epoch 251/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 25.6175 - val_loss: 230.4533\n",
      "Epoch 252/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 24.2223 - val_loss: 222.1555\n",
      "Epoch 253/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 22.9376 - val_loss: 214.7694\n",
      "Epoch 254/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 21.7486 - val_loss: 207.3722\n",
      "Epoch 255/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 20.8962 - val_loss: 198.9002\n",
      "Epoch 256/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 19.6261 - val_loss: 191.5365\n",
      "Epoch 257/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 18.3516 - val_loss: 184.8026\n",
      "Epoch 258/2000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 17.3817 - val_loss: 177.4188\n",
      "Epoch 259/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 16.5613 - val_loss: 170.4132\n",
      "Epoch 260/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 15.5925 - val_loss: 164.6493\n",
      "Epoch 261/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 14.8159 - val_loss: 159.3361\n",
      "Epoch 262/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 14.0784 - val_loss: 153.6427\n",
      "Epoch 263/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 13.4618 - val_loss: 148.7264\n",
      "Epoch 264/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 12.8883 - val_loss: 144.4268\n",
      "Epoch 265/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 12.3612 - val_loss: 140.6349\n",
      "Epoch 266/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 11.9196 - val_loss: 137.1684\n",
      "Epoch 267/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 11.5991 - val_loss: 133.7747\n",
      "Epoch 268/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 11.1766 - val_loss: 130.6982\n",
      "Epoch 269/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 10.8496 - val_loss: 127.5235\n",
      "Epoch 270/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 10.4827 - val_loss: 124.7123\n",
      "Epoch 271/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 10.1573 - val_loss: 122.1445\n",
      "Epoch 272/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 9.9500 - val_loss: 119.4884\n",
      "Epoch 273/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 9.6539 - val_loss: 116.9741\n",
      "Epoch 274/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 9.3884 - val_loss: 114.3961\n",
      "Epoch 275/2000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 9.1454 - val_loss: 111.9849\n",
      "Epoch 276/2000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 8.8514 - val_loss: 109.6843\n",
      "Epoch 277/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 8.6095 - val_loss: 106.7350\n",
      "Epoch 278/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 8.3026 - val_loss: 104.0833\n",
      "Epoch 279/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 8.0343 - val_loss: 100.9388\n",
      "Epoch 280/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 7.7159 - val_loss: 97.4866\n",
      "Epoch 281/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 7.4706 - val_loss: 94.1210\n",
      "Epoch 282/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 7.2498 - val_loss: 91.3286\n",
      "Epoch 283/2000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 7.0252 - val_loss: 88.9688\n",
      "Epoch 284/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 6.8270 - val_loss: 87.1337\n",
      "Epoch 285/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.7150 - val_loss: 85.4631\n",
      "Epoch 286/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.5660 - val_loss: 84.0196\n",
      "Epoch 287/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.4674 - val_loss: 82.3149\n",
      "Epoch 288/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.3373 - val_loss: 80.7471\n",
      "Epoch 289/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 6.2374 - val_loss: 78.9308\n",
      "Epoch 290/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 6.1752 - val_loss: 77.3712\n",
      "Epoch 291/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 6.0618 - val_loss: 76.1213\n",
      "Epoch 292/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 5.9637 - val_loss: 75.0880\n",
      "Epoch 293/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 5.8963 - val_loss: 74.1653\n",
      "Epoch 294/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 5.8440 - val_loss: 73.2836\n",
      "Epoch 295/2000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 5.8034 - val_loss: 72.4710\n",
      "Epoch 296/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 5.7438 - val_loss: 71.7742\n",
      "Epoch 297/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 5.6990 - val_loss: 70.5839\n",
      "Epoch 298/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 5.5931 - val_loss: 69.1512\n",
      "Epoch 299/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 5.5849 - val_loss: 67.6750\n",
      "Epoch 300/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 5.4951 - val_loss: 66.6291\n",
      "Epoch 301/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 5.4375 - val_loss: 65.7195\n",
      "Epoch 302/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 5.3941 - val_loss: 64.9389\n",
      "Epoch 303/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 5.3595 - val_loss: 64.2357\n",
      "Epoch 304/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.3202 - val_loss: 63.6442\n",
      "Epoch 305/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.2891 - val_loss: 62.9273\n",
      "Epoch 306/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.2543 - val_loss: 61.8701\n",
      "Epoch 307/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.2037 - val_loss: 61.1319\n",
      "Epoch 308/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.1901 - val_loss: 60.3217\n",
      "Epoch 309/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.1489 - val_loss: 59.7800\n",
      "Epoch 310/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.1205 - val_loss: 59.3884\n",
      "Epoch 311/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.1011 - val_loss: 58.9302\n",
      "Epoch 312/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 5.0946 - val_loss: 57.9990\n",
      "Epoch 313/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 5.0467 - val_loss: 57.3373\n",
      "Epoch 314/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 5.0367 - val_loss: 56.6381\n",
      "Epoch 315/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 4.9985 - val_loss: 56.0376\n",
      "Epoch 316/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 4.9725 - val_loss: 55.1723\n",
      "Epoch 317/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 4.9686 - val_loss: 54.4639\n",
      "Epoch 318/2000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 4.9232 - val_loss: 54.0890\n",
      "Epoch 319/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4.9088 - val_loss: 53.6412\n",
      "Epoch 320/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.8944 - val_loss: 52.9686\n",
      "Epoch 321/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.8744 - val_loss: 52.4931\n",
      "Epoch 322/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.8665 - val_loss: 52.0982\n",
      "Epoch 323/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.8582 - val_loss: 51.8132\n",
      "Epoch 324/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.8370 - val_loss: 51.7071\n",
      "Epoch 325/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.8291 - val_loss: 51.5453\n",
      "Epoch 326/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.8190 - val_loss: 51.4793\n",
      "Epoch 327/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.8095 - val_loss: 51.4457\n",
      "Epoch 328/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.7988 - val_loss: 51.5714\n",
      "Epoch 329/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.7912 - val_loss: 51.6804\n",
      "Epoch 330/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.7915 - val_loss: 51.7814\n",
      "Epoch 331/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.7765 - val_loss: 51.6652\n",
      "Epoch 332/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4.7676 - val_loss: 51.5905\n",
      "Epoch 333/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.7580 - val_loss: 51.6010\n",
      "Epoch 334/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.7509 - val_loss: 51.5575\n",
      "Epoch 335/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.7416 - val_loss: 51.4861\n",
      "Epoch 336/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.7341 - val_loss: 51.3790\n",
      "Epoch 337/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4.7242 - val_loss: 51.3973\n",
      "Epoch 338/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.7158 - val_loss: 51.4314\n",
      "Epoch 339/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4.7089 - val_loss: 51.4234\n",
      "Epoch 340/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.7000 - val_loss: 51.3584\n",
      "Epoch 341/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.6920 - val_loss: 51.2463\n",
      "Epoch 342/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.6795 - val_loss: 50.9061\n",
      "Epoch 343/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.6701 - val_loss: 50.6899\n",
      "Epoch 344/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.6556 - val_loss: 50.5700\n",
      "Epoch 345/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.6445 - val_loss: 50.4417\n",
      "Epoch 346/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.6347 - val_loss: 50.4889\n",
      "Epoch 347/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.6292 - val_loss: 50.4659\n",
      "Epoch 348/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.6233 - val_loss: 49.8882\n",
      "Epoch 349/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.6218 - val_loss: 49.2804\n",
      "Epoch 350/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.5875 - val_loss: 49.0744\n",
      "Epoch 351/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.5797 - val_loss: 48.9715\n",
      "Epoch 352/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 4.5639 - val_loss: 48.6199\n",
      "Epoch 353/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 4.5606 - val_loss: 48.2929\n",
      "Epoch 354/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4.5472 - val_loss: 48.2613\n",
      "Epoch 355/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.5371 - val_loss: 48.2680\n",
      "Epoch 356/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.5311 - val_loss: 48.4335\n",
      "Epoch 357/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.5229 - val_loss: 48.4128\n",
      "Epoch 358/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4.5159 - val_loss: 47.9632\n",
      "Epoch 359/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.5027 - val_loss: 47.6675\n",
      "Epoch 360/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.4917 - val_loss: 47.5068\n",
      "Epoch 361/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4.4825 - val_loss: 47.4502\n",
      "Epoch 362/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4.4739 - val_loss: 47.4117\n",
      "Epoch 363/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.4691 - val_loss: 47.3952\n",
      "Epoch 364/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.4601 - val_loss: 47.1885\n",
      "Epoch 365/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.4489 - val_loss: 46.9945\n",
      "Epoch 366/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.4351 - val_loss: 46.3158\n",
      "Epoch 367/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4.4078 - val_loss: 45.4438\n",
      "Epoch 368/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.4129 - val_loss: 44.4716\n",
      "Epoch 369/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.4053 - val_loss: 43.9236\n",
      "Epoch 370/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4.4077 - val_loss: 43.4205\n",
      "Epoch 371/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.3975 - val_loss: 43.0039\n",
      "Epoch 372/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 4.3885 - val_loss: 42.7875\n",
      "Epoch 373/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 4.3813 - val_loss: 42.5844\n",
      "Epoch 374/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 4.3722 - val_loss: 42.6059\n",
      "Epoch 375/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 4.3634 - val_loss: 42.5874\n",
      "Epoch 376/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 4.3513 - val_loss: 42.6589\n",
      "Epoch 377/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 4.3418 - val_loss: 42.7645\n",
      "Epoch 378/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.3298 - val_loss: 42.9182\n",
      "Epoch 379/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.3263 - val_loss: 43.2186\n",
      "Epoch 380/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.3077 - val_loss: 43.3437\n",
      "Epoch 381/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.3011 - val_loss: 43.3951\n",
      "Epoch 382/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.2901 - val_loss: 43.1794\n",
      "Epoch 383/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.2851 - val_loss: 42.7052\n",
      "Epoch 384/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4.2760 - val_loss: 42.4975\n",
      "Epoch 385/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.2654 - val_loss: 42.2843\n",
      "Epoch 386/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.2598 - val_loss: 42.1322\n",
      "Epoch 387/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.2498 - val_loss: 42.1106\n",
      "Epoch 388/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.2406 - val_loss: 42.2507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.2271 - val_loss: 42.3857\n",
      "Epoch 390/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.2163 - val_loss: 42.5889\n",
      "Epoch 391/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.1997 - val_loss: 42.8519\n",
      "Epoch 392/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.1973 - val_loss: 43.2921\n",
      "Epoch 393/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.1880 - val_loss: 43.7574\n",
      "Epoch 394/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4.1844 - val_loss: 44.1913\n",
      "Epoch 395/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.1596 - val_loss: 44.4505\n",
      "Epoch 396/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4.1542 - val_loss: 44.8114\n",
      "Epoch 397/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.1502 - val_loss: 45.0570\n",
      "Epoch 398/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.1399 - val_loss: 44.7499\n",
      "Epoch 399/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4.1255 - val_loss: 44.6283\n",
      "Epoch 400/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4.1154 - val_loss: 44.5156\n",
      "Epoch 401/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4.1072 - val_loss: 44.4255\n",
      "Epoch 402/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.0974 - val_loss: 44.4664\n",
      "Epoch 403/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4.0910 - val_loss: 44.6418\n",
      "Epoch 404/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4.0795 - val_loss: 44.6887\n",
      "Epoch 405/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.0717 - val_loss: 44.7461\n",
      "Epoch 406/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4.0629 - val_loss: 44.7125\n",
      "Epoch 407/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.0552 - val_loss: 44.6082\n",
      "Epoch 408/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4.0470 - val_loss: 44.6814\n",
      "Epoch 409/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4.0364 - val_loss: 44.8054\n",
      "Epoch 410/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.0287 - val_loss: 44.8556\n",
      "Epoch 411/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 4.0214 - val_loss: 44.9218\n",
      "Epoch 412/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 4.0124 - val_loss: 45.0049\n",
      "Epoch 413/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4.0100 - val_loss: 45.1510\n",
      "Epoch 414/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.9964 - val_loss: 44.9439\n",
      "Epoch 415/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.9886 - val_loss: 44.7863\n",
      "Epoch 416/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.9801 - val_loss: 44.7531\n",
      "Epoch 417/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.9744 - val_loss: 44.6804\n",
      "Epoch 418/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.9638 - val_loss: 44.6701\n",
      "Epoch 419/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.9566 - val_loss: 44.6030\n",
      "Epoch 420/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.9472 - val_loss: 44.5653\n",
      "Epoch 421/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.9396 - val_loss: 44.1814\n",
      "Epoch 422/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.9245 - val_loss: 43.8120\n",
      "Epoch 423/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.9160 - val_loss: 43.5935\n",
      "Epoch 424/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.9101 - val_loss: 43.3253\n",
      "Epoch 425/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.9010 - val_loss: 43.1825\n",
      "Epoch 426/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.8917 - val_loss: 43.2344\n",
      "Epoch 427/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 3.8840 - val_loss: 43.1820\n",
      "Epoch 428/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.8744 - val_loss: 42.8496\n",
      "Epoch 429/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.8699 - val_loss: 42.5997\n",
      "Epoch 430/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.8569 - val_loss: 42.5154\n",
      "Epoch 431/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.8501 - val_loss: 42.4087\n",
      "Epoch 432/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.8426 - val_loss: 42.4414\n",
      "Epoch 433/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.8355 - val_loss: 42.3627\n",
      "Epoch 434/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.8286 - val_loss: 42.4352\n",
      "Epoch 435/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.8179 - val_loss: 42.5315\n",
      "Epoch 436/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.8150 - val_loss: 42.7492\n",
      "Epoch 437/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.8083 - val_loss: 42.7731\n",
      "Epoch 438/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.8029 - val_loss: 42.3430\n",
      "Epoch 439/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.7881 - val_loss: 42.2673\n",
      "Epoch 440/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.7807 - val_loss: 42.2255\n",
      "Epoch 441/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.7693 - val_loss: 41.7424\n",
      "Epoch 442/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 3.7590 - val_loss: 41.3153\n",
      "Epoch 443/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.7521 - val_loss: 40.8787\n",
      "Epoch 444/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.7433 - val_loss: 40.6202\n",
      "Epoch 445/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.7361 - val_loss: 40.3257\n",
      "Epoch 446/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.7293 - val_loss: 39.7947\n",
      "Epoch 447/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.7231 - val_loss: 39.6247\n",
      "Epoch 448/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.7160 - val_loss: 39.6050\n",
      "Epoch 449/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.7048 - val_loss: 39.6999\n",
      "Epoch 450/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.6949 - val_loss: 39.9779\n",
      "Epoch 451/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.6821 - val_loss: 40.1617\n",
      "Epoch 452/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.6772 - val_loss: 40.3539\n",
      "Epoch 453/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.6649 - val_loss: 40.3964\n",
      "Epoch 454/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.6581 - val_loss: 40.5133\n",
      "Epoch 455/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.6486 - val_loss: 40.6630\n",
      "Epoch 456/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.6383 - val_loss: 40.7697\n",
      "Epoch 457/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.6318 - val_loss: 40.8680\n",
      "Epoch 458/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.6224 - val_loss: 40.8710\n",
      "Epoch 459/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.6140 - val_loss: 40.8627\n",
      "Epoch 460/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.6093 - val_loss: 41.0007\n",
      "Epoch 461/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.5982 - val_loss: 41.1299\n",
      "Epoch 462/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.5928 - val_loss: 41.2286\n",
      "Epoch 463/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.5842 - val_loss: 41.1407\n",
      "Epoch 464/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.5762 - val_loss: 41.0379\n",
      "Epoch 465/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.5689 - val_loss: 40.8891\n",
      "Epoch 466/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.5619 - val_loss: 40.8000\n",
      "Epoch 467/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.5594 - val_loss: 40.5095\n",
      "Epoch 468/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.5470 - val_loss: 40.5190\n",
      "Epoch 469/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.5406 - val_loss: 40.7246\n",
      "Epoch 470/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.5293 - val_loss: 40.9318\n",
      "Epoch 471/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.5326 - val_loss: 41.2296\n",
      "Epoch 472/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.5215 - val_loss: 41.2046\n",
      "Epoch 473/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.5126 - val_loss: 41.4013\n",
      "Epoch 474/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.5059 - val_loss: 41.3943\n",
      "Epoch 475/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.4973 - val_loss: 40.9130\n",
      "Epoch 476/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 3.4819 - val_loss: 40.6023\n",
      "Epoch 477/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.4816 - val_loss: 40.1742\n",
      "Epoch 478/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.4702 - val_loss: 40.0546\n",
      "Epoch 479/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.4606 - val_loss: 40.1477\n",
      "Epoch 480/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 3.4521 - val_loss: 40.3276\n",
      "Epoch 481/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3.4513 - val_loss: 40.6662\n",
      "Epoch 482/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3.4408 - val_loss: 40.9051\n",
      "Epoch 483/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.4341 - val_loss: 41.2059\n",
      "Epoch 484/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.4254 - val_loss: 41.4489\n",
      "Epoch 485/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.4262 - val_loss: 41.4944\n",
      "Epoch 486/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.4208 - val_loss: 40.9940\n",
      "Epoch 487/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.4025 - val_loss: 40.7157\n",
      "Epoch 488/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.3940 - val_loss: 40.4406\n",
      "Epoch 489/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.3916 - val_loss: 40.1853\n",
      "Epoch 490/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.3830 - val_loss: 40.1782\n",
      "Epoch 491/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.3757 - val_loss: 40.1918\n",
      "Epoch 492/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.3693 - val_loss: 40.3610\n",
      "Epoch 493/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.3596 - val_loss: 40.5988\n",
      "Epoch 494/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.3592 - val_loss: 40.9920\n",
      "Epoch 495/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.3537 - val_loss: 41.3328\n",
      "Epoch 496/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.3481 - val_loss: 41.4675\n",
      "Epoch 497/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.3435 - val_loss: 41.4269\n",
      "Epoch 498/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.3364 - val_loss: 41.4863\n",
      "Epoch 499/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.3364 - val_loss: 41.7522\n",
      "Epoch 500/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.3400 - val_loss: 41.8974\n",
      "Epoch 501/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.3264 - val_loss: 41.3696\n",
      "Epoch 502/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.3241 - val_loss: 40.9472\n",
      "Epoch 503/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.3008 - val_loss: 40.8841\n",
      "Epoch 504/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.2940 - val_loss: 40.8823\n",
      "Epoch 505/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.2868 - val_loss: 40.7287\n",
      "Epoch 506/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.2786 - val_loss: 40.7540\n",
      "Epoch 507/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.2731 - val_loss: 40.8865\n",
      "Epoch 508/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.2767 - val_loss: 41.1439\n",
      "Epoch 509/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.2655 - val_loss: 41.2456\n",
      "Epoch 510/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.2615 - val_loss: 41.3930\n",
      "Epoch 511/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.2578 - val_loss: 41.3393\n",
      "Epoch 512/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.2492 - val_loss: 41.4005\n",
      "Epoch 513/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.2476 - val_loss: 41.5768\n",
      "Epoch 514/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.2407 - val_loss: 41.5731\n",
      "Epoch 515/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.2351 - val_loss: 41.6530\n",
      "Epoch 516/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.2309 - val_loss: 41.7024\n",
      "Epoch 517/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 3.2285 - val_loss: 41.5429\n",
      "Epoch 518/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.2197 - val_loss: 41.5387\n",
      "Epoch 519/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.2104 - val_loss: 41.4849\n",
      "Epoch 520/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.2052 - val_loss: 41.4449\n",
      "Epoch 521/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.1991 - val_loss: 41.3877\n",
      "Epoch 522/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.1885 - val_loss: 41.0094\n",
      "Epoch 523/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.1796 - val_loss: 40.8445\n",
      "Epoch 524/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.1720 - val_loss: 40.7929\n",
      "Epoch 525/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.1670 - val_loss: 40.7342\n",
      "Epoch 526/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.1623 - val_loss: 40.6216\n",
      "Epoch 527/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.1488 - val_loss: 40.1968\n",
      "Epoch 528/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.1477 - val_loss: 39.7868\n",
      "Epoch 529/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.1346 - val_loss: 39.5676\n",
      "Epoch 530/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.1254 - val_loss: 39.3534\n",
      "Epoch 531/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.1189 - val_loss: 39.3091\n",
      "Epoch 532/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.1146 - val_loss: 39.2424\n",
      "Epoch 533/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3.1081 - val_loss: 39.3433\n",
      "Epoch 534/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.1002 - val_loss: 39.4414\n",
      "Epoch 535/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.0980 - val_loss: 39.5714\n",
      "Epoch 536/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 3.0898 - val_loss: 39.5131\n",
      "Epoch 537/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.0825 - val_loss: 39.5529\n",
      "Epoch 538/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 3.0765 - val_loss: 39.5554\n",
      "Epoch 539/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.0714 - val_loss: 39.6235\n",
      "Epoch 540/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 3.0666 - val_loss: 39.3670\n",
      "Epoch 541/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3.0556 - val_loss: 39.2491\n",
      "Epoch 542/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3.0506 - val_loss: 39.3945\n",
      "Epoch 543/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.0412 - val_loss: 39.4769\n",
      "Epoch 544/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 3.0364 - val_loss: 39.5113\n",
      "Epoch 545/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3.0352 - val_loss: 39.6335\n",
      "Epoch 546/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.0295 - val_loss: 39.5649\n",
      "Epoch 547/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 3.0291 - val_loss: 39.1776\n",
      "Epoch 548/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.0125 - val_loss: 39.0257\n",
      "Epoch 549/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 14ms/step - loss: 3.0055 - val_loss: 38.6047\n",
      "Epoch 550/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.9987 - val_loss: 38.3012\n",
      "Epoch 551/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.9888 - val_loss: 38.1882\n",
      "Epoch 552/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.9831 - val_loss: 38.1492\n",
      "Epoch 553/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.9826 - val_loss: 38.1954\n",
      "Epoch 554/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.9785 - val_loss: 38.0374\n",
      "Epoch 555/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.9719 - val_loss: 38.1795\n",
      "Epoch 556/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.9690 - val_loss: 38.0901\n",
      "Epoch 557/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.9583 - val_loss: 37.4032\n",
      "Epoch 558/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.9501 - val_loss: 36.9299\n",
      "Epoch 559/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.9406 - val_loss: 36.8208\n",
      "Epoch 560/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.9328 - val_loss: 36.6122\n",
      "Epoch 561/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.9265 - val_loss: 36.4781\n",
      "Epoch 562/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.9198 - val_loss: 36.2460\n",
      "Epoch 563/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.9117 - val_loss: 35.8283\n",
      "Epoch 564/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.9060 - val_loss: 35.1987\n",
      "Epoch 565/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.9045 - val_loss: 34.6615\n",
      "Epoch 566/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.8967 - val_loss: 34.2263\n",
      "Epoch 567/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2.8950 - val_loss: 33.9386\n",
      "Epoch 568/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2.8883 - val_loss: 33.5097\n",
      "Epoch 569/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2.8903 - val_loss: 33.1607\n",
      "Epoch 570/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.8786 - val_loss: 32.8897\n",
      "Epoch 571/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.8782 - val_loss: 32.5479\n",
      "Epoch 572/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.8832 - val_loss: 32.2890\n",
      "Epoch 573/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.8751 - val_loss: 32.1497\n",
      "Epoch 574/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.8703 - val_loss: 32.1472\n",
      "Epoch 575/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.8637 - val_loss: 32.1628\n",
      "Epoch 576/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.8632 - val_loss: 32.1650\n",
      "Epoch 577/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.8526 - val_loss: 31.8012\n",
      "Epoch 578/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.8523 - val_loss: 31.8756\n",
      "Epoch 579/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.8400 - val_loss: 32.0839\n",
      "Epoch 580/2000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.8298 - val_loss: 32.4154\n",
      "Epoch 581/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.8161 - val_loss: 32.7129\n",
      "Epoch 582/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.8128 - val_loss: 33.1335\n",
      "Epoch 583/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.7999 - val_loss: 33.4203\n",
      "Epoch 584/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.7984 - val_loss: 33.8280\n",
      "Epoch 585/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.7955 - val_loss: 34.0169\n",
      "Epoch 586/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.7838 - val_loss: 33.8616\n",
      "Epoch 587/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.7807 - val_loss: 33.6394\n",
      "Epoch 588/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.7760 - val_loss: 33.5737\n",
      "Epoch 589/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.7706 - val_loss: 33.5544\n",
      "Epoch 590/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.7637 - val_loss: 33.6989\n",
      "Epoch 591/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.7590 - val_loss: 33.8391\n",
      "Epoch 592/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.7525 - val_loss: 34.0159\n",
      "Epoch 593/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.7546 - val_loss: 34.3482\n",
      "Epoch 594/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.7463 - val_loss: 34.3691\n",
      "Epoch 595/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.7424 - val_loss: 34.0698\n",
      "Epoch 596/2000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.7344 - val_loss: 34.0006\n",
      "Epoch 597/2000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.7278 - val_loss: 33.9974\n",
      "Epoch 598/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.7244 - val_loss: 34.1368\n",
      "Epoch 599/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2.7191 - val_loss: 34.3531\n",
      "Epoch 600/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2.7132 - val_loss: 34.5685\n",
      "Epoch 601/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.7112 - val_loss: 34.5558\n",
      "Epoch 602/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.7050 - val_loss: 34.1497\n",
      "Epoch 603/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.7002 - val_loss: 33.6956\n",
      "Epoch 604/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.6967 - val_loss: 33.3432\n",
      "Epoch 605/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.6896 - val_loss: 33.0471\n",
      "Epoch 606/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.6854 - val_loss: 32.9757\n",
      "Epoch 607/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.6813 - val_loss: 32.9089\n",
      "Epoch 608/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.6786 - val_loss: 32.8369\n",
      "Epoch 609/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.6743 - val_loss: 32.9877\n",
      "Epoch 610/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.6648 - val_loss: 33.2175\n",
      "Epoch 611/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.6716 - val_loss: 33.6670\n",
      "Epoch 612/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.6584 - val_loss: 33.8096\n",
      "Epoch 613/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.6605 - val_loss: 33.8008\n",
      "Epoch 614/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.6525 - val_loss: 33.5165\n",
      "Epoch 615/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.6465 - val_loss: 33.2524\n",
      "Epoch 616/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.6423 - val_loss: 32.7777\n",
      "Epoch 617/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.6381 - val_loss: 32.5812\n",
      "Epoch 618/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.6391 - val_loss: 32.3254\n",
      "Epoch 619/2000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2.6322 - val_loss: 32.2998\n",
      "Epoch 620/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2.6264 - val_loss: 32.2979\n",
      "Epoch 621/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.6211 - val_loss: 32.4375\n",
      "Epoch 622/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.6157 - val_loss: 32.7062\n",
      "Epoch 623/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.6154 - val_loss: 33.1088\n",
      "Epoch 624/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.6271 - val_loss: 33.4418\n",
      "Epoch 625/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.6085 - val_loss: 33.4105\n",
      "Epoch 626/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.6060 - val_loss: 33.4592\n",
      "Epoch 627/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.6019 - val_loss: 33.2779\n",
      "Epoch 628/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.6053 - val_loss: 33.0705\n",
      "Epoch 629/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.5935 - val_loss: 33.2410\n",
      "Epoch 630/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.5929 - val_loss: 33.5562\n",
      "Epoch 631/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.5905 - val_loss: 33.9375\n",
      "Epoch 632/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.5892 - val_loss: 34.2768\n",
      "Epoch 633/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.5891 - val_loss: 34.3317\n",
      "Epoch 634/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.5827 - val_loss: 33.9334\n",
      "Epoch 635/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.5727 - val_loss: 33.6089\n",
      "Epoch 636/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.5580 - val_loss: 32.9084\n",
      "Epoch 637/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.5635 - val_loss: 31.9463\n",
      "Epoch 638/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.5465 - val_loss: 31.5176\n",
      "Epoch 639/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.5523 - val_loss: 31.0604\n",
      "Epoch 640/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.5514 - val_loss: 30.6045\n",
      "Epoch 641/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.5400 - val_loss: 30.3657\n",
      "Epoch 642/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.5416 - val_loss: 30.1717\n",
      "Epoch 643/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.5391 - val_loss: 30.1213\n",
      "Epoch 644/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.5313 - val_loss: 29.6234\n",
      "Epoch 645/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.5293 - val_loss: 29.3877\n",
      "Epoch 646/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.5268 - val_loss: 29.4141\n",
      "Epoch 647/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.5211 - val_loss: 29.4863\n",
      "Epoch 648/2000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.5174 - val_loss: 29.5110\n",
      "Epoch 649/2000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.5120 - val_loss: 29.6299\n",
      "Epoch 650/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.5042 - val_loss: 29.9563\n",
      "Epoch 651/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.5062 - val_loss: 30.4196\n",
      "Epoch 652/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.4942 - val_loss: 30.7665\n",
      "Epoch 653/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.4935 - val_loss: 30.9736\n",
      "Epoch 654/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.4861 - val_loss: 31.0174\n",
      "Epoch 655/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.4786 - val_loss: 31.1691\n",
      "Epoch 656/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.4756 - val_loss: 31.3613\n",
      "Epoch 657/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.4777 - val_loss: 31.3990\n",
      "Epoch 658/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.4701 - val_loss: 30.9173\n",
      "Epoch 659/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.4624 - val_loss: 30.7769\n",
      "Epoch 660/2000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2.4608 - val_loss: 30.4647\n",
      "Epoch 661/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.4540 - val_loss: 30.2644\n",
      "Epoch 662/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.4540 - val_loss: 29.8757\n",
      "Epoch 663/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.4474 - val_loss: 29.8444\n",
      "Epoch 664/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.4437 - val_loss: 29.7723\n",
      "Epoch 665/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.4411 - val_loss: 29.8108\n",
      "Epoch 666/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.4359 - val_loss: 30.0116\n",
      "Epoch 667/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.4308 - val_loss: 29.9135\n",
      "Epoch 668/2000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.4294 - val_loss: 30.0059\n",
      "Epoch 669/2000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.4215 - val_loss: 30.1346\n",
      "Epoch 670/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.4141 - val_loss: 30.3572\n",
      "Epoch 671/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.4100 - val_loss: 30.5382\n",
      "Epoch 672/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.4112 - val_loss: 30.8035\n",
      "Epoch 673/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.4095 - val_loss: 30.9668\n",
      "Epoch 674/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.4033 - val_loss: 31.0224\n",
      "Epoch 675/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.4082 - val_loss: 31.2796\n",
      "Epoch 676/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.3983 - val_loss: 31.3274\n",
      "Epoch 677/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.3959 - val_loss: 31.3692\n",
      "Epoch 678/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.3938 - val_loss: 31.4713\n",
      "Epoch 679/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.3934 - val_loss: 31.6172\n",
      "Epoch 680/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.3913 - val_loss: 31.7347\n",
      "Epoch 681/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.3889 - val_loss: 31.6878\n",
      "Epoch 682/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.3858 - val_loss: 31.6800\n",
      "Epoch 683/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.3840 - val_loss: 31.7949\n",
      "Epoch 684/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2.3810 - val_loss: 31.8748\n",
      "Epoch 685/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.3875 - val_loss: 32.1379\n",
      "Epoch 686/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.3808 - val_loss: 32.2529\n",
      "Epoch 687/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.3865 - val_loss: 32.3753\n",
      "Epoch 688/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.3864 - val_loss: 31.8687\n",
      "Epoch 689/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.3713 - val_loss: 31.4940\n",
      "Epoch 690/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.3638 - val_loss: 31.3912\n",
      "Epoch 691/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.3544 - val_loss: 31.0544\n",
      "Epoch 692/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.3545 - val_loss: 30.7972\n",
      "Epoch 693/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.3467 - val_loss: 30.7884\n",
      "Epoch 694/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.3431 - val_loss: 30.7310\n",
      "Epoch 695/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.3431 - val_loss: 30.5527\n",
      "Epoch 696/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.3351 - val_loss: 30.5479\n",
      "Epoch 697/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.3310 - val_loss: 30.3775\n",
      "Epoch 698/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.3300 - val_loss: 30.1656\n",
      "Epoch 699/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.3233 - val_loss: 30.1801\n",
      "Epoch 700/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.3222 - val_loss: 30.2696\n",
      "Epoch 701/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.3227 - val_loss: 30.2870\n",
      "Epoch 702/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.3123 - val_loss: 29.9884\n",
      "Epoch 703/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.3097 - val_loss: 29.8448\n",
      "Epoch 704/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.3094 - val_loss: 29.6097\n",
      "Epoch 705/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.3019 - val_loss: 29.5948\n",
      "Epoch 706/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.3057 - val_loss: 29.6115\n",
      "Epoch 707/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.2960 - val_loss: 29.0284\n",
      "Epoch 708/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.2913 - val_loss: 28.6754\n",
      "Epoch 709/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 18ms/step - loss: 2.2857 - val_loss: 28.4468\n",
      "Epoch 710/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.2799 - val_loss: 27.9138\n",
      "Epoch 711/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.2794 - val_loss: 27.8058\n",
      "Epoch 712/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.2753 - val_loss: 27.8300\n",
      "Epoch 713/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.2684 - val_loss: 27.9885\n",
      "Epoch 714/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.2695 - val_loss: 28.1934\n",
      "Epoch 715/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.2641 - val_loss: 28.2192\n",
      "Epoch 716/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.2612 - val_loss: 28.1466\n",
      "Epoch 717/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.2661 - val_loss: 27.8756\n",
      "Epoch 718/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.2580 - val_loss: 27.7890\n",
      "Epoch 719/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.2539 - val_loss: 27.8988\n",
      "Epoch 720/2000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2.2513 - val_loss: 27.7114\n",
      "Epoch 721/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.2431 - val_loss: 27.2050\n",
      "Epoch 722/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.2491 - val_loss: 26.9238\n",
      "Epoch 723/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.2458 - val_loss: 26.7815\n",
      "Epoch 724/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.2410 - val_loss: 26.8228\n",
      "Epoch 725/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.2386 - val_loss: 26.9309\n",
      "Epoch 726/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.2347 - val_loss: 27.1816\n",
      "Epoch 727/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.2353 - val_loss: 27.5089\n",
      "Epoch 728/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.2284 - val_loss: 27.5942\n",
      "Epoch 729/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.2346 - val_loss: 27.7532\n",
      "Epoch 730/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.2170 - val_loss: 27.3321\n",
      "Epoch 731/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.2197 - val_loss: 26.8420\n",
      "Epoch 732/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.2144 - val_loss: 26.6441\n",
      "Epoch 733/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.2152 - val_loss: 26.6126\n",
      "Epoch 734/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.2109 - val_loss: 26.8866\n",
      "Epoch 735/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.699 - 0s 18ms/step - loss: 2.2071 - val_loss: 27.1847\n",
      "Epoch 736/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.2001 - val_loss: 27.5377\n",
      "Epoch 737/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.2018 - val_loss: 27.9998\n",
      "Epoch 738/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.2091 - val_loss: 28.3996\n",
      "Epoch 739/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2.1989 - val_loss: 28.4770\n",
      "Epoch 740/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.2002 - val_loss: 28.5625\n",
      "Epoch 741/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.1963 - val_loss: 28.4924\n",
      "Epoch 742/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.1971 - val_loss: 28.2999\n",
      "Epoch 743/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.1920 - val_loss: 28.2619\n",
      "Epoch 744/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.1889 - val_loss: 28.3283\n",
      "Epoch 745/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.1900 - val_loss: 28.5124\n",
      "Epoch 746/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.1886 - val_loss: 28.5478\n",
      "Epoch 747/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.1885 - val_loss: 28.4215\n",
      "Epoch 748/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.1786 - val_loss: 27.9665\n",
      "Epoch 749/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.1763 - val_loss: 27.6921\n",
      "Epoch 750/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.1757 - val_loss: 27.4419\n",
      "Epoch 751/2000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 2.1674 - val_loss: 27.3250\n",
      "Epoch 752/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.1628 - val_loss: 26.9435\n",
      "Epoch 753/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.1756 - val_loss: 26.1359\n",
      "Epoch 754/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.1598 - val_loss: 25.7945\n",
      "Epoch 755/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.1551 - val_loss: 25.4375\n",
      "Epoch 756/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.1595 - val_loss: 24.7966\n",
      "Epoch 757/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2.1588 - val_loss: 24.6037\n",
      "Epoch 758/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2.1573 - val_loss: 24.8287\n",
      "Epoch 759/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.1460 - val_loss: 25.0647\n",
      "Epoch 760/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2.1445 - val_loss: 25.3400\n",
      "Epoch 761/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.1442 - val_loss: 25.7493\n",
      "Epoch 762/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.1321 - val_loss: 26.1338\n",
      "Epoch 763/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.1384 - val_loss: 26.4132\n",
      "Epoch 764/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.1284 - val_loss: 26.0802\n",
      "Epoch 765/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.1243 - val_loss: 25.8824\n",
      "Epoch 766/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.1258 - val_loss: 25.6772\n",
      "Epoch 767/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.1216 - val_loss: 25.6653\n",
      "Epoch 768/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.1178 - val_loss: 25.9079\n",
      "Epoch 769/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.1159 - val_loss: 26.1322\n",
      "Epoch 770/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.1128 - val_loss: 26.2257\n",
      "Epoch 771/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.1091 - val_loss: 26.4606\n",
      "Epoch 772/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.1168 - val_loss: 26.8071\n",
      "Epoch 773/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.1104 - val_loss: 26.7422\n",
      "Epoch 774/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.1074 - val_loss: 26.6560\n",
      "Epoch 775/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.1072 - val_loss: 26.4894\n",
      "Epoch 776/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.1040 - val_loss: 26.3369\n",
      "Epoch 777/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.0997 - val_loss: 26.1481\n",
      "Epoch 778/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.0830 - val_loss: 25.4394\n",
      "Epoch 779/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.0948 - val_loss: 24.4302\n",
      "Epoch 780/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.0973 - val_loss: 23.8764\n",
      "Epoch 781/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.0973 - val_loss: 23.8725\n",
      "Epoch 782/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.0916 - val_loss: 24.0112\n",
      "Epoch 783/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.0914 - val_loss: 24.3499\n",
      "Epoch 784/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.0870 - val_loss: 24.4299\n",
      "Epoch 785/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.0829 - val_loss: 24.0587\n",
      "Epoch 786/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.0788 - val_loss: 24.0752\n",
      "Epoch 787/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.0790 - val_loss: 24.3645\n",
      "Epoch 788/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.0766 - val_loss: 24.6539\n",
      "Epoch 789/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.0659 - val_loss: 24.7290\n",
      "Epoch 790/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.0625 - val_loss: 24.9595\n",
      "Epoch 791/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.0627 - val_loss: 25.1112\n",
      "Epoch 792/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.0600 - val_loss: 25.1757\n",
      "Epoch 793/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.0581 - val_loss: 25.1879\n",
      "Epoch 794/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.0570 - val_loss: 25.2992\n",
      "Epoch 795/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.0545 - val_loss: 25.3532\n",
      "Epoch 796/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.0537 - val_loss: 25.2450\n",
      "Epoch 797/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.0422 - val_loss: 24.6982\n",
      "Epoch 798/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.0508 - val_loss: 24.1871\n",
      "Epoch 799/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.0439 - val_loss: 23.8194\n",
      "Epoch 800/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.0455 - val_loss: 23.4113\n",
      "Epoch 801/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.0508 - val_loss: 23.2089\n",
      "Epoch 802/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.0453 - val_loss: 22.8325\n",
      "Epoch 803/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.0521 - val_loss: 22.8432\n",
      "Epoch 804/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.0495 - val_loss: 23.1910\n",
      "Epoch 805/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.0376 - val_loss: 23.5341\n",
      "Epoch 806/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.0309 - val_loss: 23.8415\n",
      "Epoch 807/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.0265 - val_loss: 24.2431\n",
      "Epoch 808/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.0196 - val_loss: 24.5320\n",
      "Epoch 809/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.0190 - val_loss: 24.7029\n",
      "Epoch 810/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.0173 - val_loss: 24.5643\n",
      "Epoch 811/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.0149 - val_loss: 24.6205\n",
      "Epoch 812/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.0114 - val_loss: 24.8998\n",
      "Epoch 813/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.0106 - val_loss: 25.2460\n",
      "Epoch 814/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.0141 - val_loss: 25.5421\n",
      "Epoch 815/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.0062 - val_loss: 25.3483\n",
      "Epoch 816/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.0049 - val_loss: 25.1277\n",
      "Epoch 817/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.0027 - val_loss: 24.9426\n",
      "Epoch 818/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.9971 - val_loss: 24.9773\n",
      "Epoch 819/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.9966 - val_loss: 25.0282\n",
      "Epoch 820/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.9956 - val_loss: 25.1999\n",
      "Epoch 821/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.9953 - val_loss: 25.1164\n",
      "Epoch 822/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.9779 - val_loss: 24.4548\n",
      "Epoch 823/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.0079 - val_loss: 23.3969\n",
      "Epoch 824/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.9831 - val_loss: 22.9736\n",
      "Epoch 825/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.9802 - val_loss: 22.6155\n",
      "Epoch 826/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.9864 - val_loss: 21.8874\n",
      "Epoch 827/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.9973 - val_loss: 21.3434\n",
      "Epoch 828/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2.0006 - val_loss: 21.0498\n",
      "Epoch 829/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.9997 - val_loss: 20.9410\n",
      "Epoch 830/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.9997 - val_loss: 20.8574\n",
      "Epoch 831/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.9986 - val_loss: 20.9661\n",
      "Epoch 832/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.9900 - val_loss: 21.1795\n",
      "Epoch 833/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.9845 - val_loss: 21.4787\n",
      "Epoch 834/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.9761 - val_loss: 21.3981\n",
      "Epoch 835/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.9755 - val_loss: 21.2262\n",
      "Epoch 836/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.9731 - val_loss: 21.2680\n",
      "Epoch 837/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.9696 - val_loss: 21.3436\n",
      "Epoch 838/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.9707 - val_loss: 21.8106\n",
      "Epoch 839/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.9548 - val_loss: 22.1697\n",
      "Epoch 840/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.9462 - val_loss: 22.4507\n",
      "Epoch 841/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.9372 - val_loss: 22.8977\n",
      "Epoch 842/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.9257 - val_loss: 23.3925\n",
      "Epoch 843/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.9472 - val_loss: 24.1186\n",
      "Epoch 844/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.9312 - val_loss: 24.4521\n",
      "Epoch 845/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.9325 - val_loss: 24.7098\n",
      "Epoch 846/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.9300 - val_loss: 25.0018\n",
      "Epoch 847/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.9284 - val_loss: 25.2108\n",
      "Epoch 848/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.9432 - val_loss: 25.6516\n",
      "Epoch 849/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.9368 - val_loss: 25.6510\n",
      "Epoch 850/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.9316 - val_loss: 25.0144\n",
      "Epoch 851/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.9207 - val_loss: 24.5781\n",
      "Epoch 852/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.9164 - val_loss: 24.3810\n",
      "Epoch 853/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.9120 - val_loss: 24.1761\n",
      "Epoch 854/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.9102 - val_loss: 24.0351\n",
      "Epoch 855/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.9069 - val_loss: 24.1151\n",
      "Epoch 856/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.9036 - val_loss: 23.9823\n",
      "Epoch 857/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.9027 - val_loss: 23.8804\n",
      "Epoch 858/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.8991 - val_loss: 23.8566\n",
      "Epoch 859/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.8965 - val_loss: 23.8310\n",
      "Epoch 860/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.8940 - val_loss: 23.8797\n",
      "Epoch 861/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.8965 - val_loss: 23.9511\n",
      "Epoch 862/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.8893 - val_loss: 23.6714\n",
      "Epoch 863/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.8876 - val_loss: 23.6840\n",
      "Epoch 864/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.8834 - val_loss: 23.7703\n",
      "Epoch 865/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.8872 - val_loss: 23.7935\n",
      "Epoch 866/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.8792 - val_loss: 23.4031\n",
      "Epoch 867/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.8780 - val_loss: 23.1586\n",
      "Epoch 868/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.8758 - val_loss: 23.1480\n",
      "Epoch 869/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.8783 - val_loss: 22.6907\n",
      "Epoch 870/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 9ms/step - loss: 1.8666 - val_loss: 22.3814\n",
      "Epoch 871/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.8654 - val_loss: 22.1822\n",
      "Epoch 872/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.8685 - val_loss: 22.1808\n",
      "Epoch 873/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.8617 - val_loss: 21.6699\n",
      "Epoch 874/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.8695 - val_loss: 21.3403\n",
      "Epoch 875/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.8644 - val_loss: 21.2255\n",
      "Epoch 876/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.8633 - val_loss: 20.9601\n",
      "Epoch 877/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.8583 - val_loss: 20.8804\n",
      "Epoch 878/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.8633 - val_loss: 20.7279\n",
      "Epoch 879/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.8538 - val_loss: 20.9241\n",
      "Epoch 880/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.8480 - val_loss: 21.1838\n",
      "Epoch 881/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.8395 - val_loss: 21.5686\n",
      "Epoch 882/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.8395 - val_loss: 21.8779\n",
      "Epoch 883/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.8375 - val_loss: 21.8893\n",
      "Epoch 884/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.8326 - val_loss: 21.7051\n",
      "Epoch 885/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.8296 - val_loss: 21.6066\n",
      "Epoch 886/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.8289 - val_loss: 21.5884\n",
      "Epoch 887/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.8283 - val_loss: 21.5660\n",
      "Epoch 888/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.8231 - val_loss: 21.8189\n",
      "Epoch 889/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.8204 - val_loss: 22.1851\n",
      "Epoch 890/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.8207 - val_loss: 22.5372\n",
      "Epoch 891/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.8136 - val_loss: 22.8801\n",
      "Epoch 892/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.8138 - val_loss: 23.1065\n",
      "Epoch 893/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.8148 - val_loss: 23.1653\n",
      "Epoch 894/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.8086 - val_loss: 22.6393\n",
      "Epoch 895/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.8031 - val_loss: 22.4450\n",
      "Epoch 896/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.8007 - val_loss: 22.4563\n",
      "Epoch 897/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.8023 - val_loss: 22.6283\n",
      "Epoch 898/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.7956 - val_loss: 22.9018\n",
      "Epoch 899/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.7999 - val_loss: 23.2254\n",
      "Epoch 900/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.7996 - val_loss: 23.6024\n",
      "Epoch 901/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.7994 - val_loss: 23.9929\n",
      "Epoch 902/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.8037 - val_loss: 24.2336\n",
      "Epoch 903/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.7963 - val_loss: 23.9626\n",
      "Epoch 904/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.7936 - val_loss: 23.8595\n",
      "Epoch 905/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.7924 - val_loss: 23.7674\n",
      "Epoch 906/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.7943 - val_loss: 23.1103\n",
      "Epoch 907/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.7770 - val_loss: 22.6058\n",
      "Epoch 908/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.7692 - val_loss: 22.1898\n",
      "Epoch 909/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.7650 - val_loss: 21.8390\n",
      "Epoch 910/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.7664 - val_loss: 21.4471\n",
      "Epoch 911/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.7606 - val_loss: 21.2641\n",
      "Epoch 912/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.7611 - val_loss: 20.9138\n",
      "Epoch 913/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.7579 - val_loss: 20.9255\n",
      "Epoch 914/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.7530 - val_loss: 20.8066\n",
      "Epoch 915/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.7514 - val_loss: 20.7532\n",
      "Epoch 916/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.7507 - val_loss: 20.8093\n",
      "Epoch 917/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.7442 - val_loss: 20.9596\n",
      "Epoch 918/2000\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.7412 - val_loss: 21.2151\n",
      "Epoch 919/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.7385 - val_loss: 21.6214\n",
      "Epoch 920/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.7326 - val_loss: 21.9460\n",
      "Epoch 921/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.7348 - val_loss: 22.3725\n",
      "Epoch 922/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.7366 - val_loss: 22.7495\n",
      "Epoch 923/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.7385 - val_loss: 22.9783\n",
      "Epoch 924/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.7338 - val_loss: 22.8953\n",
      "Epoch 925/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.7306 - val_loss: 22.7339\n",
      "Epoch 926/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.7266 - val_loss: 22.5824\n",
      "Epoch 927/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.7231 - val_loss: 22.4304\n",
      "Epoch 928/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.7213 - val_loss: 22.0942\n",
      "Epoch 929/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.7139 - val_loss: 21.8733\n",
      "Epoch 930/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.7132 - val_loss: 21.6866\n",
      "Epoch 931/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.7102 - val_loss: 21.8745\n",
      "Epoch 932/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.7097 - val_loss: 22.2149\n",
      "Epoch 933/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.7032 - val_loss: 22.5774\n",
      "Epoch 934/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.7097 - val_loss: 22.8709\n",
      "Epoch 935/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.7059 - val_loss: 22.6525\n",
      "Epoch 936/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.7017 - val_loss: 22.4900\n",
      "Epoch 937/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.7010 - val_loss: 22.5138\n",
      "Epoch 938/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.6962 - val_loss: 22.3982\n",
      "Epoch 939/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.6926 - val_loss: 22.3470\n",
      "Epoch 940/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.6891 - val_loss: 22.3672\n",
      "Epoch 941/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.6873 - val_loss: 22.3532\n",
      "Epoch 942/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.6851 - val_loss: 22.2875\n",
      "Epoch 943/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.6823 - val_loss: 22.0422\n",
      "Epoch 944/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.6758 - val_loss: 21.6787\n",
      "Epoch 945/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.6595 - val_loss: 20.8201\n",
      "Epoch 946/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.6656 - val_loss: 19.9152\n",
      "Epoch 947/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.6688 - val_loss: 19.4367\n",
      "Epoch 948/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.6728 - val_loss: 19.2466\n",
      "Epoch 949/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.6741 - val_loss: 19.0958\n",
      "Epoch 950/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.6723 - val_loss: 19.1598\n",
      "Epoch 951/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.6647 - val_loss: 19.3771\n",
      "Epoch 952/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.6693 - val_loss: 19.7539\n",
      "Epoch 953/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.6546 - val_loss: 19.4947\n",
      "Epoch 954/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.6539 - val_loss: 19.2392\n",
      "Epoch 955/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.6519 - val_loss: 18.8940\n",
      "Epoch 956/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.6507 - val_loss: 18.7723\n",
      "Epoch 957/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.6497 - val_loss: 18.7294\n",
      "Epoch 958/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.6444 - val_loss: 18.9159\n",
      "Epoch 959/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.6317 - val_loss: 19.3449\n",
      "Epoch 960/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.6296 - val_loss: 19.9577\n",
      "Epoch 961/2000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.6279 - val_loss: 20.3517\n",
      "Epoch 962/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.6216 - val_loss: 20.2997\n",
      "Epoch 963/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.6214 - val_loss: 20.4753\n",
      "Epoch 964/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.6168 - val_loss: 20.2111\n",
      "Epoch 965/2000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.6125 - val_loss: 20.0644\n",
      "Epoch 966/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.6090 - val_loss: 19.4654\n",
      "Epoch 967/2000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.6065 - val_loss: 19.2480\n",
      "Epoch 968/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.6031 - val_loss: 19.1513\n",
      "Epoch 969/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 1.5992 - val_loss: 18.9881\n",
      "Epoch 970/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.5993 - val_loss: 18.9042\n",
      "Epoch 971/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.5972 - val_loss: 18.9946\n",
      "Epoch 972/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.5913 - val_loss: 19.4637\n",
      "Epoch 973/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.5892 - val_loss: 19.9853\n",
      "Epoch 974/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.5854 - val_loss: 20.3242\n",
      "Epoch 975/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.5784 - val_loss: 20.6134\n",
      "Epoch 976/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.5822 - val_loss: 20.8819\n",
      "Epoch 977/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.5873 - val_loss: 21.1018\n",
      "Epoch 978/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.5781 - val_loss: 20.8271\n",
      "Epoch 979/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.5792 - val_loss: 20.9292\n",
      "Epoch 980/2000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.5715 - val_loss: 20.8736\n",
      "Epoch 981/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.5701 - val_loss: 20.8120\n",
      "Epoch 982/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.5644 - val_loss: 20.5143\n",
      "Epoch 983/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.5541 - val_loss: 20.0081\n",
      "Epoch 984/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.5579 - val_loss: 19.4686\n",
      "Epoch 985/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.5485 - val_loss: 19.1409\n",
      "Epoch 986/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.5487 - val_loss: 18.9245\n",
      "Epoch 987/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.5519 - val_loss: 19.0086\n",
      "Epoch 988/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.5452 - val_loss: 18.9902\n",
      "Epoch 989/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.5421 - val_loss: 18.9506\n",
      "Epoch 990/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.5401 - val_loss: 18.9609\n",
      "Epoch 991/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.5397 - val_loss: 19.1361\n",
      "Epoch 992/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.5366 - val_loss: 19.2696\n",
      "Epoch 993/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.5324 - val_loss: 19.0127\n",
      "Epoch 994/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.5303 - val_loss: 18.8294\n",
      "Epoch 995/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.5331 - val_loss: 18.9512\n",
      "Epoch 996/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.5265 - val_loss: 18.9248\n",
      "Epoch 997/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.5198 - val_loss: 19.1892\n",
      "Epoch 998/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.5186 - val_loss: 19.4568\n",
      "Epoch 999/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.5120 - val_loss: 19.2431\n",
      "Epoch 1000/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.5099 - val_loss: 19.0158\n",
      "Epoch 1001/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.4999 - val_loss: 18.4283\n",
      "Epoch 1002/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.5090 - val_loss: 18.0376\n",
      "Epoch 1003/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.5033 - val_loss: 18.0137\n",
      "Epoch 1004/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.4980 - val_loss: 18.1416\n",
      "Epoch 1005/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.4927 - val_loss: 18.2587\n",
      "Epoch 1006/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.4881 - val_loss: 18.6192\n",
      "Epoch 1007/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.4814 - val_loss: 19.1399\n",
      "Epoch 1008/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.4721 - val_loss: 19.5912\n",
      "Epoch 1009/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.4741 - val_loss: 19.9904\n",
      "Epoch 1010/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.4884 - val_loss: 20.3371\n",
      "Epoch 1011/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.4798 - val_loss: 19.9211\n",
      "Epoch 1012/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.4749 - val_loss: 19.7144\n",
      "Epoch 1013/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.4696 - val_loss: 19.6451\n",
      "Epoch 1014/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.4648 - val_loss: 19.4959\n",
      "Epoch 1015/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.4614 - val_loss: 19.3237\n",
      "Epoch 1016/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.4570 - val_loss: 19.1662\n",
      "Epoch 1017/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.4545 - val_loss: 19.2234\n",
      "Epoch 1018/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.4505 - val_loss: 19.1963\n",
      "Epoch 1019/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.4480 - val_loss: 19.0567\n",
      "Epoch 1020/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.4461 - val_loss: 18.4962\n",
      "Epoch 1021/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.4371 - val_loss: 18.0986\n",
      "Epoch 1022/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.4340 - val_loss: 17.8186\n",
      "Epoch 1023/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.4351 - val_loss: 17.7261\n",
      "Epoch 1024/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.4313 - val_loss: 17.5614\n",
      "Epoch 1025/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.4319 - val_loss: 17.4013\n",
      "Epoch 1026/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.4286 - val_loss: 17.3319\n",
      "Epoch 1027/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.4247 - val_loss: 17.6369\n",
      "Epoch 1028/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.4186 - val_loss: 18.0801\n",
      "Epoch 1029/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.4136 - val_loss: 18.5040\n",
      "Epoch 1030/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.4118 - val_loss: 19.0534\n",
      "Epoch 1031/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 16ms/step - loss: 1.4138 - val_loss: 19.5354\n",
      "Epoch 1032/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.4152 - val_loss: 19.7428\n",
      "Epoch 1033/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.4182 - val_loss: 19.9176\n",
      "Epoch 1034/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.4163 - val_loss: 19.8151\n",
      "Epoch 1035/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.4050 - val_loss: 19.2985\n",
      "Epoch 1036/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.4029 - val_loss: 18.9909\n",
      "Epoch 1037/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.3944 - val_loss: 18.7872\n",
      "Epoch 1038/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.3899 - val_loss: 18.5870\n",
      "Epoch 1039/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.3844 - val_loss: 18.4933\n",
      "Epoch 1040/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.3794 - val_loss: 18.2187\n",
      "Epoch 1041/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.3697 - val_loss: 17.5581\n",
      "Epoch 1042/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.3693 - val_loss: 17.2922\n",
      "Epoch 1043/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.3665 - val_loss: 17.0639\n",
      "Epoch 1044/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.3671 - val_loss: 17.0017\n",
      "Epoch 1045/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.3628 - val_loss: 16.9118\n",
      "Epoch 1046/2000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 1.3601 - val_loss: 16.9951\n",
      "Epoch 1047/2000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.3567 - val_loss: 17.2806\n",
      "Epoch 1048/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.3542 - val_loss: 17.6708\n",
      "Epoch 1049/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.3477 - val_loss: 17.8219\n",
      "Epoch 1050/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.3489 - val_loss: 17.8155\n",
      "Epoch 1051/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.3456 - val_loss: 17.1374\n",
      "Epoch 1052/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.3319 - val_loss: 16.7430\n",
      "Epoch 1053/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.3326 - val_loss: 16.4460\n",
      "Epoch 1054/2000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 1.3333 - val_loss: 16.1932\n",
      "Epoch 1055/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.3338 - val_loss: 16.0670\n",
      "Epoch 1056/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.3288 - val_loss: 16.2271\n",
      "Epoch 1057/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.3213 - val_loss: 16.4030\n",
      "Epoch 1058/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.3240 - val_loss: 16.8576\n",
      "Epoch 1059/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.3111 - val_loss: 17.3183\n",
      "Epoch 1060/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.3148 - val_loss: 17.7125\n",
      "Epoch 1061/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.3114 - val_loss: 18.0217\n",
      "Epoch 1062/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.3101 - val_loss: 18.1560\n",
      "Epoch 1063/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.3078 - val_loss: 18.1645\n",
      "Epoch 1064/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.3061 - val_loss: 17.9181\n",
      "Epoch 1065/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.2966 - val_loss: 17.5874\n",
      "Epoch 1066/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.2922 - val_loss: 17.1026\n",
      "Epoch 1067/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.2875 - val_loss: 16.2365\n",
      "Epoch 1068/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.2972 - val_loss: 15.5805\n",
      "Epoch 1069/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.2888 - val_loss: 15.1751\n",
      "Epoch 1070/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.2963 - val_loss: 14.8557\n",
      "Epoch 1071/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.2913 - val_loss: 14.8098\n",
      "Epoch 1072/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.2880 - val_loss: 14.9454\n",
      "Epoch 1073/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.2765 - val_loss: 15.2889\n",
      "Epoch 1074/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.2680 - val_loss: 15.7510\n",
      "Epoch 1075/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.2593 - val_loss: 16.0447\n",
      "Epoch 1076/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.2600 - val_loss: 16.2948\n",
      "Epoch 1077/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.2522 - val_loss: 16.4053\n",
      "Epoch 1078/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.2519 - val_loss: 16.7875\n",
      "Epoch 1079/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.2426 - val_loss: 17.0903\n",
      "Epoch 1080/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.2423 - val_loss: 17.2353\n",
      "Epoch 1081/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.2430 - val_loss: 17.2092\n",
      "Epoch 1082/2000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.2405 - val_loss: 17.3780\n",
      "Epoch 1083/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.2368 - val_loss: 17.2714\n",
      "Epoch 1084/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.2336 - val_loss: 17.0446\n",
      "Epoch 1085/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.2264 - val_loss: 16.9029\n",
      "Epoch 1086/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.2237 - val_loss: 16.6972\n",
      "Epoch 1087/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.2194 - val_loss: 16.7751\n",
      "Epoch 1088/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.2168 - val_loss: 16.8658\n",
      "Epoch 1089/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.2179 - val_loss: 16.5449\n",
      "Epoch 1090/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.2103 - val_loss: 16.6692\n",
      "Epoch 1091/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.2071 - val_loss: 16.7039\n",
      "Epoch 1092/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.1982 - val_loss: 16.4197\n",
      "Epoch 1093/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.1957 - val_loss: 16.2446\n",
      "Epoch 1094/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.1912 - val_loss: 16.2198\n",
      "Epoch 1095/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.1879 - val_loss: 16.3835\n",
      "Epoch 1096/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.1853 - val_loss: 16.3345\n",
      "Epoch 1097/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.1860 - val_loss: 16.3934\n",
      "Epoch 1098/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.1808 - val_loss: 16.3223\n",
      "Epoch 1099/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.1751 - val_loss: 16.1077\n",
      "Epoch 1100/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.1710 - val_loss: 15.8889\n",
      "Epoch 1101/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.1709 - val_loss: 15.7741\n",
      "Epoch 1102/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.1671 - val_loss: 15.9589\n",
      "Epoch 1103/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.1619 - val_loss: 16.0743\n",
      "Epoch 1104/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.1589 - val_loss: 16.1669\n",
      "Epoch 1105/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.1587 - val_loss: 16.2187\n",
      "Epoch 1106/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.1552 - val_loss: 16.1473\n",
      "Epoch 1107/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.1524 - val_loss: 16.1403\n",
      "Epoch 1108/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.1490 - val_loss: 16.1577\n",
      "Epoch 1109/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.1480 - val_loss: 15.9913\n",
      "Epoch 1110/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.1317 - val_loss: 15.3254\n",
      "Epoch 1111/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.1287 - val_loss: 14.6123\n",
      "Epoch 1112/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.1343 - val_loss: 13.9243\n",
      "Epoch 1113/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.1364 - val_loss: 13.6771\n",
      "Epoch 1114/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.1295 - val_loss: 13.6633\n",
      "Epoch 1115/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.1295 - val_loss: 13.5259\n",
      "Epoch 1116/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.1224 - val_loss: 13.5495\n",
      "Epoch 1117/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.1193 - val_loss: 13.5929\n",
      "Epoch 1118/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.1134 - val_loss: 13.6270\n",
      "Epoch 1119/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.1096 - val_loss: 13.6492\n",
      "Epoch 1120/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.1051 - val_loss: 13.4864\n",
      "Epoch 1121/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.1031 - val_loss: 13.3859\n",
      "Epoch 1122/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.1008 - val_loss: 13.4077\n",
      "Epoch 1123/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.0970 - val_loss: 13.4961\n",
      "Epoch 1124/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.0929 - val_loss: 13.4251\n",
      "Epoch 1125/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.0914 - val_loss: 13.0408\n",
      "Epoch 1126/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.0894 - val_loss: 13.0801\n",
      "Epoch 1127/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.0829 - val_loss: 13.0652\n",
      "Epoch 1128/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.0778 - val_loss: 13.2537\n",
      "Epoch 1129/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.0654 - val_loss: 13.6182\n",
      "Epoch 1130/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.0633 - val_loss: 14.0909\n",
      "Epoch 1131/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.0590 - val_loss: 14.2221\n",
      "Epoch 1132/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.0553 - val_loss: 13.9921\n",
      "Epoch 1133/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0455 - val_loss: 13.3983\n",
      "Epoch 1134/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.0466 - val_loss: 12.5175\n",
      "Epoch 1135/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.0584 - val_loss: 11.8931\n",
      "Epoch 1136/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.0580 - val_loss: 11.5789\n",
      "Epoch 1137/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.0616 - val_loss: 11.4562\n",
      "Epoch 1138/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0599 - val_loss: 11.5506\n",
      "Epoch 1139/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.0512 - val_loss: 11.9309\n",
      "Epoch 1140/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.0378 - val_loss: 12.3131\n",
      "Epoch 1141/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.0256 - val_loss: 12.6639\n",
      "Epoch 1142/2000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.0157 - val_loss: 13.0599\n",
      "Epoch 1143/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.0146 - val_loss: 13.3909\n",
      "Epoch 1144/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.0121 - val_loss: 13.5018\n",
      "Epoch 1145/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0084 - val_loss: 13.2241\n",
      "Epoch 1146/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0022 - val_loss: 12.9423\n",
      "Epoch 1147/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9961 - val_loss: 12.6451\n",
      "Epoch 1148/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9953 - val_loss: 12.2095\n",
      "Epoch 1149/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9941 - val_loss: 11.5753\n",
      "Epoch 1150/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0106 - val_loss: 11.2214\n",
      "Epoch 1151/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.0026 - val_loss: 11.3720\n",
      "Epoch 1152/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9862 - val_loss: 11.7602\n",
      "Epoch 1153/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9804 - val_loss: 12.3979\n",
      "Epoch 1154/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9741 - val_loss: 13.0390\n",
      "Epoch 1155/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.9677 - val_loss: 13.5563\n",
      "Epoch 1156/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.9781 - val_loss: 13.8338\n",
      "Epoch 1157/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.9762 - val_loss: 13.7945\n",
      "Epoch 1158/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.9720 - val_loss: 13.6116\n",
      "Epoch 1159/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.9679 - val_loss: 13.1801\n",
      "Epoch 1160/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.9553 - val_loss: 12.9702\n",
      "Epoch 1161/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.9487 - val_loss: 12.3981\n",
      "Epoch 1162/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9372 - val_loss: 12.0488\n",
      "Epoch 1163/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.9374 - val_loss: 11.7743\n",
      "Epoch 1164/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.9367 - val_loss: 11.6255\n",
      "Epoch 1165/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.9367 - val_loss: 11.5145\n",
      "Epoch 1166/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.9280 - val_loss: 11.6701\n",
      "Epoch 1167/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.9238 - val_loss: 11.6668\n",
      "Epoch 1168/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.9215 - val_loss: 11.5178\n",
      "Epoch 1169/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.9215 - val_loss: 10.9515\n",
      "Epoch 1170/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.9246 - val_loss: 10.6372\n",
      "Epoch 1171/2000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.9178 - val_loss: 10.7141\n",
      "Epoch 1172/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.9138 - val_loss: 10.9034\n",
      "Epoch 1173/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.9049 - val_loss: 11.0135\n",
      "Epoch 1174/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8998 - val_loss: 11.1349\n",
      "Epoch 1175/2000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8938 - val_loss: 11.1765\n",
      "Epoch 1176/2000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.8904 - val_loss: 11.5199\n",
      "Epoch 1177/2000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8847 - val_loss: 11.8937\n",
      "Epoch 1178/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8826 - val_loss: 12.1464\n",
      "Epoch 1179/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8822 - val_loss: 12.1501\n",
      "Epoch 1180/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.8811 - val_loss: 12.0995\n",
      "Epoch 1181/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.8768 - val_loss: 12.0769\n",
      "Epoch 1182/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8730 - val_loss: 11.9818\n",
      "Epoch 1183/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.8687 - val_loss: 11.8986\n",
      "Epoch 1184/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8644 - val_loss: 11.9015\n",
      "Epoch 1185/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8668 - val_loss: 12.1246\n",
      "Epoch 1186/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.8623 - val_loss: 12.1197\n",
      "Epoch 1187/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.8600 - val_loss: 12.0815\n",
      "Epoch 1188/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8614 - val_loss: 12.1555\n",
      "Epoch 1189/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8565 - val_loss: 12.0568\n",
      "Epoch 1190/2000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.8561 - val_loss: 11.8990\n",
      "Epoch 1191/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8405 - val_loss: 11.1187\n",
      "Epoch 1192/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8444 - val_loss: 10.3674\n",
      "Epoch 1193/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8332 - val_loss: 9.9146\n",
      "Epoch 1194/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8292 - val_loss: 9.7955\n",
      "Epoch 1195/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8269 - val_loss: 9.6957\n",
      "Epoch 1196/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8258 - val_loss: 9.7185\n",
      "Epoch 1197/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8234 - val_loss: 10.0755\n",
      "Epoch 1198/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.8125 - val_loss: 10.1591\n",
      "Epoch 1199/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8066 - val_loss: 10.3047\n",
      "Epoch 1200/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.8025 - val_loss: 10.5280\n",
      "Epoch 1201/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.8017 - val_loss: 10.6796\n",
      "Epoch 1202/2000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.8006 - val_loss: 10.8477\n",
      "Epoch 1203/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.8010 - val_loss: 10.8342\n",
      "Epoch 1204/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7966 - val_loss: 10.5303\n",
      "Epoch 1205/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7860 - val_loss: 9.7926\n",
      "Epoch 1206/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7932 - val_loss: 9.2716\n",
      "Epoch 1207/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7893 - val_loss: 9.1615\n",
      "Epoch 1208/2000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7906 - val_loss: 9.0847\n",
      "Epoch 1209/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7848 - val_loss: 9.1218\n",
      "Epoch 1210/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7839 - val_loss: 9.4767\n",
      "Epoch 1211/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7638 - val_loss: 9.8683\n",
      "Epoch 1212/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7608 - val_loss: 10.3849\n",
      "Epoch 1213/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7731 - val_loss: 10.8875\n",
      "Epoch 1214/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7824 - val_loss: 11.0131\n",
      "Epoch 1215/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.7748 - val_loss: 10.5915\n",
      "Epoch 1216/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7626 - val_loss: 10.2659\n",
      "Epoch 1217/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7559 - val_loss: 9.8463\n",
      "Epoch 1218/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7496 - val_loss: 9.5308\n",
      "Epoch 1219/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7449 - val_loss: 9.4094\n",
      "Epoch 1220/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7430 - val_loss: 9.3871\n",
      "Epoch 1221/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7397 - val_loss: 9.3204\n",
      "Epoch 1222/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7371 - val_loss: 9.2690\n",
      "Epoch 1223/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7351 - val_loss: 9.0632\n",
      "Epoch 1224/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7325 - val_loss: 8.6957\n",
      "Epoch 1225/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7335 - val_loss: 8.4731\n",
      "Epoch 1226/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7311 - val_loss: 8.3866\n",
      "Epoch 1227/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7286 - val_loss: 8.5040\n",
      "Epoch 1228/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7232 - val_loss: 8.6737\n",
      "Epoch 1229/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7217 - val_loss: 8.9567\n",
      "Epoch 1230/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7159 - val_loss: 8.9320\n",
      "Epoch 1231/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7123 - val_loss: 9.0371\n",
      "Epoch 1232/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7102 - val_loss: 9.1608\n",
      "Epoch 1233/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7089 - val_loss: 8.9306\n",
      "Epoch 1234/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7051 - val_loss: 8.7086\n",
      "Epoch 1235/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7034 - val_loss: 8.7961\n",
      "Epoch 1236/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6997 - val_loss: 8.8945\n",
      "Epoch 1237/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6965 - val_loss: 9.0017\n",
      "Epoch 1238/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7023 - val_loss: 9.1239\n",
      "Epoch 1239/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6941 - val_loss: 8.6993\n",
      "Epoch 1240/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6899 - val_loss: 8.5652\n",
      "Epoch 1241/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6858 - val_loss: 8.4683\n",
      "Epoch 1242/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6847 - val_loss: 8.1637\n",
      "Epoch 1243/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6791 - val_loss: 8.1464\n",
      "Epoch 1244/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6763 - val_loss: 8.0941\n",
      "Epoch 1245/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6751 - val_loss: 8.0445\n",
      "Epoch 1246/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6724 - val_loss: 7.8084\n",
      "Epoch 1247/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6718 - val_loss: 7.6241\n",
      "Epoch 1248/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6664 - val_loss: 7.6078\n",
      "Epoch 1249/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6658 - val_loss: 7.5962\n",
      "Epoch 1250/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6638 - val_loss: 7.4934\n",
      "Epoch 1251/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6588 - val_loss: 7.6634\n",
      "Epoch 1252/2000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.6617 - val_loss: 7.8541\n",
      "Epoch 1253/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6622 - val_loss: 7.5056\n",
      "Epoch 1254/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6503 - val_loss: 7.5202\n",
      "Epoch 1255/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6475 - val_loss: 7.6989\n",
      "Epoch 1256/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6474 - val_loss: 7.8806\n",
      "Epoch 1257/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6467 - val_loss: 7.6818\n",
      "Epoch 1258/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6415 - val_loss: 7.4903\n",
      "Epoch 1259/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6387 - val_loss: 7.1218\n",
      "Epoch 1260/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6384 - val_loss: 6.9458\n",
      "Epoch 1261/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6364 - val_loss: 6.9252\n",
      "Epoch 1262/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6345 - val_loss: 7.0852\n",
      "Epoch 1263/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6309 - val_loss: 7.1774\n",
      "Epoch 1264/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6280 - val_loss: 7.2594\n",
      "Epoch 1265/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6277 - val_loss: 7.3912\n",
      "Epoch 1266/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6263 - val_loss: 7.3742\n",
      "Epoch 1267/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6247 - val_loss: 7.4565\n",
      "Epoch 1268/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6222 - val_loss: 7.6843\n",
      "Epoch 1269/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6301 - val_loss: 7.8538\n",
      "Epoch 1270/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6305 - val_loss: 7.8876\n",
      "Epoch 1271/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6287 - val_loss: 7.6751\n",
      "Epoch 1272/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6246 - val_loss: 7.1368\n",
      "Epoch 1273/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6137 - val_loss: 6.7976\n",
      "Epoch 1274/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6236 - val_loss: 6.1992\n",
      "Epoch 1275/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6220 - val_loss: 5.9911\n",
      "Epoch 1276/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6168 - val_loss: 5.9970\n",
      "Epoch 1277/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6135 - val_loss: 6.0002\n",
      "Epoch 1278/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6082 - val_loss: 6.1501\n",
      "Epoch 1279/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5991 - val_loss: 6.4722\n",
      "Epoch 1280/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6015 - val_loss: 6.9853\n",
      "Epoch 1281/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6152 - val_loss: 7.4465\n",
      "Epoch 1282/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6114 - val_loss: 7.6221\n",
      "Epoch 1283/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6243 - val_loss: 7.7465\n",
      "Epoch 1284/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6220 - val_loss: 7.6769\n",
      "Epoch 1285/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6171 - val_loss: 7.4853\n",
      "Epoch 1286/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6108 - val_loss: 7.2580\n",
      "Epoch 1287/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6047 - val_loss: 7.0542\n",
      "Epoch 1288/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5969 - val_loss: 6.9000\n",
      "Epoch 1289/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5924 - val_loss: 6.6985\n",
      "Epoch 1290/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5882 - val_loss: 6.4900\n",
      "Epoch 1291/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5834 - val_loss: 6.3068\n",
      "Epoch 1292/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5787 - val_loss: 6.0535\n",
      "Epoch 1293/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5791 - val_loss: 5.8129\n",
      "Epoch 1294/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5809 - val_loss: 5.6508\n",
      "Epoch 1295/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5807 - val_loss: 5.4910\n",
      "Epoch 1296/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5838 - val_loss: 5.2038\n",
      "Epoch 1297/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6014 - val_loss: 4.8827\n",
      "Epoch 1298/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5943 - val_loss: 5.0960\n",
      "Epoch 1299/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5810 - val_loss: 5.5775\n",
      "Epoch 1300/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5653 - val_loss: 5.8947\n",
      "Epoch 1301/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5595 - val_loss: 6.2615\n",
      "Epoch 1302/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5772 - val_loss: 6.7855\n",
      "Epoch 1303/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5768 - val_loss: 6.9978\n",
      "Epoch 1304/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5812 - val_loss: 7.0045\n",
      "Epoch 1305/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5799 - val_loss: 6.7942\n",
      "Epoch 1306/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5728 - val_loss: 6.5379\n",
      "Epoch 1307/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5637 - val_loss: 5.7626\n",
      "Epoch 1308/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5611 - val_loss: 5.2770\n",
      "Epoch 1309/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5586 - val_loss: 5.1833\n",
      "Epoch 1310/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5597 - val_loss: 5.1780\n",
      "Epoch 1311/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5587 - val_loss: 5.4892\n",
      "Epoch 1312/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5487 - val_loss: 5.6256\n",
      "Epoch 1313/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5462 - val_loss: 5.8476\n",
      "Epoch 1314/2000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.5478 - val_loss: 6.0298\n",
      "Epoch 1315/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5494 - val_loss: 6.2089\n",
      "Epoch 1316/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5514 - val_loss: 6.2298\n",
      "Epoch 1317/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5523 - val_loss: 6.1944\n",
      "Epoch 1318/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5496 - val_loss: 6.0773\n",
      "Epoch 1319/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5474 - val_loss: 6.0181\n",
      "Epoch 1320/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5463 - val_loss: 5.7856\n",
      "Epoch 1321/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5454 - val_loss: 5.8429\n",
      "Epoch 1322/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5394 - val_loss: 5.7222\n",
      "Epoch 1323/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5380 - val_loss: 5.5170\n",
      "Epoch 1324/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5344 - val_loss: 5.3588\n",
      "Epoch 1325/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5393 - val_loss: 5.1363\n",
      "Epoch 1326/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5341 - val_loss: 5.1854\n",
      "Epoch 1327/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5307 - val_loss: 5.4823\n",
      "Epoch 1328/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5326 - val_loss: 5.8573\n",
      "Epoch 1329/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5345 - val_loss: 6.0016\n",
      "Epoch 1330/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5398 - val_loss: 6.0112\n",
      "Epoch 1331/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5380 - val_loss: 5.8254\n",
      "Epoch 1332/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5295 - val_loss: 5.4239\n",
      "Epoch 1333/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5210 - val_loss: 4.9184\n",
      "Epoch 1334/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5231 - val_loss: 4.6624\n",
      "Epoch 1335/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5291 - val_loss: 4.5048\n",
      "Epoch 1336/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5304 - val_loss: 4.5476\n",
      "Epoch 1337/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5225 - val_loss: 4.8110\n",
      "Epoch 1338/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5208 - val_loss: 4.9892\n",
      "Epoch 1339/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5196 - val_loss: 5.0864\n",
      "Epoch 1340/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5181 - val_loss: 5.1556\n",
      "Epoch 1341/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5180 - val_loss: 5.1544\n",
      "Epoch 1342/2000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.5161 - val_loss: 5.1303\n",
      "Epoch 1343/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5154 - val_loss: 5.1755\n",
      "Epoch 1344/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5144 - val_loss: 5.0785\n",
      "Epoch 1345/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5162 - val_loss: 4.9199\n",
      "Epoch 1346/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5119 - val_loss: 4.7878\n",
      "Epoch 1347/2000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.5078 - val_loss: 4.4858\n",
      "Epoch 1348/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5194 - val_loss: 3.9274\n",
      "Epoch 1349/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5390 - val_loss: 3.7038\n",
      "Epoch 1350/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5327 - val_loss: 3.9741\n",
      "Epoch 1351/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5135 - val_loss: 4.5449\n",
      "Epoch 1352/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5005 - val_loss: 5.1624\n",
      "Epoch 1353/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5082 - val_loss: 5.6734\n",
      "Epoch 1354/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5224 - val_loss: 5.7459\n",
      "Epoch 1355/2000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5188 - val_loss: 5.5258\n",
      "Epoch 1356/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5097 - val_loss: 5.1772\n",
      "Epoch 1357/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5049 - val_loss: 4.8540\n",
      "Epoch 1358/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4982 - val_loss: 4.6572\n",
      "Epoch 1359/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4978 - val_loss: 4.5730\n",
      "Epoch 1360/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4973 - val_loss: 4.6301\n",
      "Epoch 1361/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4985 - val_loss: 4.6476\n",
      "Epoch 1362/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4950 - val_loss: 4.3003\n",
      "Epoch 1363/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4976 - val_loss: 4.2796\n",
      "Epoch 1364/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4948 - val_loss: 4.3113\n",
      "Epoch 1365/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4938 - val_loss: 4.2634\n",
      "Epoch 1366/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4926 - val_loss: 4.2307\n",
      "Epoch 1367/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4923 - val_loss: 4.2401\n",
      "Epoch 1368/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4946 - val_loss: 4.2580\n",
      "Epoch 1369/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4860 - val_loss: 4.5121\n",
      "Epoch 1370/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4929 - val_loss: 4.8054\n",
      "Epoch 1371/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4909 - val_loss: 4.9754\n",
      "Epoch 1372/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4951 - val_loss: 4.8866\n",
      "Epoch 1373/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4918 - val_loss: 4.2983\n",
      "Epoch 1374/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4850 - val_loss: 4.0907\n",
      "Epoch 1375/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4925 - val_loss: 3.9156\n",
      "Epoch 1376/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4865 - val_loss: 3.9881\n",
      "Epoch 1377/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4813 - val_loss: 4.2310\n",
      "Epoch 1378/2000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4802 - val_loss: 4.6005\n",
      "Epoch 1379/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4868 - val_loss: 4.8844\n",
      "Epoch 1380/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4899 - val_loss: 4.7842\n",
      "Epoch 1381/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4835 - val_loss: 4.5721\n",
      "Epoch 1382/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4842 - val_loss: 4.3722\n",
      "Epoch 1383/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4796 - val_loss: 4.3165\n",
      "Epoch 1384/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4727 - val_loss: 3.8919\n",
      "Epoch 1385/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4768 - val_loss: 3.6790\n",
      "Epoch 1386/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4781 - val_loss: 3.4942\n",
      "Epoch 1387/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4875 - val_loss: 3.1704\n",
      "Epoch 1388/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4947 - val_loss: 3.1548\n",
      "Epoch 1389/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4905 - val_loss: 3.2873\n",
      "Epoch 1390/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4860 - val_loss: 3.4437\n",
      "Epoch 1391/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4787 - val_loss: 3.4691\n",
      "Epoch 1392/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4768 - val_loss: 3.4235\n",
      "Epoch 1393/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4743 - val_loss: 3.6057\n",
      "Epoch 1394/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4688 - val_loss: 3.6824\n",
      "Epoch 1395/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4670 - val_loss: 3.8176\n",
      "Epoch 1396/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4635 - val_loss: 4.0295\n",
      "Epoch 1397/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4643 - val_loss: 4.1273\n",
      "Epoch 1398/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4636 - val_loss: 3.9588\n",
      "Epoch 1399/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4618 - val_loss: 3.7944\n",
      "Epoch 1400/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4633 - val_loss: 3.6885\n",
      "Epoch 1401/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4617 - val_loss: 3.7959\n",
      "Epoch 1402/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4656 - val_loss: 3.9423\n",
      "Epoch 1403/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4601 - val_loss: 3.9065\n",
      "Epoch 1404/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4582 - val_loss: 3.8649\n",
      "Epoch 1405/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4585 - val_loss: 3.8448\n",
      "Epoch 1406/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4568 - val_loss: 3.9268\n",
      "Epoch 1407/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4564 - val_loss: 4.0407\n",
      "Epoch 1408/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4650 - val_loss: 4.1665\n",
      "Epoch 1409/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4709 - val_loss: 3.6694\n",
      "Epoch 1410/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4547 - val_loss: 3.6190\n",
      "Epoch 1411/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4541 - val_loss: 3.5429\n",
      "Epoch 1412/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4535 - val_loss: 3.5083\n",
      "Epoch 1413/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4547 - val_loss: 3.7128\n",
      "Epoch 1414/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4498 - val_loss: 3.8988\n",
      "Epoch 1415/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4545 - val_loss: 3.9982\n",
      "Epoch 1416/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4545 - val_loss: 3.9483\n",
      "Epoch 1417/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4525 - val_loss: 3.6106\n",
      "Epoch 1418/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4487 - val_loss: 3.4373\n",
      "Epoch 1419/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4523 - val_loss: 2.9387\n",
      "Epoch 1420/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4694 - val_loss: 2.5241\n",
      "Epoch 1421/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4790 - val_loss: 2.5329\n",
      "Epoch 1422/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4701 - val_loss: 2.7999\n",
      "Epoch 1423/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4564 - val_loss: 3.1724\n",
      "Epoch 1424/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4512 - val_loss: 3.5968\n",
      "Epoch 1425/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4447 - val_loss: 3.6789\n",
      "Epoch 1426/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4455 - val_loss: 3.5149\n",
      "Epoch 1427/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4515 - val_loss: 3.0106\n",
      "Epoch 1428/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4495 - val_loss: 2.8779\n",
      "Epoch 1429/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4497 - val_loss: 2.8852\n",
      "Epoch 1430/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4495 - val_loss: 3.1335\n",
      "Epoch 1431/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4386 - val_loss: 3.2936\n",
      "Epoch 1432/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4400 - val_loss: 3.2495\n",
      "Epoch 1433/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4391 - val_loss: 3.3008\n",
      "Epoch 1434/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4378 - val_loss: 3.4035\n",
      "Epoch 1435/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4384 - val_loss: 3.6166\n",
      "Epoch 1436/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4427 - val_loss: 3.8048\n",
      "Epoch 1437/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4483 - val_loss: 3.7964\n",
      "Epoch 1438/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4458 - val_loss: 3.7709\n",
      "Epoch 1439/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4439 - val_loss: 3.6289\n",
      "Epoch 1440/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4376 - val_loss: 3.4079\n",
      "Epoch 1441/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4352 - val_loss: 3.2875\n",
      "Epoch 1442/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4343 - val_loss: 3.2235\n",
      "Epoch 1443/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4338 - val_loss: 3.2834\n",
      "Epoch 1444/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4305 - val_loss: 3.2114\n",
      "Epoch 1445/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4323 - val_loss: 3.0939\n",
      "Epoch 1446/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4296 - val_loss: 3.0569\n",
      "Epoch 1447/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4316 - val_loss: 3.2811\n",
      "Epoch 1448/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4289 - val_loss: 3.5546\n",
      "Epoch 1449/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4403 - val_loss: 3.8091\n",
      "Epoch 1450/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4399 - val_loss: 3.7612\n",
      "Epoch 1451/2000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4377 - val_loss: 3.5640\n",
      "Epoch 1452/2000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4387 - val_loss: 2.9285\n",
      "Epoch 1453/2000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.4279 - val_loss: 2.6470\n",
      "Epoch 1454/2000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.4316 - val_loss: 2.6564\n",
      "Epoch 1455/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4284 - val_loss: 2.7548\n",
      "Epoch 1456/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4262 - val_loss: 3.0078\n",
      "Epoch 1457/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4238 - val_loss: 3.3218\n",
      "Epoch 1458/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4226 - val_loss: 3.4337\n",
      "Epoch 1459/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4256 - val_loss: 3.4104\n",
      "Epoch 1460/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4250 - val_loss: 3.3348\n",
      "Epoch 1461/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4218 - val_loss: 3.1564\n",
      "Epoch 1462/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4203 - val_loss: 3.1374\n",
      "Epoch 1463/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4206 - val_loss: 3.0571\n",
      "Epoch 1464/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4194 - val_loss: 2.6599\n",
      "Epoch 1465/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4213 - val_loss: 2.5812\n",
      "Epoch 1466/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4192 - val_loss: 2.7439\n",
      "Epoch 1467/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4138 - val_loss: 2.9816\n",
      "Epoch 1468/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4138 - val_loss: 3.1771\n",
      "Epoch 1469/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4173 - val_loss: 3.2104\n",
      "Epoch 1470/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4167 - val_loss: 3.1108\n",
      "Epoch 1471/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4138 - val_loss: 2.9366\n",
      "Epoch 1472/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4142 - val_loss: 2.7773\n",
      "Epoch 1473/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4118 - val_loss: 2.6753\n",
      "Epoch 1474/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4173 - val_loss: 2.5584\n",
      "Epoch 1475/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4181 - val_loss: 2.6734\n",
      "Epoch 1476/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4120 - val_loss: 2.7129\n",
      "Epoch 1477/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4176 - val_loss: 2.9790\n",
      "Epoch 1478/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4096 - val_loss: 3.0203\n",
      "Epoch 1479/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4107 - val_loss: 3.0840\n",
      "Epoch 1480/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4102 - val_loss: 3.2013\n",
      "Epoch 1481/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4120 - val_loss: 3.1973\n",
      "Epoch 1482/2000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4102 - val_loss: 2.9916\n",
      "Epoch 1483/2000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.803 - 0s 18ms/step - loss: 0.4143 - val_loss: 2.5465\n",
      "Epoch 1484/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4084 - val_loss: 2.3751\n",
      "Epoch 1485/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4124 - val_loss: 2.3338\n",
      "Epoch 1486/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4147 - val_loss: 2.3341\n",
      "Epoch 1487/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4092 - val_loss: 2.6022\n",
      "Epoch 1488/2000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4048 - val_loss: 2.7496\n",
      "Epoch 1489/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4038 - val_loss: 2.8344\n",
      "Epoch 1490/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4039 - val_loss: 2.8672\n",
      "Epoch 1491/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4044 - val_loss: 2.8815\n",
      "Epoch 1492/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4023 - val_loss: 2.8759\n",
      "Epoch 1493/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4010 - val_loss: 2.9840\n",
      "Epoch 1494/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4035 - val_loss: 3.1864\n",
      "Epoch 1495/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4069 - val_loss: 3.2473\n",
      "Epoch 1496/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4075 - val_loss: 3.3093\n",
      "Epoch 1497/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4112 - val_loss: 3.3338\n",
      "Epoch 1498/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4076 - val_loss: 3.1248\n",
      "Epoch 1499/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4018 - val_loss: 2.8603\n",
      "Epoch 1500/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3966 - val_loss: 2.2719\n",
      "Epoch 1501/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4117 - val_loss: 2.0185\n",
      "Epoch 1502/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4136 - val_loss: 2.1010\n",
      "Epoch 1503/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4041 - val_loss: 2.2953\n",
      "Epoch 1504/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3935 - val_loss: 2.6949\n",
      "Epoch 1505/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4029 - val_loss: 3.0269\n",
      "Epoch 1506/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4015 - val_loss: 2.8826\n",
      "Epoch 1507/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3937 - val_loss: 2.3362\n",
      "Epoch 1508/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3954 - val_loss: 2.1568\n",
      "Epoch 1509/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3977 - val_loss: 2.1584\n",
      "Epoch 1510/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3970 - val_loss: 2.1950\n",
      "Epoch 1511/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3991 - val_loss: 2.0678\n",
      "Epoch 1512/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3966 - val_loss: 2.2062\n",
      "Epoch 1513/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3951 - val_loss: 2.3388\n",
      "Epoch 1514/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3919 - val_loss: 2.3665\n",
      "Epoch 1515/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3907 - val_loss: 2.3513\n",
      "Epoch 1516/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3896 - val_loss: 2.5219\n",
      "Epoch 1517/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3902 - val_loss: 2.6413\n",
      "Epoch 1518/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3893 - val_loss: 2.7013\n",
      "Epoch 1519/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3902 - val_loss: 2.6796\n",
      "Epoch 1520/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3893 - val_loss: 2.6044\n",
      "Epoch 1521/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3882 - val_loss: 2.4012\n",
      "Epoch 1522/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3850 - val_loss: 2.2403\n",
      "Epoch 1523/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3891 - val_loss: 2.0971\n",
      "Epoch 1524/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3917 - val_loss: 2.0845\n",
      "Epoch 1525/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3867 - val_loss: 2.2149\n",
      "Epoch 1526/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3875 - val_loss: 2.2884\n",
      "Epoch 1527/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3828 - val_loss: 2.1564\n",
      "Epoch 1528/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3844 - val_loss: 2.0045\n",
      "Epoch 1529/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3942 - val_loss: 1.7447\n",
      "Epoch 1530/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3979 - val_loss: 1.8150\n",
      "Epoch 1531/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3868 - val_loss: 2.1204\n",
      "Epoch 1532/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3774 - val_loss: 2.4115\n",
      "Epoch 1533/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3771 - val_loss: 2.7695\n",
      "Epoch 1534/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3865 - val_loss: 2.9528\n",
      "Epoch 1535/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4011 - val_loss: 3.0315\n",
      "Epoch 1536/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3955 - val_loss: 2.8304\n",
      "Epoch 1537/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3852 - val_loss: 2.5423\n",
      "Epoch 1538/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3847 - val_loss: 2.1845\n",
      "Epoch 1539/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3788 - val_loss: 2.0233\n",
      "Epoch 1540/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3793 - val_loss: 1.9935\n",
      "Epoch 1541/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3796 - val_loss: 2.0160\n",
      "Epoch 1542/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3802 - val_loss: 1.7691\n",
      "Epoch 1543/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3906 - val_loss: 1.5182\n",
      "Epoch 1544/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3974 - val_loss: 1.5634\n",
      "Epoch 1545/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3921 - val_loss: 1.6864\n",
      "Epoch 1546/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3801 - val_loss: 2.0748\n",
      "Epoch 1547/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3783 - val_loss: 2.3928\n",
      "Epoch 1548/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3756 - val_loss: 2.4126\n",
      "Epoch 1549/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3749 - val_loss: 2.3790\n",
      "Epoch 1550/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3742 - val_loss: 2.3277\n",
      "Epoch 1551/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3727 - val_loss: 2.3695\n",
      "Epoch 1552/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3730 - val_loss: 2.3178\n",
      "Epoch 1553/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3719 - val_loss: 2.2534\n",
      "Epoch 1554/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3727 - val_loss: 2.2121\n",
      "Epoch 1555/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3721 - val_loss: 2.3759\n",
      "Epoch 1556/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3722 - val_loss: 2.4241\n",
      "Epoch 1557/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3732 - val_loss: 2.3543\n",
      "Epoch 1558/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3719 - val_loss: 2.3243\n",
      "Epoch 1559/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3697 - val_loss: 2.1343\n",
      "Epoch 1560/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3643 - val_loss: 1.7019\n",
      "Epoch 1561/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3788 - val_loss: 1.5391\n",
      "Epoch 1562/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3802 - val_loss: 1.5605\n",
      "Epoch 1563/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3779 - val_loss: 1.6312\n",
      "Epoch 1564/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3737 - val_loss: 1.7704\n",
      "Epoch 1565/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3697 - val_loss: 1.8800\n",
      "Epoch 1566/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3709 - val_loss: 2.1348\n",
      "Epoch 1567/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3644 - val_loss: 1.9163\n",
      "Epoch 1568/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3671 - val_loss: 1.7594\n",
      "Epoch 1569/2000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.3668 - val_loss: 1.7456\n",
      "Epoch 1570/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3667 - val_loss: 1.7933\n",
      "Epoch 1571/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3627 - val_loss: 2.0289\n",
      "Epoch 1572/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3640 - val_loss: 2.1896\n",
      "Epoch 1573/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3658 - val_loss: 2.3553\n",
      "Epoch 1574/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3692 - val_loss: 2.4724\n",
      "Epoch 1575/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3695 - val_loss: 2.3490\n",
      "Epoch 1576/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3655 - val_loss: 2.1410\n",
      "Epoch 1577/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3597 - val_loss: 2.0401\n",
      "Epoch 1578/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3596 - val_loss: 1.9228\n",
      "Epoch 1579/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3591 - val_loss: 1.9342\n",
      "Epoch 1580/2000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.3582 - val_loss: 1.9499\n",
      "Epoch 1581/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3580 - val_loss: 1.9873\n",
      "Epoch 1582/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3568 - val_loss: 2.0787\n",
      "Epoch 1583/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3579 - val_loss: 2.0955\n",
      "Epoch 1584/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3575 - val_loss: 2.1261\n",
      "Epoch 1585/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3578 - val_loss: 2.1100\n",
      "Epoch 1586/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3579 - val_loss: 1.8988\n",
      "Epoch 1587/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3558 - val_loss: 1.6993\n",
      "Epoch 1588/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3569 - val_loss: 1.6117\n",
      "Epoch 1589/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3586 - val_loss: 1.6810\n",
      "Epoch 1590/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3566 - val_loss: 1.9726\n",
      "Epoch 1591/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3600 - val_loss: 2.2507\n",
      "Epoch 1592/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3593 - val_loss: 2.2031\n",
      "Epoch 1593/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3578 - val_loss: 2.1533\n",
      "Epoch 1594/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3562 - val_loss: 2.1091\n",
      "Epoch 1595/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3543 - val_loss: 2.0216\n",
      "Epoch 1596/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3544 - val_loss: 1.9656\n",
      "Epoch 1597/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3518 - val_loss: 2.0576\n",
      "Epoch 1598/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3527 - val_loss: 2.1997\n",
      "Epoch 1599/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3638 - val_loss: 2.2249\n",
      "Epoch 1600/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3501 - val_loss: 1.6451\n",
      "Epoch 1601/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3527 - val_loss: 1.2752\n",
      "Epoch 1602/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3630 - val_loss: 1.3201\n",
      "Epoch 1603/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3590 - val_loss: 1.4449\n",
      "Epoch 1604/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3542 - val_loss: 1.4408\n",
      "Epoch 1605/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3518 - val_loss: 1.7375\n",
      "Epoch 1606/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3502 - val_loss: 1.9858\n",
      "Epoch 1607/2000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3511 - val_loss: 1.9031\n",
      "Epoch 1608/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3535 - val_loss: 1.7569\n",
      "Epoch 1609/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3492 - val_loss: 1.8744\n",
      "Epoch 1610/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3485 - val_loss: 1.9273\n",
      "Epoch 1611/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3503 - val_loss: 1.9480\n",
      "Epoch 1612/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3519 - val_loss: 2.0489\n",
      "Epoch 1613/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3562 - val_loss: 2.0816\n",
      "Epoch 1614/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3559 - val_loss: 1.9457\n",
      "Epoch 1615/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3501 - val_loss: 1.8736\n",
      "Epoch 1616/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3493 - val_loss: 1.7189\n",
      "Epoch 1617/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3445 - val_loss: 1.5386\n",
      "Epoch 1618/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3429 - val_loss: 1.4214\n",
      "Epoch 1619/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3457 - val_loss: 1.3146\n",
      "Epoch 1620/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3476 - val_loss: 1.3855\n",
      "Epoch 1621/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3449 - val_loss: 1.6073\n",
      "Epoch 1622/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3423 - val_loss: 1.7423\n",
      "Epoch 1623/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3402 - val_loss: 1.8886\n",
      "Epoch 1624/2000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.3430 - val_loss: 1.8901\n",
      "Epoch 1625/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3426 - val_loss: 1.7885\n",
      "Epoch 1626/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3409 - val_loss: 1.6870\n",
      "Epoch 1627/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3402 - val_loss: 1.6943\n",
      "Epoch 1628/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3394 - val_loss: 1.9002\n",
      "Epoch 1629/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3475 - val_loss: 2.1010\n",
      "Epoch 1630/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3481 - val_loss: 2.0217\n",
      "Epoch 1631/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3432 - val_loss: 1.7572\n",
      "Epoch 1632/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3379 - val_loss: 1.5851\n",
      "Epoch 1633/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3359 - val_loss: 1.5855\n",
      "Epoch 1634/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3360 - val_loss: 1.6108\n",
      "Epoch 1635/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3350 - val_loss: 1.6134\n",
      "Epoch 1636/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3352 - val_loss: 1.7016\n",
      "Epoch 1637/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3376 - val_loss: 1.7161\n",
      "Epoch 1638/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3338 - val_loss: 1.4369\n",
      "Epoch 1639/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3363 - val_loss: 1.2634\n",
      "Epoch 1640/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3394 - val_loss: 1.2396\n",
      "Epoch 1641/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3399 - val_loss: 1.2893\n",
      "Epoch 1642/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3357 - val_loss: 1.3798\n",
      "Epoch 1643/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3332 - val_loss: 1.6336\n",
      "Epoch 1644/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3313 - val_loss: 1.7218\n",
      "Epoch 1645/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3320 - val_loss: 1.7736\n",
      "Epoch 1646/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3323 - val_loss: 1.8625\n",
      "Epoch 1647/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3349 - val_loss: 1.7672\n",
      "Epoch 1648/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3369 - val_loss: 1.3895\n",
      "Epoch 1649/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3348 - val_loss: 1.2622\n",
      "Epoch 1650/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3345 - val_loss: 1.2532\n",
      "Epoch 1651/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3356 - val_loss: 1.1312\n",
      "Epoch 1652/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3390 - val_loss: 1.1471\n",
      "Epoch 1653/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3371 - val_loss: 1.2216\n",
      "Epoch 1654/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3324 - val_loss: 1.3397\n",
      "Epoch 1655/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3243 - val_loss: 1.6438\n",
      "Epoch 1656/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3253 - val_loss: 1.9252\n",
      "Epoch 1657/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3368 - val_loss: 1.9598\n",
      "Epoch 1658/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3361 - val_loss: 1.6698\n",
      "Epoch 1659/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3261 - val_loss: 1.4241\n",
      "Epoch 1660/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3260 - val_loss: 1.1732\n",
      "Epoch 1661/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3385 - val_loss: 1.0246\n",
      "Epoch 1662/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3494 - val_loss: 0.9826\n",
      "Epoch 1663/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3399 - val_loss: 1.3038\n",
      "Epoch 1664/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3249 - val_loss: 1.6179\n",
      "Epoch 1665/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3239 - val_loss: 1.7925\n",
      "Epoch 1666/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3317 - val_loss: 1.8374\n",
      "Epoch 1667/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3258 - val_loss: 1.5743\n",
      "Epoch 1668/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3368 - val_loss: 1.1022\n",
      "Epoch 1669/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3338 - val_loss: 1.0818\n",
      "Epoch 1670/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3326 - val_loss: 1.1511\n",
      "Epoch 1671/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3256 - val_loss: 1.3307\n",
      "Epoch 1672/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3243 - val_loss: 1.6692\n",
      "Epoch 1673/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3257 - val_loss: 1.9590\n",
      "Epoch 1674/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3374 - val_loss: 2.0682\n",
      "Epoch 1675/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3349 - val_loss: 1.7230\n",
      "Epoch 1676/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3170 - val_loss: 1.2042\n",
      "Epoch 1677/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3214 - val_loss: 0.9442\n",
      "Epoch 1678/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3375 - val_loss: 0.8920\n",
      "Epoch 1679/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3333 - val_loss: 1.1554\n",
      "Epoch 1680/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3238 - val_loss: 1.6143\n",
      "Epoch 1681/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3224 - val_loss: 1.9393\n",
      "Epoch 1682/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3377 - val_loss: 1.9693\n",
      "Epoch 1683/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3205 - val_loss: 1.3892\n",
      "Epoch 1684/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3278 - val_loss: 0.8203\n",
      "Epoch 1685/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3393 - val_loss: 0.8351\n",
      "Epoch 1686/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3278 - val_loss: 1.1221\n",
      "Epoch 1687/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3116 - val_loss: 1.4101\n",
      "Epoch 1688/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3138 - val_loss: 1.7005\n",
      "Epoch 1689/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3245 - val_loss: 1.7923\n",
      "Epoch 1690/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3290 - val_loss: 1.7654\n",
      "Epoch 1691/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3207 - val_loss: 1.5050\n",
      "Epoch 1692/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3196 - val_loss: 1.1812\n",
      "Epoch 1693/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3159 - val_loss: 1.1675\n",
      "Epoch 1694/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3135 - val_loss: 1.3876\n",
      "Epoch 1695/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3135 - val_loss: 1.5109\n",
      "Epoch 1696/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3148 - val_loss: 1.5615\n",
      "Epoch 1697/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3166 - val_loss: 1.4841\n",
      "Epoch 1698/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3118 - val_loss: 1.1145\n",
      "Epoch 1699/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3151 - val_loss: 0.9062\n",
      "Epoch 1700/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3203 - val_loss: 0.8763\n",
      "Epoch 1701/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3207 - val_loss: 0.9018\n",
      "Epoch 1702/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3175 - val_loss: 1.0059\n",
      "Epoch 1703/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3127 - val_loss: 1.1606\n",
      "Epoch 1704/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3108 - val_loss: 1.2242\n",
      "Epoch 1705/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3077 - val_loss: 1.0498\n",
      "Epoch 1706/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3098 - val_loss: 0.8094\n",
      "Epoch 1707/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3283 - val_loss: 0.7260\n",
      "Epoch 1708/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3292 - val_loss: 0.8563\n",
      "Epoch 1709/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3114 - val_loss: 1.0903\n",
      "Epoch 1710/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3059 - val_loss: 1.4176\n",
      "Epoch 1711/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3158 - val_loss: 1.6786\n",
      "Epoch 1712/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3211 - val_loss: 1.5625\n",
      "Epoch 1713/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3073 - val_loss: 0.9864\n",
      "Epoch 1714/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3236 - val_loss: 0.7302\n",
      "Epoch 1715/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3212 - val_loss: 0.8793\n",
      "Epoch 1716/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3094 - val_loss: 1.0384\n",
      "Epoch 1717/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3031 - val_loss: 1.2345\n",
      "Epoch 1718/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3027 - val_loss: 1.3777\n",
      "Epoch 1719/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3105 - val_loss: 1.5510\n",
      "Epoch 1720/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3149 - val_loss: 1.5129\n",
      "Epoch 1721/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3100 - val_loss: 1.2410\n",
      "Epoch 1722/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3004 - val_loss: 1.0866\n",
      "Epoch 1723/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3044 - val_loss: 0.9715\n",
      "Epoch 1724/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3032 - val_loss: 0.9962\n",
      "Epoch 1725/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3018 - val_loss: 1.0442\n",
      "Epoch 1726/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3028 - val_loss: 1.1517\n",
      "Epoch 1727/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3004 - val_loss: 1.1345\n",
      "Epoch 1728/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2993 - val_loss: 1.2358\n",
      "Epoch 1729/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2993 - val_loss: 1.3437\n",
      "Epoch 1730/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3023 - val_loss: 1.3426\n",
      "Epoch 1731/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3042 - val_loss: 1.1849\n",
      "Epoch 1732/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3005 - val_loss: 1.1564\n",
      "Epoch 1733/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2982 - val_loss: 1.2075\n",
      "Epoch 1734/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2999 - val_loss: 1.3825\n",
      "Epoch 1735/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3058 - val_loss: 1.4200\n",
      "Epoch 1736/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2988 - val_loss: 1.0881\n",
      "Epoch 1737/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2917 - val_loss: 0.8249\n",
      "Epoch 1738/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3041 - val_loss: 0.6086\n",
      "Epoch 1739/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3186 - val_loss: 0.6532\n",
      "Epoch 1740/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3098 - val_loss: 0.8129\n",
      "Epoch 1741/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2990 - val_loss: 1.0509\n",
      "Epoch 1742/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2964 - val_loss: 1.1771\n",
      "Epoch 1743/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2952 - val_loss: 1.1612\n",
      "Epoch 1744/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2964 - val_loss: 1.0422\n",
      "Epoch 1745/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2937 - val_loss: 0.9628\n",
      "Epoch 1746/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2939 - val_loss: 0.7948\n",
      "Epoch 1747/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2981 - val_loss: 0.8851\n",
      "Epoch 1748/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2894 - val_loss: 1.1317\n",
      "Epoch 1749/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2949 - val_loss: 1.4435\n",
      "Epoch 1750/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3020 - val_loss: 1.4404\n",
      "Epoch 1751/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3019 - val_loss: 1.3757\n",
      "Epoch 1752/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2992 - val_loss: 1.2779\n",
      "Epoch 1753/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2963 - val_loss: 1.0116\n",
      "Epoch 1754/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2928 - val_loss: 0.8316\n",
      "Epoch 1755/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2943 - val_loss: 0.8053\n",
      "Epoch 1756/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2927 - val_loss: 1.0393\n",
      "Epoch 1757/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2895 - val_loss: 1.3601\n",
      "Epoch 1758/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3036 - val_loss: 1.5983\n",
      "Epoch 1759/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3059 - val_loss: 1.4474\n",
      "Epoch 1760/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2947 - val_loss: 1.2183\n",
      "Epoch 1761/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2895 - val_loss: 0.9889\n",
      "Epoch 1762/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2886 - val_loss: 1.0050\n",
      "Epoch 1763/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2859 - val_loss: 1.1322\n",
      "Epoch 1764/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2948 - val_loss: 1.2935\n",
      "Epoch 1765/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2957 - val_loss: 1.0112\n",
      "Epoch 1766/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2868 - val_loss: 0.8688\n",
      "Epoch 1767/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2865 - val_loss: 0.6902\n",
      "Epoch 1768/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2948 - val_loss: 0.6927\n",
      "Epoch 1769/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2902 - val_loss: 0.8991\n",
      "Epoch 1770/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2892 - val_loss: 1.1549\n",
      "Epoch 1771/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2862 - val_loss: 1.0844\n",
      "Epoch 1772/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2866 - val_loss: 0.9741\n",
      "Epoch 1773/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2841 - val_loss: 0.8839\n",
      "Epoch 1774/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2833 - val_loss: 0.7637\n",
      "Epoch 1775/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2862 - val_loss: 0.7964\n",
      "Epoch 1776/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2827 - val_loss: 0.9843\n",
      "Epoch 1777/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2830 - val_loss: 1.1907\n",
      "Epoch 1778/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2884 - val_loss: 1.2316\n",
      "Epoch 1779/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2887 - val_loss: 1.0740\n",
      "Epoch 1780/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2841 - val_loss: 0.9775\n",
      "Epoch 1781/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2812 - val_loss: 1.0031\n",
      "Epoch 1782/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2813 - val_loss: 1.0741\n",
      "Epoch 1783/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2841 - val_loss: 1.1744\n",
      "Epoch 1784/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2851 - val_loss: 1.1080\n",
      "Epoch 1785/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2823 - val_loss: 0.9552\n",
      "Epoch 1786/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2799 - val_loss: 0.8638\n",
      "Epoch 1787/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2796 - val_loss: 0.8081\n",
      "Epoch 1788/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2795 - val_loss: 0.6094\n",
      "Epoch 1789/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2883 - val_loss: 0.5819\n",
      "Epoch 1790/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2864 - val_loss: 0.6759\n",
      "Epoch 1791/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.2811 - val_loss: 0.8700\n",
      "Epoch 1792/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2788 - val_loss: 1.1230\n",
      "Epoch 1793/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2924 - val_loss: 1.2342\n",
      "Epoch 1794/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2864 - val_loss: 1.0243\n",
      "Epoch 1795/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2810 - val_loss: 0.8334\n",
      "Epoch 1796/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2771 - val_loss: 0.7525\n",
      "Epoch 1797/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2764 - val_loss: 0.7829\n",
      "Epoch 1798/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2763 - val_loss: 0.8480\n",
      "Epoch 1799/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2753 - val_loss: 0.8306\n",
      "Epoch 1800/2000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.2760 - val_loss: 0.8300\n",
      "Epoch 1801/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2741 - val_loss: 0.7609\n",
      "Epoch 1802/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2747 - val_loss: 0.7386\n",
      "Epoch 1803/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2745 - val_loss: 0.7180\n",
      "Epoch 1804/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2765 - val_loss: 0.7962\n",
      "Epoch 1805/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2735 - val_loss: 0.6349\n",
      "Epoch 1806/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2765 - val_loss: 0.5877\n",
      "Epoch 1807/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.2768 - val_loss: 0.6679\n",
      "Epoch 1808/2000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.2748 - val_loss: 0.6993\n",
      "Epoch 1809/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2727 - val_loss: 0.6435\n",
      "Epoch 1810/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2744 - val_loss: 0.7033\n",
      "Epoch 1811/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2719 - val_loss: 0.6425\n",
      "Epoch 1812/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2721 - val_loss: 0.7407\n",
      "Epoch 1813/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2719 - val_loss: 0.9400\n",
      "Epoch 1814/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2713 - val_loss: 0.9624\n",
      "Epoch 1815/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2709 - val_loss: 1.0167\n",
      "Epoch 1816/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2733 - val_loss: 1.0398\n",
      "Epoch 1817/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2732 - val_loss: 1.0015\n",
      "Epoch 1818/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2738 - val_loss: 0.9634\n",
      "Epoch 1819/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2694 - val_loss: 0.6535\n",
      "Epoch 1820/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2706 - val_loss: 0.5149\n",
      "Epoch 1821/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2768 - val_loss: 0.5325\n",
      "Epoch 1822/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2710 - val_loss: 0.7737\n",
      "Epoch 1823/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2700 - val_loss: 0.9704\n",
      "Epoch 1824/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2685 - val_loss: 0.9259\n",
      "Epoch 1825/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2680 - val_loss: 0.7723\n",
      "Epoch 1826/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2650 - val_loss: 0.7563\n",
      "Epoch 1827/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2656 - val_loss: 0.8136\n",
      "Epoch 1828/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2650 - val_loss: 0.8598\n",
      "Epoch 1829/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2651 - val_loss: 0.8241\n",
      "Epoch 1830/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2634 - val_loss: 0.8920\n",
      "Epoch 1831/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2642 - val_loss: 0.8642\n",
      "Epoch 1832/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2631 - val_loss: 0.7897\n",
      "Epoch 1833/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2637 - val_loss: 0.7778\n",
      "Epoch 1834/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2638 - val_loss: 0.7637\n",
      "Epoch 1835/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2621 - val_loss: 0.8375\n",
      "Epoch 1836/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2685 - val_loss: 0.9199\n",
      "Epoch 1837/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2623 - val_loss: 0.6525\n",
      "Epoch 1838/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2634 - val_loss: 0.6074\n",
      "Epoch 1839/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2630 - val_loss: 0.6145\n",
      "Epoch 1840/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.2626 - val_loss: 0.6375\n",
      "Epoch 1841/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2612 - val_loss: 0.6567\n",
      "Epoch 1842/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2624 - val_loss: 0.7592\n",
      "Epoch 1843/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2607 - val_loss: 0.8089\n",
      "Epoch 1844/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2577 - val_loss: 0.6588\n",
      "Epoch 1845/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2656 - val_loss: 0.4782\n",
      "Epoch 1846/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2709 - val_loss: 0.5173\n",
      "Epoch 1847/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.2679 - val_loss: 0.7953\n",
      "Epoch 1848/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.2600 - val_loss: 0.8757\n",
      "Epoch 1849/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2585 - val_loss: 0.7807\n",
      "Epoch 1850/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2572 - val_loss: 0.7749\n",
      "Epoch 1851/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2571 - val_loss: 0.7324\n",
      "Epoch 1852/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2633 - val_loss: 0.5838\n",
      "Epoch 1853/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2579 - val_loss: 0.6848\n",
      "Epoch 1854/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2588 - val_loss: 0.8054\n",
      "Epoch 1855/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2561 - val_loss: 0.8066\n",
      "Epoch 1856/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2559 - val_loss: 0.7723\n",
      "Epoch 1857/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2554 - val_loss: 0.7872\n",
      "Epoch 1858/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2561 - val_loss: 0.8506\n",
      "Epoch 1859/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2567 - val_loss: 0.8468\n",
      "Epoch 1860/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2575 - val_loss: 0.8166\n",
      "Epoch 1861/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2541 - val_loss: 0.7251\n",
      "Epoch 1862/2000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.2533 - val_loss: 0.7503\n",
      "Epoch 1863/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.2530 - val_loss: 0.8021\n",
      "Epoch 1864/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2545 - val_loss: 0.7753\n",
      "Epoch 1865/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2532 - val_loss: 0.7120\n",
      "Epoch 1866/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2518 - val_loss: 0.6640\n",
      "Epoch 1867/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2505 - val_loss: 0.7114\n",
      "Epoch 1868/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2518 - val_loss: 0.7523\n",
      "Epoch 1869/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2513 - val_loss: 0.8076\n",
      "Epoch 1870/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2534 - val_loss: 0.7137\n",
      "Epoch 1871/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2519 - val_loss: 0.5972\n",
      "Epoch 1872/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2529 - val_loss: 0.5511\n",
      "Epoch 1873/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2510 - val_loss: 0.7138\n",
      "Epoch 1874/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2490 - val_loss: 0.8117\n",
      "Epoch 1875/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2522 - val_loss: 0.7968\n",
      "Epoch 1876/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.2511 - val_loss: 0.7717\n",
      "Epoch 1877/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2507 - val_loss: 0.7727\n",
      "Epoch 1878/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2508 - val_loss: 0.8299\n",
      "Epoch 1879/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2531 - val_loss: 0.8403\n",
      "Epoch 1880/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2529 - val_loss: 0.7886\n",
      "Epoch 1881/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2508 - val_loss: 0.6969\n",
      "Epoch 1882/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2472 - val_loss: 0.6221\n",
      "Epoch 1883/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2468 - val_loss: 0.5671\n",
      "Epoch 1884/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2462 - val_loss: 0.5310\n",
      "Epoch 1885/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2453 - val_loss: 0.5620\n",
      "Epoch 1886/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2453 - val_loss: 0.5586\n",
      "Epoch 1887/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2455 - val_loss: 0.5261\n",
      "Epoch 1888/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2452 - val_loss: 0.5023\n",
      "Epoch 1889/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2444 - val_loss: 0.5444\n",
      "Epoch 1890/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2430 - val_loss: 0.5791\n",
      "Epoch 1891/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2422 - val_loss: 0.6480\n",
      "Epoch 1892/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2436 - val_loss: 0.6903\n",
      "Epoch 1893/2000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2443 - val_loss: 0.7039\n",
      "Epoch 1894/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2439 - val_loss: 0.5849\n",
      "Epoch 1895/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2424 - val_loss: 0.5537\n",
      "Epoch 1896/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2436 - val_loss: 0.6201\n",
      "Epoch 1897/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2420 - val_loss: 0.4789\n",
      "Epoch 1898/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2446 - val_loss: 0.4183\n",
      "Epoch 1899/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2411 - val_loss: 0.5459\n",
      "Epoch 1900/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2401 - val_loss: 0.7711\n",
      "Epoch 1901/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2448 - val_loss: 0.8874\n",
      "Epoch 1902/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2515 - val_loss: 0.8771\n",
      "Epoch 1903/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2492 - val_loss: 0.7259\n",
      "Epoch 1904/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2399 - val_loss: 0.5728\n",
      "Epoch 1905/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2397 - val_loss: 0.3935\n",
      "Epoch 1906/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2475 - val_loss: 0.3184\n",
      "Epoch 1907/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2452 - val_loss: 0.4290\n",
      "Epoch 1908/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2330 - val_loss: 0.6716\n",
      "Epoch 1909/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2389 - val_loss: 0.9408\n",
      "Epoch 1910/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.2613 - val_loss: 0.8918\n",
      "Epoch 1911/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2459 - val_loss: 0.3893\n",
      "Epoch 1912/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2424 - val_loss: 0.2735\n",
      "Epoch 1913/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2490 - val_loss: 0.2885\n",
      "Epoch 1914/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.2459 - val_loss: 0.3794\n",
      "Epoch 1915/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2400 - val_loss: 0.5799\n",
      "Epoch 1916/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2360 - val_loss: 0.5219\n",
      "Epoch 1917/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2336 - val_loss: 0.5711\n",
      "Epoch 1918/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2337 - val_loss: 0.5748\n",
      "Epoch 1919/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2332 - val_loss: 0.5133\n",
      "Epoch 1920/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.2331 - val_loss: 0.4098\n",
      "Epoch 1921/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.2399 - val_loss: 0.2988\n",
      "Epoch 1922/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.2414 - val_loss: 0.3849\n",
      "Epoch 1923/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2350 - val_loss: 0.4528\n",
      "Epoch 1924/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2324 - val_loss: 0.5360\n",
      "Epoch 1925/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2331 - val_loss: 0.5102\n",
      "Epoch 1926/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2330 - val_loss: 0.5728\n",
      "Epoch 1927/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2323 - val_loss: 0.6267\n",
      "Epoch 1928/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2327 - val_loss: 0.6398\n",
      "Epoch 1929/2000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2318 - val_loss: 0.5301\n",
      "Epoch 1930/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2313 - val_loss: 0.4097\n",
      "Epoch 1931/2000\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2345 - val_loss: 0.3927\n",
      "Epoch 1932/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2309 - val_loss: 0.5389\n",
      "Epoch 1933/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2308 - val_loss: 0.8030\n",
      "Epoch 1934/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2418 - val_loss: 0.8192\n",
      "Epoch 1935/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2338 - val_loss: 0.4664\n",
      "Epoch 1936/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2347 - val_loss: 0.3276\n",
      "Epoch 1937/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2337 - val_loss: 0.4642\n",
      "Epoch 1938/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2282 - val_loss: 0.6464\n",
      "Epoch 1939/2000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.2337 - val_loss: 0.7573\n",
      "Epoch 1940/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2361 - val_loss: 0.6692\n",
      "Epoch 1941/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2305 - val_loss: 0.5853\n",
      "Epoch 1942/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2268 - val_loss: 0.4481\n",
      "Epoch 1943/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2253 - val_loss: 0.3575\n",
      "Epoch 1944/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2302 - val_loss: 0.3317\n",
      "Epoch 1945/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2315 - val_loss: 0.3772\n",
      "Epoch 1946/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2269 - val_loss: 0.4768\n",
      "Epoch 1947/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2255 - val_loss: 0.5318\n",
      "Epoch 1948/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2258 - val_loss: 0.5584\n",
      "Epoch 1949/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2248 - val_loss: 0.4932\n",
      "Epoch 1950/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2232 - val_loss: 0.4550\n",
      "Epoch 1951/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2234 - val_loss: 0.4259\n",
      "Epoch 1952/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2245 - val_loss: 0.3767\n",
      "Epoch 1953/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2259 - val_loss: 0.3272\n",
      "Epoch 1954/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2267 - val_loss: 0.3753\n",
      "Epoch 1955/2000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2201 - val_loss: 0.5635\n",
      "Epoch 1956/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2229 - val_loss: 0.7385\n",
      "Epoch 1957/2000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.2295 - val_loss: 0.6633\n",
      "Epoch 1958/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2256 - val_loss: 0.5953\n",
      "Epoch 1959/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2221 - val_loss: 0.5311\n",
      "Epoch 1960/2000\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2210 - val_loss: 0.4050\n",
      "Epoch 1961/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2211 - val_loss: 0.4094\n",
      "Epoch 1962/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2248 - val_loss: 0.5417\n",
      "Epoch 1963/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2195 - val_loss: 0.5140\n",
      "Epoch 1964/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2203 - val_loss: 0.5279\n",
      "Epoch 1965/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2188 - val_loss: 0.4909\n",
      "Epoch 1966/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2189 - val_loss: 0.4912\n",
      "Epoch 1967/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2177 - val_loss: 0.4267\n",
      "Epoch 1968/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2188 - val_loss: 0.4338\n",
      "Epoch 1969/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2185 - val_loss: 0.3108\n",
      "Epoch 1970/2000\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2217 - val_loss: 0.2730\n",
      "Epoch 1971/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2233 - val_loss: 0.3182\n",
      "Epoch 1972/2000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2179 - val_loss: 0.4526\n",
      "Epoch 1973/2000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2162 - val_loss: 0.6698\n",
      "Epoch 1974/2000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2238 - val_loss: 0.7585\n",
      "Epoch 1975/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2264 - val_loss: 0.6239\n",
      "Epoch 1976/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2198 - val_loss: 0.4961\n",
      "Epoch 1977/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2152 - val_loss: 0.2608\n",
      "Epoch 1978/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2210 - val_loss: 0.2471\n",
      "Epoch 1979/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2202 - val_loss: 0.3219\n",
      "Epoch 1980/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2138 - val_loss: 0.5376\n",
      "Epoch 1981/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2201 - val_loss: 0.6904\n",
      "Epoch 1982/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2232 - val_loss: 0.6231\n",
      "Epoch 1983/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.2149 - val_loss: 0.4189\n",
      "Epoch 1984/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2133 - val_loss: 0.2591\n",
      "Epoch 1985/2000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2177 - val_loss: 0.2897\n",
      "Epoch 1986/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2131 - val_loss: 0.4776\n",
      "Epoch 1987/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2204 - val_loss: 0.6801\n",
      "Epoch 1988/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2247 - val_loss: 0.6482\n",
      "Epoch 1989/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2167 - val_loss: 0.4201\n",
      "Epoch 1990/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2139 - val_loss: 0.1591\n",
      "Epoch 1991/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2272 - val_loss: 0.1167\n",
      "Epoch 1992/2000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2309 - val_loss: 0.2088\n",
      "Epoch 1993/2000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2112 - val_loss: 0.4909\n",
      "Epoch 1994/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.2146 - val_loss: 0.7471\n",
      "Epoch 1995/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.2253 - val_loss: 0.6474\n",
      "Epoch 1996/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.2147 - val_loss: 0.4587\n",
      "Epoch 1997/2000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.2083 - val_loss: 0.3620\n",
      "Epoch 1998/2000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.2079 - val_loss: 0.2742\n",
      "Epoch 1999/2000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.2126 - val_loss: 0.2757\n",
      "Epoch 2000/2000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2082 - val_loss: 0.4224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x227b8efa6a0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=2000, validation_split=0.2, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 1, 50)             10400     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 30,651\n",
      "Trainable params: 30,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#stacked LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(1, 1)))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 21020.3223 - val_loss: 77177.5625\n",
      "Epoch 2/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 21008.8027 - val_loss: 77133.3125\n",
      "Epoch 3/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 20996.9551 - val_loss: 77083.6719\n",
      "Epoch 4/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 20981.5781 - val_loss: 77026.8750\n",
      "Epoch 5/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 20967.8223 - val_loss: 76956.7031\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 20948.9844 - val_loss: 76871.4375\n",
      "Epoch 7/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 20925.5527 - val_loss: 76770.5000\n",
      "Epoch 8/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 20902.1328 - val_loss: 76641.2812\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 20870.2891 - val_loss: 76483.3438\n",
      "Epoch 10/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 20836.0488 - val_loss: 76293.1250\n",
      "Epoch 11/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 20787.1797 - val_loss: 76060.6719\n",
      "Epoch 12/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 20730.3867 - val_loss: 75756.3594\n",
      "Epoch 13/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 20663.4277 - val_loss: 75359.2656\n",
      "Epoch 14/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 20576.5391 - val_loss: 74833.1562\n",
      "Epoch 15/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 20451.4199 - val_loss: 74208.2578\n",
      "Epoch 16/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 20318.8418 - val_loss: 73415.1172\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 20158.1250 - val_loss: 72470.4375\n",
      "Epoch 18/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 19889.8945 - val_loss: 71396.8438\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 19661.0625 - val_loss: 70020.9688\n",
      "Epoch 20/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 19295.3379 - val_loss: 68433.7578\n",
      "Epoch 21/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 18914.0586 - val_loss: 66671.8750\n",
      "Epoch 22/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 18482.1680 - val_loss: 64781.0273\n",
      "Epoch 23/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 18001.7891 - val_loss: 62864.2109\n",
      "Epoch 24/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 17471.7266 - val_loss: 60852.2109\n",
      "Epoch 25/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 16956.2715 - val_loss: 58598.3867\n",
      "Epoch 26/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 16378.3525 - val_loss: 56306.8711\n",
      "Epoch 27/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 15767.2793 - val_loss: 53949.4922\n",
      "Epoch 28/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 15108.9072 - val_loss: 51577.4453\n",
      "Epoch 29/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 14541.4092 - val_loss: 48951.2070\n",
      "Epoch 30/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 13788.6475 - val_loss: 46261.5117\n",
      "Epoch 31/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 13165.2754 - val_loss: 43430.6641\n",
      "Epoch 32/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 12418.9932 - val_loss: 40441.9805\n",
      "Epoch 33/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 11577.6660 - val_loss: 37354.7344\n",
      "Epoch 34/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 10724.8477 - val_loss: 34218.2812\n",
      "Epoch 35/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 10011.6211 - val_loss: 30713.1953\n",
      "Epoch 36/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 9095.5029 - val_loss: 27406.6562\n",
      "Epoch 37/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 8159.1343 - val_loss: 24280.9395\n",
      "Epoch 38/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 7409.4385 - val_loss: 20912.7246\n",
      "Epoch 39/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6454.9912 - val_loss: 17724.7461\n",
      "Epoch 40/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5592.3735 - val_loss: 14864.7969\n",
      "Epoch 41/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4808.4033 - val_loss: 12144.8008\n",
      "Epoch 42/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4103.9761 - val_loss: 9685.9590\n",
      "Epoch 43/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3390.9807 - val_loss: 7636.2246\n",
      "Epoch 44/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2790.2920 - val_loss: 5838.0049\n",
      "Epoch 45/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2247.1270 - val_loss: 4321.5410\n",
      "Epoch 46/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1823.7869 - val_loss: 3018.1528\n",
      "Epoch 47/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1400.8038 - val_loss: 2039.2745\n",
      "Epoch 48/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1059.5128 - val_loss: 1318.2533\n",
      "Epoch 49/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 802.8925 - val_loss: 759.5487\n",
      "Epoch 50/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 603.4323 - val_loss: 363.6614\n",
      "Epoch 51/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 420.3888 - val_loss: 136.2594\n",
      "Epoch 52/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 304.4524 - val_loss: 26.2637\n",
      "Epoch 53/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 224.8037 - val_loss: 4.1176\n",
      "Epoch 54/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 165.9146 - val_loss: 37.2280\n",
      "Epoch 55/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 130.8577 - val_loss: 100.1254\n",
      "Epoch 56/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 111.7932 - val_loss: 175.0759\n",
      "Epoch 57/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 101.3362 - val_loss: 248.8258\n",
      "Epoch 58/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 97.0020 - val_loss: 316.2586\n",
      "Epoch 59/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 95.6094 - val_loss: 369.6113\n",
      "Epoch 60/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 95.1127 - val_loss: 401.6584\n",
      "Epoch 61/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 94.8094 - val_loss: 421.6870\n",
      "Epoch 62/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 95.4370 - val_loss: 439.3856\n",
      "Epoch 63/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 94.8735 - val_loss: 445.8023\n",
      "Epoch 64/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 94.2147 - val_loss: 446.5620\n",
      "Epoch 65/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 93.6053 - val_loss: 440.7881\n",
      "Epoch 66/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 92.9945 - val_loss: 437.8758\n",
      "Epoch 67/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 92.7227 - val_loss: 420.2803\n",
      "Epoch 68/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 91.1355 - val_loss: 408.6180\n",
      "Epoch 69/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 90.1477 - val_loss: 372.6517\n",
      "Epoch 70/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 88.8742 - val_loss: 346.5268\n",
      "Epoch 71/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 87.9986 - val_loss: 332.7897\n",
      "Epoch 72/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 87.1507 - val_loss: 323.0146\n",
      "Epoch 73/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 86.5392 - val_loss: 314.2820\n",
      "Epoch 74/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 85.9719 - val_loss: 312.3522\n",
      "Epoch 75/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 85.1819 - val_loss: 316.9495\n",
      "Epoch 76/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 84.6537 - val_loss: 326.6754\n",
      "Epoch 77/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 84.0811 - val_loss: 333.8924\n",
      "Epoch 78/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 83.5324 - val_loss: 337.2797\n",
      "Epoch 79/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 83.2007 - val_loss: 340.5010\n",
      "Epoch 80/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 82.8237 - val_loss: 342.3571\n",
      "Epoch 81/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 82.2196 - val_loss: 334.4748\n",
      "Epoch 82/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 81.4103 - val_loss: 321.6120\n",
      "Epoch 83/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 80.7597 - val_loss: 309.7816\n",
      "Epoch 84/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 79.7807 - val_loss: 287.2401\n",
      "Epoch 85/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 79.6531 - val_loss: 262.6541\n",
      "Epoch 86/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 79.7138 - val_loss: 244.9327\n",
      "Epoch 87/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 79.2002 - val_loss: 239.8822\n",
      "Epoch 88/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 78.6615 - val_loss: 242.8028\n",
      "Epoch 89/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 77.9918 - val_loss: 244.4199\n",
      "Epoch 90/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 77.4130 - val_loss: 238.9470\n",
      "Epoch 91/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 76.8556 - val_loss: 239.7794\n",
      "Epoch 92/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 76.1760 - val_loss: 232.7819\n",
      "Epoch 93/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 75.7013 - val_loss: 234.5468\n",
      "Epoch 94/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 74.8760 - val_loss: 241.0819\n",
      "Epoch 95/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 74.5243 - val_loss: 250.0089\n",
      "Epoch 96/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 73.5731 - val_loss: 245.2282\n",
      "Epoch 97/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 72.8703 - val_loss: 233.8879\n",
      "Epoch 98/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 72.5606 - val_loss: 214.6335\n",
      "Epoch 99/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 72.7161 - val_loss: 206.3687\n",
      "Epoch 100/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 72.1025 - val_loss: 209.5892\n",
      "Epoch 101/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 71.3144 - val_loss: 214.6697\n",
      "Epoch 102/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 70.5428 - val_loss: 225.2292\n",
      "Epoch 103/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 69.9356 - val_loss: 237.2065\n",
      "Epoch 104/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 69.4131 - val_loss: 249.4464\n",
      "Epoch 105/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 68.6888 - val_loss: 251.0514\n",
      "Epoch 106/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 68.2317 - val_loss: 249.8731\n",
      "Epoch 107/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 67.8899 - val_loss: 256.6224\n",
      "Epoch 108/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 67.1177 - val_loss: 254.5721\n",
      "Epoch 109/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 66.6903 - val_loss: 251.3510\n",
      "Epoch 110/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 66.1464 - val_loss: 236.9852\n",
      "Epoch 111/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 65.5382 - val_loss: 231.6970\n",
      "Epoch 112/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 65.0733 - val_loss: 234.7553\n",
      "Epoch 113/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 64.5072 - val_loss: 238.9271\n",
      "Epoch 114/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 63.9895 - val_loss: 245.2563\n",
      "Epoch 115/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 63.3930 - val_loss: 252.0211\n",
      "Epoch 116/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 62.8183 - val_loss: 260.3407\n",
      "Epoch 117/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 62.7775 - val_loss: 272.5296\n",
      "Epoch 118/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 62.0436 - val_loss: 276.5637\n",
      "Epoch 119/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 62.1497 - val_loss: 281.3228\n",
      "Epoch 120/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 61.8022 - val_loss: 261.3412\n",
      "Epoch 121/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 60.4562 - val_loss: 250.5898\n",
      "Epoch 122/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 59.8944 - val_loss: 243.1360\n",
      "Epoch 123/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 59.3613 - val_loss: 238.2646\n",
      "Epoch 124/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 58.8696 - val_loss: 230.9596\n",
      "Epoch 125/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 58.3613 - val_loss: 223.3365\n",
      "Epoch 126/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 57.8363 - val_loss: 220.1576\n",
      "Epoch 127/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 57.5940 - val_loss: 211.3676\n",
      "Epoch 128/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 56.8908 - val_loss: 214.1383\n",
      "Epoch 129/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 56.5538 - val_loss: 222.7992\n",
      "Epoch 130/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 56.0585 - val_loss: 229.5819\n",
      "Epoch 131/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 55.5791 - val_loss: 233.3486\n",
      "Epoch 132/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 55.3057 - val_loss: 238.5747\n",
      "Epoch 133/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 55.1728 - val_loss: 247.7275\n",
      "Epoch 134/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 54.7406 - val_loss: 251.3146\n",
      "Epoch 135/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 54.2182 - val_loss: 239.9208\n",
      "Epoch 136/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 53.0335 - val_loss: 211.1285\n",
      "Epoch 137/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 53.6232 - val_loss: 179.4081\n",
      "Epoch 138/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 52.4571 - val_loss: 168.7563\n",
      "Epoch 139/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 52.3285 - val_loss: 164.5232\n",
      "Epoch 140/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 51.9522 - val_loss: 165.9266\n",
      "Epoch 141/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 51.4643 - val_loss: 168.2033\n",
      "Epoch 142/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 50.8932 - val_loss: 178.1725\n",
      "Epoch 143/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 50.1854 - val_loss: 188.4946\n",
      "Epoch 144/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 50.1436 - val_loss: 199.6512\n",
      "Epoch 145/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 49.5923 - val_loss: 209.6207\n",
      "Epoch 146/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 49.0960 - val_loss: 217.8047\n",
      "Epoch 147/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 49.2547 - val_loss: 229.5265\n",
      "Epoch 148/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 48.9105 - val_loss: 234.6113\n",
      "Epoch 149/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 48.6105 - val_loss: 229.3120\n",
      "Epoch 150/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 48.0778 - val_loss: 227.4735\n",
      "Epoch 151/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 47.8251 - val_loss: 230.1916\n",
      "Epoch 152/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 47.4961 - val_loss: 227.1307\n",
      "Epoch 153/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 46.8043 - val_loss: 217.0327\n",
      "Epoch 154/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 46.3328 - val_loss: 208.1647\n",
      "Epoch 155/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 45.7869 - val_loss: 195.5030\n",
      "Epoch 156/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 45.4441 - val_loss: 178.8874\n",
      "Epoch 157/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 44.7429 - val_loss: 173.1515\n",
      "Epoch 158/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 44.4590 - val_loss: 172.7559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 44.1271 - val_loss: 164.0822\n",
      "Epoch 160/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 43.6793 - val_loss: 164.2466\n",
      "Epoch 161/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 43.3221 - val_loss: 167.4476\n",
      "Epoch 162/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 42.9252 - val_loss: 174.1579\n",
      "Epoch 163/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 42.5803 - val_loss: 182.6608\n",
      "Epoch 164/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 42.2415 - val_loss: 189.0916\n",
      "Epoch 165/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 42.0583 - val_loss: 196.1458\n",
      "Epoch 166/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 42.0688 - val_loss: 200.1706\n",
      "Epoch 167/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 41.7100 - val_loss: 190.4638\n",
      "Epoch 168/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 41.2679 - val_loss: 182.2137\n",
      "Epoch 169/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 40.6335 - val_loss: 175.7205\n",
      "Epoch 170/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 40.2404 - val_loss: 169.1879\n",
      "Epoch 171/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 39.8039 - val_loss: 157.1348\n",
      "Epoch 172/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 39.4389 - val_loss: 147.6810\n",
      "Epoch 173/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 38.8918 - val_loss: 131.8528\n",
      "Epoch 174/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 38.8543 - val_loss: 119.4539\n",
      "Epoch 175/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 39.1585 - val_loss: 107.7261\n",
      "Epoch 176/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 39.1875 - val_loss: 105.8196\n",
      "Epoch 177/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 38.8658 - val_loss: 108.1571\n",
      "Epoch 178/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 38.4160 - val_loss: 107.9400\n",
      "Epoch 179/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 37.9861 - val_loss: 112.7952\n",
      "Epoch 180/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 37.5234 - val_loss: 116.6274\n",
      "Epoch 181/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 37.0987 - val_loss: 113.1304\n",
      "Epoch 182/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 36.7193 - val_loss: 118.7679\n",
      "Epoch 183/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 36.1366 - val_loss: 127.2171\n",
      "Epoch 184/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 35.8216 - val_loss: 136.5905\n",
      "Epoch 185/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 35.2781 - val_loss: 146.1688\n",
      "Epoch 186/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 35.0276 - val_loss: 156.5325\n",
      "Epoch 187/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 34.8513 - val_loss: 164.7545\n",
      "Epoch 188/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 34.7239 - val_loss: 170.5525\n",
      "Epoch 189/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 34.7927 - val_loss: 174.8118\n",
      "Epoch 190/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 34.4087 - val_loss: 175.7957\n",
      "Epoch 191/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 34.2003 - val_loss: 174.0479\n",
      "Epoch 192/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 33.8663 - val_loss: 170.7025\n",
      "Epoch 193/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 33.4637 - val_loss: 166.8607\n",
      "Epoch 194/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 33.1106 - val_loss: 162.4664\n",
      "Epoch 195/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 32.6873 - val_loss: 158.6155\n",
      "Epoch 196/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 32.2109 - val_loss: 150.9107\n",
      "Epoch 197/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 31.7563 - val_loss: 142.0042\n",
      "Epoch 198/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 31.3738 - val_loss: 135.9524\n",
      "Epoch 199/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 31.0894 - val_loss: 129.5079\n",
      "Epoch 200/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 30.8236 - val_loss: 122.2887\n",
      "Epoch 201/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 30.5082 - val_loss: 121.1481\n",
      "Epoch 202/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 30.2894 - val_loss: 120.4589\n",
      "Epoch 203/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 29.9886 - val_loss: 118.9964\n",
      "Epoch 204/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 29.7785 - val_loss: 119.8307\n",
      "Epoch 205/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 29.5309 - val_loss: 119.3183\n",
      "Epoch 206/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 29.3588 - val_loss: 121.1585\n",
      "Epoch 207/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 29.0051 - val_loss: 116.9066\n",
      "Epoch 208/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 28.7569 - val_loss: 114.0275\n",
      "Epoch 209/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 28.4640 - val_loss: 115.0766\n",
      "Epoch 210/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 28.2627 - val_loss: 113.9688\n",
      "Epoch 211/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 27.8892 - val_loss: 103.0625\n",
      "Epoch 212/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 28.1520 - val_loss: 87.6670\n",
      "Epoch 213/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 28.0514 - val_loss: 83.9421\n",
      "Epoch 214/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 27.5826 - val_loss: 88.8666\n",
      "Epoch 215/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 27.1305 - val_loss: 97.1517\n",
      "Epoch 216/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 26.7291 - val_loss: 106.5435\n",
      "Epoch 217/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 26.7153 - val_loss: 114.9995\n",
      "Epoch 218/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 26.2978 - val_loss: 110.8599\n",
      "Epoch 219/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 26.0214 - val_loss: 112.5332\n",
      "Epoch 220/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 25.7850 - val_loss: 113.1325\n",
      "Epoch 221/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 25.5748 - val_loss: 113.5164\n",
      "Epoch 222/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 25.3398 - val_loss: 110.4511\n",
      "Epoch 223/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 25.0020 - val_loss: 105.4250\n",
      "Epoch 224/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 24.8868 - val_loss: 93.3373\n",
      "Epoch 225/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 24.3805 - val_loss: 85.5289\n",
      "Epoch 226/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 24.2979 - val_loss: 76.0146\n",
      "Epoch 227/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 24.4893 - val_loss: 72.8102\n",
      "Epoch 228/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 24.2764 - val_loss: 75.6241\n",
      "Epoch 229/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 23.8711 - val_loss: 81.4189\n",
      "Epoch 230/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 23.4539 - val_loss: 88.6316\n",
      "Epoch 231/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 23.0474 - val_loss: 97.7628\n",
      "Epoch 232/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 22.7608 - val_loss: 106.3577\n",
      "Epoch 233/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 22.8805 - val_loss: 114.7497\n",
      "Epoch 234/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 23.0136 - val_loss: 119.1837\n",
      "Epoch 235/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 22.7094 - val_loss: 110.2291\n",
      "Epoch 236/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 22.1719 - val_loss: 105.9746\n",
      "Epoch 237/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 21.9379 - val_loss: 103.5480\n",
      "Epoch 238/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 21.6694 - val_loss: 103.4257\n",
      "Epoch 239/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 21.6087 - val_loss: 105.0554\n",
      "Epoch 240/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 21.2816 - val_loss: 103.8536\n",
      "Epoch 241/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 21.0948 - val_loss: 101.7991\n",
      "Epoch 242/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 20.8601 - val_loss: 99.2565\n",
      "Epoch 243/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 20.6660 - val_loss: 98.7699\n",
      "Epoch 244/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 20.5569 - val_loss: 98.8409\n",
      "Epoch 245/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 20.2595 - val_loss: 95.1958\n",
      "Epoch 246/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 20.0602 - val_loss: 93.2349\n",
      "Epoch 247/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 19.7641 - val_loss: 82.3071\n",
      "Epoch 248/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 19.5370 - val_loss: 77.1447\n",
      "Epoch 249/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 19.2809 - val_loss: 78.1906\n",
      "Epoch 250/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 19.0814 - val_loss: 81.3212\n",
      "Epoch 251/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 18.8666 - val_loss: 83.7734\n",
      "Epoch 252/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 18.8283 - val_loss: 87.2752\n",
      "Epoch 253/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 18.6165 - val_loss: 89.6430\n",
      "Epoch 254/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 18.5155 - val_loss: 90.5397\n",
      "Epoch 255/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 18.4746 - val_loss: 93.5204\n",
      "Epoch 256/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 18.3267 - val_loss: 91.1467\n",
      "Epoch 257/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 18.0992 - val_loss: 87.3993\n",
      "Epoch 258/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 17.7684 - val_loss: 78.4730\n",
      "Epoch 259/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 17.4897 - val_loss: 75.1932\n",
      "Epoch 260/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 17.2990 - val_loss: 74.7654\n",
      "Epoch 261/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 17.1419 - val_loss: 74.6355\n",
      "Epoch 262/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 17.0190 - val_loss: 70.8119\n",
      "Epoch 263/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 16.7559 - val_loss: 71.8105\n",
      "Epoch 264/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 16.5982 - val_loss: 71.5832\n",
      "Epoch 265/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 16.3875 - val_loss: 70.8620\n",
      "Epoch 266/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 16.2204 - val_loss: 72.0825\n",
      "Epoch 267/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 16.1272 - val_loss: 72.4750\n",
      "Epoch 268/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 15.9093 - val_loss: 65.7354\n",
      "Epoch 269/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 15.6827 - val_loss: 62.4081\n",
      "Epoch 270/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 15.5493 - val_loss: 57.4570\n",
      "Epoch 271/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 15.3788 - val_loss: 55.3864\n",
      "Epoch 272/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 15.2456 - val_loss: 54.9086\n",
      "Epoch 273/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 15.0938 - val_loss: 55.0733\n",
      "Epoch 274/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 14.9573 - val_loss: 55.9871\n",
      "Epoch 275/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 14.7190 - val_loss: 59.7964\n",
      "Epoch 276/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 14.5235 - val_loss: 64.4507\n",
      "Epoch 277/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 14.4278 - val_loss: 69.3342\n",
      "Epoch 278/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 14.3917 - val_loss: 71.2410\n",
      "Epoch 279/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 14.2498 - val_loss: 70.0721\n",
      "Epoch 280/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 14.0887 - val_loss: 67.9365\n",
      "Epoch 281/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 13.9630 - val_loss: 65.4351\n",
      "Epoch 282/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 13.7154 - val_loss: 62.5546\n",
      "Epoch 283/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 13.5363 - val_loss: 58.0864\n",
      "Epoch 284/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 13.7511 - val_loss: 47.6982\n",
      "Epoch 285/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 13.3528 - val_loss: 46.2532\n",
      "Epoch 286/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 13.2389 - val_loss: 48.2109\n",
      "Epoch 287/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 13.0722 - val_loss: 50.7547\n",
      "Epoch 288/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 12.8161 - val_loss: 51.9445\n",
      "Epoch 289/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 12.6428 - val_loss: 53.8811\n",
      "Epoch 290/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 12.5594 - val_loss: 57.0860\n",
      "Epoch 291/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 12.4181 - val_loss: 57.2530\n",
      "Epoch 292/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 12.2874 - val_loss: 58.3229\n",
      "Epoch 293/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 12.3332 - val_loss: 58.6944\n",
      "Epoch 294/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 11.7875 - val_loss: 49.6489\n",
      "Epoch 295/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 11.7625 - val_loss: 37.8265\n",
      "Epoch 296/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 12.2595 - val_loss: 27.9439\n",
      "Epoch 297/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 12.4280 - val_loss: 25.2819\n",
      "Epoch 298/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 12.4088 - val_loss: 25.6530\n",
      "Epoch 299/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 12.2764 - val_loss: 25.4166\n",
      "Epoch 300/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 11.9893 - val_loss: 28.5055\n",
      "Epoch 301/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 11.6814 - val_loss: 33.6078\n",
      "Epoch 302/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 11.2036 - val_loss: 34.7506\n",
      "Epoch 303/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 10.9671 - val_loss: 38.4492\n",
      "Epoch 304/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 10.7592 - val_loss: 42.7133\n",
      "Epoch 305/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 10.5501 - val_loss: 48.0482\n",
      "Epoch 306/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 10.4067 - val_loss: 52.2416\n",
      "Epoch 307/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 10.3870 - val_loss: 55.5720\n",
      "Epoch 308/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 10.4243 - val_loss: 57.3523\n",
      "Epoch 309/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 10.3379 - val_loss: 57.0444\n",
      "Epoch 310/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 10.2591 - val_loss: 56.5182\n",
      "Epoch 311/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 10.1077 - val_loss: 55.4065\n",
      "Epoch 312/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 9.9594 - val_loss: 51.8606\n",
      "Epoch 313/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 9.7431 - val_loss: 49.8472\n",
      "Epoch 314/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 9.5707 - val_loss: 46.4446\n",
      "Epoch 315/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 9.4430 - val_loss: 42.9482\n",
      "Epoch 316/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 9.3550 - val_loss: 37.2288\n",
      "Epoch 317/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 9.1629 - val_loss: 35.1137\n",
      "Epoch 318/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 18ms/step - loss: 9.0507 - val_loss: 31.0869\n",
      "Epoch 319/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 8.9813 - val_loss: 26.7411\n",
      "Epoch 320/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 9.0870 - val_loss: 26.0149\n",
      "Epoch 321/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 8.9354 - val_loss: 28.7810\n",
      "Epoch 322/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 8.6982 - val_loss: 32.5440\n",
      "Epoch 323/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 8.5727 - val_loss: 33.9264\n",
      "Epoch 324/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 8.4139 - val_loss: 31.7539\n",
      "Epoch 325/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 8.3066 - val_loss: 28.6277\n",
      "Epoch 326/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 8.2958 - val_loss: 27.9852\n",
      "Epoch 327/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 8.1635 - val_loss: 29.8456\n",
      "Epoch 328/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 8.0201 - val_loss: 33.4008\n",
      "Epoch 329/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 7.8738 - val_loss: 37.5102\n",
      "Epoch 330/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 7.7678 - val_loss: 40.0529\n",
      "Epoch 331/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 7.8148 - val_loss: 42.8708\n",
      "Epoch 332/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 7.7894 - val_loss: 41.8390\n",
      "Epoch 333/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 7.6233 - val_loss: 35.9741\n",
      "Epoch 334/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 7.5377 - val_loss: 31.5699\n",
      "Epoch 335/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 7.3021 - val_loss: 29.9721\n",
      "Epoch 336/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 7.1868 - val_loss: 30.1873\n",
      "Epoch 337/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 7.1216 - val_loss: 31.0693\n",
      "Epoch 338/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 6.9900 - val_loss: 31.1058\n",
      "Epoch 339/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 6.9177 - val_loss: 32.1677\n",
      "Epoch 340/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 6.8277 - val_loss: 32.3915\n",
      "Epoch 341/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 6.8365 - val_loss: 32.6291\n",
      "Epoch 342/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 6.8124 - val_loss: 26.9025\n",
      "Epoch 343/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 6.6027 - val_loss: 25.2793\n",
      "Epoch 344/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 6.4963 - val_loss: 26.3208\n",
      "Epoch 345/500\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 6.3886 - val_loss: 25.6842\n",
      "Epoch 346/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 6.3124 - val_loss: 26.3722\n",
      "Epoch 347/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.2221 - val_loss: 27.7913\n",
      "Epoch 348/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.1205 - val_loss: 28.7713\n",
      "Epoch 349/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6.0994 - val_loss: 29.7684\n",
      "Epoch 350/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 6.0216 - val_loss: 28.4175\n",
      "Epoch 351/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5.9612 - val_loss: 25.1127\n",
      "Epoch 352/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 5.8334 - val_loss: 23.7640\n",
      "Epoch 353/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 5.7644 - val_loss: 20.9331\n",
      "Epoch 354/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 5.7430 - val_loss: 20.6115\n",
      "Epoch 355/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 5.6157 - val_loss: 22.3724\n",
      "Epoch 356/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 5.5876 - val_loss: 24.2629\n",
      "Epoch 357/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 5.4677 - val_loss: 23.0355\n",
      "Epoch 358/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 5.3939 - val_loss: 23.5185\n",
      "Epoch 359/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 5.3371 - val_loss: 23.9111\n",
      "Epoch 360/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 5.2817 - val_loss: 22.6640\n",
      "Epoch 361/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 5.1815 - val_loss: 22.9040\n",
      "Epoch 362/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 5.1134 - val_loss: 23.6718\n",
      "Epoch 363/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 5.0763 - val_loss: 24.0314\n",
      "Epoch 364/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 5.0144 - val_loss: 22.0876\n",
      "Epoch 365/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 4.9496 - val_loss: 17.5638\n",
      "Epoch 366/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 4.9490 - val_loss: 15.4634\n",
      "Epoch 367/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 4.8891 - val_loss: 15.4959\n",
      "Epoch 368/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 4.7990 - val_loss: 16.1516\n",
      "Epoch 369/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 4.7053 - val_loss: 17.6222\n",
      "Epoch 370/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 4.6128 - val_loss: 18.5338\n",
      "Epoch 371/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 4.5805 - val_loss: 20.4335\n",
      "Epoch 372/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 4.5542 - val_loss: 21.2908\n",
      "Epoch 373/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 4.4979 - val_loss: 20.0598\n",
      "Epoch 374/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 4.4324 - val_loss: 18.3870\n",
      "Epoch 375/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 4.3483 - val_loss: 18.0559\n",
      "Epoch 376/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 4.3078 - val_loss: 16.8810\n",
      "Epoch 377/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 4.2319 - val_loss: 17.2306\n",
      "Epoch 378/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 4.1902 - val_loss: 19.0802\n",
      "Epoch 379/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 4.1460 - val_loss: 19.7514\n",
      "Epoch 380/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 4.0811 - val_loss: 18.2202\n",
      "Epoch 381/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 4.0295 - val_loss: 17.0162\n",
      "Epoch 382/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 4.0310 - val_loss: 13.1396\n",
      "Epoch 383/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 3.9490 - val_loss: 11.7212\n",
      "Epoch 384/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 3.9178 - val_loss: 11.6546\n",
      "Epoch 385/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 3.8589 - val_loss: 12.4699\n",
      "Epoch 386/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 3.8082 - val_loss: 14.4918\n",
      "Epoch 387/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 3.7210 - val_loss: 15.6751\n",
      "Epoch 388/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 3.6603 - val_loss: 14.8323\n",
      "Epoch 389/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 3.5952 - val_loss: 15.1029\n",
      "Epoch 390/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 3.5869 - val_loss: 16.5189\n",
      "Epoch 391/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 3.5389 - val_loss: 16.6105\n",
      "Epoch 392/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 3.4966 - val_loss: 17.1185\n",
      "Epoch 393/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 3.4726 - val_loss: 17.0511\n",
      "Epoch 394/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 3.4334 - val_loss: 16.4564\n",
      "Epoch 395/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 3.3995 - val_loss: 14.9964\n",
      "Epoch 396/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 3.3148 - val_loss: 14.0607\n",
      "Epoch 397/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 3.2819 - val_loss: 11.8605\n",
      "Epoch 398/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 3.2399 - val_loss: 11.1106\n",
      "Epoch 399/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 3.1798 - val_loss: 11.5888\n",
      "Epoch 400/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 3.1781 - val_loss: 13.1218\n",
      "Epoch 401/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 3.1048 - val_loss: 13.5177\n",
      "Epoch 402/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 3.0926 - val_loss: 12.5653\n",
      "Epoch 403/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 3.0081 - val_loss: 12.7176\n",
      "Epoch 404/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.9585 - val_loss: 13.3709\n",
      "Epoch 405/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.9785 - val_loss: 13.6335\n",
      "Epoch 406/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.8707 - val_loss: 11.4843\n",
      "Epoch 407/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.7973 - val_loss: 9.2834\n",
      "Epoch 408/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.8566 - val_loss: 7.3309\n",
      "Epoch 409/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.8348 - val_loss: 7.1165\n",
      "Epoch 410/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.8013 - val_loss: 7.3905\n",
      "Epoch 411/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.7642 - val_loss: 8.4123\n",
      "Epoch 412/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.6601 - val_loss: 8.9949\n",
      "Epoch 413/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.6111 - val_loss: 9.9122\n",
      "Epoch 414/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.5927 - val_loss: 11.3285\n",
      "Epoch 415/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.5725 - val_loss: 11.8107\n",
      "Epoch 416/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.5124 - val_loss: 9.8633\n",
      "Epoch 417/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.4888 - val_loss: 6.9576\n",
      "Epoch 418/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.4899 - val_loss: 6.0723\n",
      "Epoch 419/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.4706 - val_loss: 6.0967\n",
      "Epoch 420/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.4253 - val_loss: 6.8256\n",
      "Epoch 421/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.3617 - val_loss: 8.0203\n",
      "Epoch 422/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.3037 - val_loss: 8.2770\n",
      "Epoch 423/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.3019 - val_loss: 8.0646\n",
      "Epoch 424/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.2439 - val_loss: 8.4701\n",
      "Epoch 425/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.2248 - val_loss: 8.7412\n",
      "Epoch 426/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.1981 - val_loss: 9.2366\n",
      "Epoch 427/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.1880 - val_loss: 9.3005\n",
      "Epoch 428/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.1814 - val_loss: 9.9329\n",
      "Epoch 429/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.1606 - val_loss: 10.0958\n",
      "Epoch 430/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.1561 - val_loss: 10.2792\n",
      "Epoch 431/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.1300 - val_loss: 10.1450\n",
      "Epoch 432/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.1080 - val_loss: 9.3347\n",
      "Epoch 433/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.0401 - val_loss: 6.3947\n",
      "Epoch 434/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.9466 - val_loss: 4.0343\n",
      "Epoch 435/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.0714 - val_loss: 2.3642\n",
      "Epoch 436/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.2558 - val_loss: 1.7038\n",
      "Epoch 437/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.2763 - val_loss: 2.1896\n",
      "Epoch 438/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.0741 - val_loss: 3.5302\n",
      "Epoch 439/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.8990 - val_loss: 5.4626\n",
      "Epoch 440/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.7964 - val_loss: 7.2710\n",
      "Epoch 441/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.8065 - val_loss: 8.9958\n",
      "Epoch 442/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.8743 - val_loss: 10.1715\n",
      "Epoch 443/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.9155 - val_loss: 10.4013\n",
      "Epoch 444/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.9192 - val_loss: 9.9248\n",
      "Epoch 445/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.8855 - val_loss: 8.0986\n",
      "Epoch 446/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.7534 - val_loss: 7.0510\n",
      "Epoch 447/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.6935 - val_loss: 6.5140\n",
      "Epoch 448/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.6584 - val_loss: 6.3485\n",
      "Epoch 449/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.6331 - val_loss: 5.8447\n",
      "Epoch 450/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.5891 - val_loss: 4.8774\n",
      "Epoch 451/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.5972 - val_loss: 4.3334\n",
      "Epoch 452/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.5565 - val_loss: 4.4380\n",
      "Epoch 453/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.5449 - val_loss: 4.7612\n",
      "Epoch 454/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.5161 - val_loss: 4.6932\n",
      "Epoch 455/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.4972 - val_loss: 4.7856\n",
      "Epoch 456/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.5107 - val_loss: 5.2849\n",
      "Epoch 457/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.4861 - val_loss: 5.3271\n",
      "Epoch 458/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.4599 - val_loss: 4.8834\n",
      "Epoch 459/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.4368 - val_loss: 4.7267\n",
      "Epoch 460/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.4160 - val_loss: 4.2756\n",
      "Epoch 461/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.3921 - val_loss: 3.6603\n",
      "Epoch 462/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.3833 - val_loss: 3.3361\n",
      "Epoch 463/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.3806 - val_loss: 3.3539\n",
      "Epoch 464/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.3595 - val_loss: 3.9723\n",
      "Epoch 465/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.3461 - val_loss: 4.6553\n",
      "Epoch 466/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.3423 - val_loss: 4.8965\n",
      "Epoch 467/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.3324 - val_loss: 4.8039\n",
      "Epoch 468/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.3235 - val_loss: 4.7454\n",
      "Epoch 469/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.3019 - val_loss: 4.1879\n",
      "Epoch 470/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.2592 - val_loss: 3.0708\n",
      "Epoch 471/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.2608 - val_loss: 2.6572\n",
      "Epoch 472/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.2377 - val_loss: 2.7470\n",
      "Epoch 473/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.2174 - val_loss: 3.0896\n",
      "Epoch 474/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.1997 - val_loss: 3.4745\n",
      "Epoch 475/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.1904 - val_loss: 3.5451\n",
      "Epoch 476/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.1866 - val_loss: 3.4513\n",
      "Epoch 477/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.1585 - val_loss: 2.7609\n",
      "Epoch 478/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.1559 - val_loss: 2.3432\n",
      "Epoch 479/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.1410 - val_loss: 2.3573\n",
      "Epoch 480/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.1276 - val_loss: 2.2910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.1161 - val_loss: 2.2807\n",
      "Epoch 482/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.1050 - val_loss: 2.2374\n",
      "Epoch 483/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.0981 - val_loss: 2.2968\n",
      "Epoch 484/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.0893 - val_loss: 2.4310\n",
      "Epoch 485/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.0755 - val_loss: 2.3185\n",
      "Epoch 486/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.0585 - val_loss: 1.7424\n",
      "Epoch 487/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.0864 - val_loss: 1.4489\n",
      "Epoch 488/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.0590 - val_loss: 1.6431\n",
      "Epoch 489/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.0379 - val_loss: 1.8494\n",
      "Epoch 490/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.0232 - val_loss: 1.9530\n",
      "Epoch 491/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.0251 - val_loss: 2.2535\n",
      "Epoch 492/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.0026 - val_loss: 1.9890\n",
      "Epoch 493/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.9900 - val_loss: 1.9645\n",
      "Epoch 494/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.9810 - val_loss: 1.7088\n",
      "Epoch 495/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.9675 - val_loss: 1.7057\n",
      "Epoch 496/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9581 - val_loss: 1.8346\n",
      "Epoch 497/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.9460 - val_loss: 1.9856\n",
      "Epoch 498/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.9367 - val_loss: 2.2507\n",
      "Epoch 499/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.9426 - val_loss: 2.3228\n",
      "Epoch 500/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9395 - val_loss: 1.6812\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, epochs=500, validation_split=0.2, verbose=1, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[450.37497]]\n"
     ]
    }
   ],
   "source": [
    "test_input = array([30])\n",
    "test_input = test_input.reshape((1, 1, 1))\n",
    "test_output = model.predict(test_input, verbose=0)\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  4  6  8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48\n",
      " 50]\n",
      "[ 3  6  9 12 15 18 21 24 27 30 33 36 39 42 45 48 51 54 57 60 63 66 69 72\n",
      " 75]\n",
      "[   6   24   54   96  150  216  294  384  486  600  726  864 1014 1176\n",
      " 1350 1536 1734 1944 2166 2400 2646 2904 3174 3456 3750]\n",
      "[[ 2  3]\n",
      " [ 4  6]\n",
      " [ 6  9]\n",
      " [ 8 12]\n",
      " [10 15]\n",
      " [12 18]\n",
      " [14 21]\n",
      " [16 24]\n",
      " [18 27]\n",
      " [20 30]\n",
      " [22 33]\n",
      " [24 36]\n",
      " [26 39]\n",
      " [28 42]\n",
      " [30 45]\n",
      " [32 48]\n",
      " [34 51]\n",
      " [36 54]\n",
      " [38 57]\n",
      " [40 60]\n",
      " [42 63]\n",
      " [44 66]\n",
      " [46 69]\n",
      " [48 72]\n",
      " [50 75]]\n"
     ]
    }
   ],
   "source": [
    "# one to one with multiple features\n",
    "nums = 25\n",
    "\n",
    "X1 = list()\n",
    "X2 = list()\n",
    "X = list()\n",
    "Y = list()\n",
    "\n",
    "X1 = np.array([(x+1)*2 for x in range(25)])\n",
    "X2 = np.array([(x+1)*3 for x in range(25)])\n",
    "Y = np.array([x1*x2 for x1,x2 in zip(X1,X2)])\n",
    "\n",
    "print(X1)\n",
    "print(X2)\n",
    "print(Y)\n",
    "X = np.column_stack((X1, X2))\n",
    "print(X)\n",
    "X = array(X).reshape(25, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 80)                26560     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                810       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 27,381\n",
      "Trainable params: 27,381\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(80, activation='relu', input_shape=(1, 2)))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1299383.2500 - val_loss: 10291243.0000\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1298296.6250 - val_loss: 10285802.0000\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1297399.5000 - val_loss: 10279183.0000\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1296276.7500 - val_loss: 10270326.0000\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1294556.0000 - val_loss: 10258542.0000\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1292281.2500 - val_loss: 10244703.0000\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1289642.3750 - val_loss: 10228926.0000\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1286855.2500 - val_loss: 10210426.0000\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1283514.8750 - val_loss: 10189971.0000\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1280165.5000 - val_loss: 10166443.0000\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1275623.0000 - val_loss: 10141253.0000\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1271155.7500 - val_loss: 10113214.0000\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1265718.7500 - val_loss: 10081273.0000\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1259689.1250 - val_loss: 10044410.0000\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1252395.7500 - val_loss: 10003334.0000\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1245041.2500 - val_loss: 9958387.0000\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1237559.2500 - val_loss: 9907646.0000\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1228316.3750 - val_loss: 9851264.0000\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1218634.8750 - val_loss: 9786519.0000\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1206157.5000 - val_loss: 9719091.0000\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1195587.5000 - val_loss: 9647150.0000\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1183856.1250 - val_loss: 9574668.0000\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1169816.6250 - val_loss: 9506587.0000\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1159085.1250 - val_loss: 9433852.0000\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1144819.7500 - val_loss: 9358734.0000\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1129621.2500 - val_loss: 9278814.0000\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1117575.8750 - val_loss: 9188184.0000\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1099904.0000 - val_loss: 9098086.0000\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1085903.8750 - val_loss: 9001664.0000\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1066773.6250 - val_loss: 8905844.0000\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1050852.2500 - val_loss: 8802290.0000\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1033129.3125 - val_loss: 8694570.0000\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1013112.8125 - val_loss: 8584471.0000\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 994126.8750 - val_loss: 8467864.0000\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 972260.0000 - val_loss: 8349145.0000\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 954223.3125 - val_loss: 8220624.0000\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 932237.6250 - val_loss: 8088605.5000\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 907233.3750 - val_loss: 7957213.0000\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 887551.0000 - val_loss: 7814233.5000\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 860616.1250 - val_loss: 7674666.5000\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 839529.8125 - val_loss: 7524434.5000\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 815450.8750 - val_loss: 7370287.0000\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 790227.1875 - val_loss: 7214413.5000\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 764204.3750 - val_loss: 7056229.0000\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 735749.3750 - val_loss: 6900937.0000\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 713594.3125 - val_loss: 6735697.5000\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 689142.1875 - val_loss: 6565800.0000\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 659097.0625 - val_loss: 6402234.5000\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 634899.8750 - val_loss: 6231309.0000\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 605286.3125 - val_loss: 6065765.5000\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 582822.4375 - val_loss: 5886485.0000\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 550472.1250 - val_loss: 5712979.0000\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 531058.3750 - val_loss: 5516753.0000\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 499728.5000 - val_loss: 5325384.5000\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 475701.3125 - val_loss: 5129381.5000\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 444252.0938 - val_loss: 4945240.5000\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 420075.0625 - val_loss: 4765521.5000\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 394921.4375 - val_loss: 4591252.5000\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 373367.6250 - val_loss: 4415855.0000\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 348065.3750 - val_loss: 4250037.5000\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 328773.0625 - val_loss: 4079879.2500\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 307782.1875 - val_loss: 3914475.5000\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 284560.4375 - val_loss: 3761004.7500\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 266466.8438 - val_loss: 3607872.0000\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 247008.3750 - val_loss: 3463048.5000\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 232636.0781 - val_loss: 3313325.2500\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 220347.0469 - val_loss: 3159120.7500\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 199336.8906 - val_loss: 3028351.5000\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 184260.0312 - val_loss: 2907061.2500\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 175478.7656 - val_loss: 2774980.2500\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 163318.1250 - val_loss: 2649109.7500\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 148413.8438 - val_loss: 2543339.7500\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 138775.2344 - val_loss: 2439686.2500\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 130769.8750 - val_loss: 2334142.5000\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 121277.7734 - val_loss: 2237347.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 114302.3516 - val_loss: 2141602.2500\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 105993.6016 - val_loss: 2056186.0000\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 100315.1719 - val_loss: 1970255.7500\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 93072.0859 - val_loss: 1895885.0000\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 88670.2969 - val_loss: 1819994.7500\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 82717.0156 - val_loss: 1754215.2500\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 79505.1641 - val_loss: 1683768.6250\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 74445.1875 - val_loss: 1625045.1250\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 70704.3281 - val_loss: 1570035.3750\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 66776.5547 - val_loss: 1522689.3750\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 63908.6797 - val_loss: 1469912.0000\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 60817.1484 - val_loss: 1425968.2500\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 58538.1641 - val_loss: 1375805.6250\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 55474.6172 - val_loss: 1340360.7500\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 53460.4688 - val_loss: 1299567.2500\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 51217.4062 - val_loss: 1261474.3750\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 48936.7344 - val_loss: 1237190.7500\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 47333.7539 - val_loss: 1208236.7500\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 45353.2930 - val_loss: 1175332.3750\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 43614.5430 - val_loss: 1143960.8750\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 42568.9922 - val_loss: 1102831.0000\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 40982.8984 - val_loss: 1081193.5000\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 39411.5234 - val_loss: 1058610.2500\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 38305.3867 - val_loss: 1042437.3750\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 37164.4258 - val_loss: 1026346.8125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x227c11105e0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=100, validation_split=0.2, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2611.701]]\n"
     ]
    }
   ],
   "source": [
    "test_input = array([55,80])\n",
    "test_input = test_input.reshape((1, 1, 2))\n",
    "test_output = model.predict(test_input, verbose=0)\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 1, 200)            162400    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 1, 100)            120400    \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 1, 50)             30200     \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 25)                7600      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 20)                520       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 321,341\n",
      "Trainable params: 321,341\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# via stacked LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, activation='relu', return_sequences=True, input_shape=(1, 2)))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(25, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 324.5717 - val_loss: 9896.1729\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 933.4037 - val_loss: 8361.7969\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 271.2434 - val_loss: 11604.1572\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 183.9642 - val_loss: 10757.1865\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 176.1675 - val_loss: 4890.7017\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 248.2892 - val_loss: 5970.9395\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 211.7718 - val_loss: 8672.3115\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 148.2747 - val_loss: 15760.7236\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - ETA: 0s - loss: 303.353 - 0s 5ms/step - loss: 552.0873 - val_loss: 23508.7871\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1078.4310 - val_loss: 21435.0703\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 525.1988 - val_loss: 1791.1693\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 866.0352 - val_loss: 7126.3032\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 556.4767 - val_loss: 20669.4785\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 236.9037 - val_loss: 15524.4580\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 167.0555 - val_loss: 8204.9531\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 362.3373 - val_loss: 17792.8457\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 315.6265 - val_loss: 24904.6074\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 575.5679 - val_loss: 9472.3154\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 202.2243 - val_loss: 16634.4316\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 332.9985 - val_loss: 17914.6484\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 489.0191 - val_loss: 12186.2275\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 556.7247 - val_loss: 11978.7334\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 368.6952 - val_loss: 18525.4453\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 338.4180 - val_loss: 8325.0010\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 87.6079 - val_loss: 11352.5869\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 150.2582 - val_loss: 9757.3643\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 106.3222 - val_loss: 11587.7842\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 88.3848 - val_loss: 8464.9795\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 343.5048 - val_loss: 10407.6377\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1238.4357 - val_loss: 2099.2195\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 400.1693 - val_loss: 11467.6240\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 752.8576 - val_loss: 21448.7422\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 227.8442 - val_loss: 10105.7217\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 416.2361 - val_loss: 15567.6904\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 519.4090 - val_loss: 34129.0820\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1236.2628 - val_loss: 29332.2500\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1877.1875 - val_loss: 1534.3097\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2080.7783 - val_loss: 15641.2607\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1073.8279 - val_loss: 67107.0547\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3467.6008 - val_loss: 37881.2656\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2699.6230 - val_loss: 3106.2258\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4913.8569 - val_loss: 6578.9097\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2034.5051 - val_loss: 117596.1016\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6054.6216 - val_loss: 18080.0371\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 460.2004 - val_loss: 64237.4258\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 946.9949 - val_loss: 26880.4160\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1523.2422 - val_loss: 15251.4922\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 535.8388 - val_loss: 24915.9121\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 278.1765 - val_loss: 8217.1113\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 495.2030 - val_loss: 6316.5156\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 276.8926 - val_loss: 10233.4561\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 482.5939 - val_loss: 23808.3535\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2339.5979 - val_loss: 3655.0164\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1501.5311 - val_loss: 3972.1797\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5780.0498 - val_loss: 22508.5137\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1669.3661 - val_loss: 102918.3984\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 2767.1777 - val_loss: 18849.6680\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1167.0653 - val_loss: 36208.6680\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 565.4472 - val_loss: 35881.1211\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 347.3684 - val_loss: 7946.1606\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 795.4103 - val_loss: 62929.1758\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3332.1150 - val_loss: 23885.3457\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8831.0635 - val_loss: 13861.3838\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11059.8115 - val_loss: 2998.7361\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17774.3945 - val_loss: 390783.0938\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 29155.4492 - val_loss: 13903.2979\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 34961.6094 - val_loss: 75895.2578\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 4360.9854 - val_loss: 85720.7891\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 3011.1208 - val_loss: 17396.9375\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1984.4027 - val_loss: 109663.0938\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 3049.0759 - val_loss: 24475.9766\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1080.1674 - val_loss: 24642.3672\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 479.6194 - val_loss: 23084.1250\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 316.4643 - val_loss: 20023.9102\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 262.3020 - val_loss: 6417.5078\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1198.8691 - val_loss: 16374.8174\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 527.6217 - val_loss: 21875.6738\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 448.6668 - val_loss: 19364.2637\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 191.9948 - val_loss: 4183.7124\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 859.6094 - val_loss: 22906.7422\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 323.5090 - val_loss: 20001.7480\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 187.6165 - val_loss: 20777.4980\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 425.3284 - val_loss: 16025.2764\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 130.0110 - val_loss: 6797.0151\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 592.0219 - val_loss: 4543.4951\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 4027.4719 - val_loss: 38089.4805\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 1866.3638 - val_loss: 34147.1680\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 610.2075 - val_loss: 26210.9277\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 487.5796 - val_loss: 40838.1289\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 654.0989 - val_loss: 8316.0420\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 812.7000 - val_loss: 7083.0649\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 1799.0529 - val_loss: 22158.3066\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 514.3218 - val_loss: 25780.1562\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 421.1075 - val_loss: 11439.8945\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 185.9967 - val_loss: 6634.0679\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 369.7013 - val_loss: 23856.8340\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 445.4078 - val_loss: 22801.1504\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 2178.8772 - val_loss: 5216.5742\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 666.2197 - val_loss: 4049.9802\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 1570.5753 - val_loss: 33911.7461\n",
      "[[3978.253]]\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, epochs=100, validation_split=0.1, verbose=1, batch_size=3)\n",
    "\n",
    "test_output = model.predict(test_input, verbose=0)\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45]\n",
      "[[[ 1]\n",
      "  [ 2]\n",
      "  [ 3]]\n",
      "\n",
      " [[ 4]\n",
      "  [ 5]\n",
      "  [ 6]]\n",
      "\n",
      " [[ 7]\n",
      "  [ 8]\n",
      "  [ 9]]\n",
      "\n",
      " [[10]\n",
      "  [11]\n",
      "  [12]]\n",
      "\n",
      " [[13]\n",
      "  [14]\n",
      "  [15]]\n",
      "\n",
      " [[16]\n",
      "  [17]\n",
      "  [18]]\n",
      "\n",
      " [[19]\n",
      "  [20]\n",
      "  [21]]\n",
      "\n",
      " [[22]\n",
      "  [23]\n",
      "  [24]]\n",
      "\n",
      " [[25]\n",
      "  [26]\n",
      "  [27]]\n",
      "\n",
      " [[28]\n",
      "  [29]\n",
      "  [30]]\n",
      "\n",
      " [[31]\n",
      "  [32]\n",
      "  [33]]\n",
      "\n",
      " [[34]\n",
      "  [35]\n",
      "  [36]]\n",
      "\n",
      " [[37]\n",
      "  [38]\n",
      "  [39]]\n",
      "\n",
      " [[40]\n",
      "  [41]\n",
      "  [42]]\n",
      "\n",
      " [[43]\n",
      "  [44]\n",
      "  [45]]]\n"
     ]
    }
   ],
   "source": [
    "# in one to one, sample consists of one time stamp with one or more features\n",
    "# many to one \n",
    "X = np.array([x+1 for x in range(45)])\n",
    "print(X)\n",
    "X = X.reshape(15,3,1)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6  15  24  33  42  51  60  69  78  87  96 105 114 123 132]\n"
     ]
    }
   ],
   "source": [
    "Y = list()\n",
    "for x in X:\n",
    "    Y.append(x.sum())\n",
    "\n",
    "Y = np.array(Y)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 4016.5359 - val_loss: 14924.7432\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3991.7356 - val_loss: 14831.5000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3967.5129 - val_loss: 14740.9189\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3943.7092 - val_loss: 14651.8721\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3920.2644 - val_loss: 14563.8906\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3897.1123 - val_loss: 14476.8545\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3874.2031 - val_loss: 14390.6338\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3851.4900 - val_loss: 14305.0830\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3828.9277 - val_loss: 14220.0547\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3806.4670 - val_loss: 14135.3906\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3784.0645 - val_loss: 14050.9180\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3761.6746 - val_loss: 13966.4609\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3739.2468 - val_loss: 13881.8242\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3716.7351 - val_loss: 13796.9062\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3694.0876 - val_loss: 13711.7422\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3671.2600 - val_loss: 13625.7295\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3648.2441 - val_loss: 13538.5713\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3624.9460 - val_loss: 13449.9971\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3601.2842 - val_loss: 13359.7021\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3577.1863 - val_loss: 13267.3555\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3552.5801 - val_loss: 13172.6016\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3527.3938 - val_loss: 13075.0547\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3501.5442 - val_loss: 12974.2998\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3474.9551 - val_loss: 12869.8945\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3447.5369 - val_loss: 12761.3789\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3419.2004 - val_loss: 12648.2773\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3389.8513 - val_loss: 12530.1094\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3359.3914 - val_loss: 12406.3955\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3327.7175 - val_loss: 12276.6807\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3294.7244 - val_loss: 12140.5234\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3260.2930 - val_loss: 11997.5107\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3224.3000 - val_loss: 11847.2734\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3186.6414 - val_loss: 11689.4717\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3147.1946 - val_loss: 11523.7725\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3105.8254 - val_loss: 11350.0039\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3062.4143 - val_loss: 11167.6201\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3016.8848 - val_loss: 10975.9932\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2969.0273 - val_loss: 10774.4131\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2918.6399 - val_loss: 10561.9287\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2865.5020 - val_loss: 10337.3438\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2809.3855 - val_loss: 10099.2354\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2750.0342 - val_loss: 9846.0059\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2687.1780 - val_loss: 9576.0264\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2620.5383 - val_loss: 9287.8799\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2549.8511 - val_loss: 8980.6553\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2474.8940 - val_loss: 8654.3457\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2395.5173 - val_loss: 8309.9287\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2311.6851 - val_loss: 7949.0288\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2223.4866 - val_loss: 7573.2300\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2131.1433 - val_loss: 7183.4536\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2034.9800 - val_loss: 6779.9863\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1935.3912 - val_loss: 6363.3765\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1832.8314 - val_loss: 5935.6738\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1727.8198 - val_loss: 5501.0601\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1620.9673 - val_loss: 5065.0684\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1512.9806 - val_loss: 4632.7524\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1404.6152 - val_loss: 4207.1851\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1296.6068 - val_loss: 3789.6555\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1189.6136 - val_loss: 3381.4021\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1084.2264 - val_loss: 2985.4568\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 981.0399 - val_loss: 2606.9128\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 880.7326 - val_loss: 2251.3079\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 784.0826 - val_loss: 1922.5660\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 691.8945 - val_loss: 1622.1710\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 604.8809 - val_loss: 1349.7887\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 523.5751 - val_loss: 1104.3488\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 448.3153 - val_loss: 884.8318\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 379.2864 - val_loss: 690.5543\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 316.5844 - val_loss: 521.1500\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 260.2549 - val_loss: 376.4249\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 210.3179 - val_loss: 256.1927\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 166.7623 - val_loss: 160.1272\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 129.5359 - val_loss: 87.6462\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 98.5310 - val_loss: 37.8213\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 73.5628 - val_loss: 9.3146\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 54.3570 - val_loss: 0.3451\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 40.5398 - val_loss: 8.6817\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 31.6311 - val_loss: 31.6788\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 27.0536 - val_loss: 66.3245\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 26.1410 - val_loss: 109.0285\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 28.1213 - val_loss: 155.8284\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 32.1251 - val_loss: 203.1841\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 37.3129 - val_loss: 247.9370\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 42.9205 - val_loss: 287.4170\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 48.2916 - val_loss: 319.5669\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 52.9069 - val_loss: 343.0317\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 56.4000 - val_loss: 357.1779\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 58.5620 - val_loss: 362.0562\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 59.3304 - val_loss: 358.2867\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 58.7684 - val_loss: 346.9248\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 57.0348 - val_loss: 329.3054\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 54.3528 - val_loss: 306.8957\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 50.9785 - val_loss: 281.1759\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 47.1733 - val_loss: 253.5385\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 43.1834 - val_loss: 225.2208\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 39.2244 - val_loss: 197.2661\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 35.4720 - val_loss: 170.5007\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 32.0578 - val_loss: 145.5360\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 29.0699 - val_loss: 122.7836\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 26.5558 - val_loss: 102.4762\n",
      "[[167.56187]]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(3, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history = model.fit(X, Y, epochs=100, validation_split=0.2, verbose=1)\n",
    "\n",
    "test_input = array([50,51,52])\n",
    "test_input = test_input.reshape((1, 3, 1))\n",
    "test_output = model.predict(test_input, verbose=0)\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 4045.7480 - val_loss: 15177.7002\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4043.9753 - val_loss: 15170.8135\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4041.9871 - val_loss: 15161.4404\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 4039.8604 - val_loss: 15149.0420\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4037.1536 - val_loss: 15130.2109\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4033.4285 - val_loss: 15100.2861\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4028.0781 - val_loss: 15050.7266\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4020.0449 - val_loss: 14971.7158\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4007.4719 - val_loss: 14856.0703\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3987.8193 - val_loss: 14697.9570\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3958.2253 - val_loss: 14490.3438\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 3915.2937 - val_loss: 14180.2188\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3853.1848 - val_loss: 13670.1250\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3759.1855 - val_loss: 12810.4375\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3607.8494 - val_loss: 11532.2939\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3378.3545 - val_loss: 10069.9766\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3087.8040 - val_loss: 8601.9639\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2743.9531 - val_loss: 6916.9648\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2341.2490 - val_loss: 4826.2935\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1851.6151 - val_loss: 2743.5657\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1302.4650 - val_loss: 832.1740\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 737.8935 - val_loss: 22.3074\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 296.6025 - val_loss: 1415.8843\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 213.1711 - val_loss: 4633.9243\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 523.7692 - val_loss: 6493.8979\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 767.6621 - val_loss: 6073.5181\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 717.1973 - val_loss: 4382.9570\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 508.3462 - val_loss: 2541.7893\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 295.6002 - val_loss: 1184.5321\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 168.5815 - val_loss: 411.0520\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 134.6351 - val_loss: 76.7471\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 160.9904 - val_loss: 4.1262\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 209.4778 - val_loss: 32.9147\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 251.4923 - val_loss: 70.0305\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 272.2320 - val_loss: 74.3480\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 266.3217 - val_loss: 38.3103\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 233.9096 - val_loss: 9.4189\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 179.0661 - val_loss: 285.4677\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 133.1470 - val_loss: 634.0208\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 128.4492 - val_loss: 915.1805\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 140.3171 - val_loss: 1079.8293\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 150.9125 - val_loss: 1088.8971\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 149.7852 - val_loss: 951.5035\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 135.7825 - val_loss: 730.4804\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 115.8557 - val_loss: 497.9601\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 97.9628 - val_loss: 304.0325\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 87.3014 - val_loss: 170.1527\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 83.8572 - val_loss: 90.9707\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 84.0563 - val_loss: 53.1762\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 83.2544 - val_loss: 46.2909\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 78.0376 - val_loss: 81.8331\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 69.2889 - val_loss: 163.1581\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 64.8025 - val_loss: 223.8933\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 69.4660 - val_loss: 144.9511\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 59.7979 - val_loss: 51.2994\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 51.7736 - val_loss: 15.1401\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 50.8184 - val_loss: 8.3405\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 48.1379 - val_loss: 11.5875\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 41.5083 - val_loss: 31.2593\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 38.4651 - val_loss: 33.9334\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.2275 - val_loss: 28.8272\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 30.9765 - val_loss: 30.1080\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 29.0701 - val_loss: 34.6270\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 27.2174 - val_loss: 40.7441\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 25.3391 - val_loss: 46.7267\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 23.7263 - val_loss: 46.0440\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 21.9704 - val_loss: 39.1253\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 19.9224 - val_loss: 28.0794\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.7551 - val_loss: 15.7134\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 15.6507 - val_loss: 7.1377\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.1171 - val_loss: 2.7178\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 12.7831 - val_loss: 0.9016\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.6887 - val_loss: 0.0905\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 11.0795 - val_loss: 0.1934\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 10.2142 - val_loss: 0.8300\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.5492 - val_loss: 1.0701\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 8.7832 - val_loss: 0.7332\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.9312 - val_loss: 0.2624\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.2166 - val_loss: 0.0337\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6.6575 - val_loss: 0.0292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.1440 - val_loss: 0.0535\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 5.6271 - val_loss: 0.0359\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.1449 - val_loss: 0.0738\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.7525 - val_loss: 0.2428\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.4469 - val_loss: 0.4827\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.1845 - val_loss: 0.6876\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.9429 - val_loss: 0.8350\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.7408 - val_loss: 1.1197\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.5521 - val_loss: 1.5417\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.3712 - val_loss: 2.0004\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.2128 - val_loss: 2.3649\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.0724 - val_loss: 2.5671\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.9429 - val_loss: 2.6375\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.8247 - val_loss: 2.6641\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.7169 - val_loss: 2.7219\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.6139 - val_loss: 2.8297\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.5127 - val_loss: 2.9489\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.4179 - val_loss: 3.0081\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.3299 - val_loss: 2.9620\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.2461 - val_loss: 2.8099\n",
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000227CD13C5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[149.37749]]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(200, activation='relu', return_sequences=True, input_shape=(3, 1)))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(25, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history = model.fit(X, Y, epochs=100, validation_split=0.2, verbose=1)\n",
    "test_output = model.predict(test_input, verbose=0)\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 3977.8601 - val_loss: 14636.7344\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3928.9883 - val_loss: 14452.6533\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3880.7861 - val_loss: 14270.3291\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3832.9668 - val_loss: 14089.3662\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3785.4551 - val_loss: 13909.4580\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3738.1160 - val_loss: 13730.3369\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3690.8230 - val_loss: 13551.1729\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3643.4802 - val_loss: 13371.9482\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3595.9792 - val_loss: 13192.3584\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3547.9749 - val_loss: 13012.1992\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3499.5000 - val_loss: 12830.9482\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3450.3945 - val_loss: 12648.1758\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3400.4531 - val_loss: 12463.3516\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3349.4688 - val_loss: 12275.8359\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3297.2317 - val_loss: 12084.9561\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3243.5281 - val_loss: 11889.8818\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3188.1248 - val_loss: 11689.3516\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3130.7864 - val_loss: 11481.9170\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3071.1873 - val_loss: 11266.0225\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3008.9473 - val_loss: 11039.8359\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2943.6575 - val_loss: 10801.2041\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2874.8606 - val_loss: 10547.5977\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2802.0413 - val_loss: 10276.0635\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2724.6406 - val_loss: 9983.1641\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2642.0640 - val_loss: 9665.0518\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2553.5432 - val_loss: 9317.2139\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2458.2322 - val_loss: 8934.1104\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2355.2961 - val_loss: 8508.9062\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2243.7095 - val_loss: 8035.6152\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2122.8357 - val_loss: 7509.9556\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1992.3475 - val_loss: 6928.6704\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1852.0040 - val_loss: 6293.6909\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1702.4410 - val_loss: 5615.7344\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1545.2601 - val_loss: 4915.5020\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1383.0914 - val_loss: 4220.5820\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1219.4164 - val_loss: 3557.9578\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1058.1272 - val_loss: 2947.2644\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 902.9881 - val_loss: 2398.6497\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 757.0373 - val_loss: 1912.8239\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 622.2729 - val_loss: 1485.6617\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 499.7213 - val_loss: 1109.4512\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 389.9944 - val_loss: 778.7829\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 293.0424 - val_loss: 500.3112\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 210.0479 - val_loss: 280.6338\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 141.9712 - val_loss: 124.0299\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 89.4890 - val_loss: 31.1462\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 52.8144 - val_loss: 0.0519\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 31.5984 - val_loss: 25.8302\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 24.7223 - val_loss: 99.2534\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 30.1523 - val_loss: 206.1149\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 44.7978 - val_loss: 328.2306\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 64.6954 - val_loss: 446.5253\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 85.5758 - val_loss: 544.6696\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 103.6616 - val_loss: 609.9000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 116.2667 - val_loss: 639.0931\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 122.1117 - val_loss: 632.3587\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 121.1630 - val_loss: 594.6705\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 114.3434 - val_loss: 533.5768\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 103.1433 - val_loss: 457.7014\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 89.2749 - val_loss: 375.4958\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 74.4042 - val_loss: 294.2839\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 59.9644 - val_loss: 219.6501\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 47.03 - 0s 17ms/step - loss: 47.0399 - val_loss: 155.2262\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 36.3335 - val_loss: 102.8263\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 28.1802 - val_loss: 62.7622\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 22.5943 - val_loss: 34.2252\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 19.3504 - val_loss: 15.6655\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 18.0700 - val_loss: 5.1464\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 18.2890 - val_loss: 0.6381\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 19.5214 - val_loss: 0.2126\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.3072 - val_loss: 2.1702\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 23.2446 - val_loss: 5.1318\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 25.0179 - val_loss: 8.0829\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 26.4024 - val_loss: 10.3650\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 27.2661 - val_loss: 11.6304\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 27.5549 - val_loss: 11.7839\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 27.2771 - val_loss: 10.9209\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 26.4909 - val_loss: 9.2665\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 25.2864 - val_loss: 7.1209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 23.7738 - val_loss: 4.8149\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22.0716 - val_loss: 2.6750\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 20.2970 - val_loss: 1.0063\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 18.5612 - val_loss: 0.0925\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 16.9666 - val_loss: 0.2201\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 15.6073 - val_loss: 1.7334\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.5717 - val_loss: 5.0147\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 13.9407 - val_loss: 9.6286\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 13.7092 - val_loss: 13.7898\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 13.6863 - val_loss: 16.7097\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.7080 - val_loss: 18.3822\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.6889 - val_loss: 19.0364\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 13.5888 - val_loss: 18.9765\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.4045 - val_loss: 18.4556\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 13.1529 - val_loss: 17.6220\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 12.8551 - val_loss: 16.5464\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 12.5282 - val_loss: 15.2711\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 12.1851 - val_loss: 13.8408\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 11.8360 - val_loss: 12.3100\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.4895 - val_loss: 10.7398\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 11.1531 - val_loss: 9.1912\n",
      "WARNING:tensorflow:8 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000227CB6B90D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[156.44215]]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(3, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history = model.fit(X, Y, epochs=100, validation_split=0.2, verbose=1)\n",
    "test_output = model.predict(test_input, verbose=0)\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3   6   9  12  15  18  21  24  27  30  33  36  39  42  45  48  51  54\n",
      "  57  60  63  66  69  72  75  78  81  84  87  90  93  96  99 102 105 108\n",
      " 111 114 117 120 123 126 129 132 135]\n",
      "[  5  10  15  20  25  30  35  40  45  50  55  60  65  70  75  80  85  90\n",
      "  95 100 105 110 115 120 125 130 135 140 145 150 155 160 165 170 175 180\n",
      " 185 190 195 200 205 210 215 220 225]\n",
      "[[  3   5]\n",
      " [  6  10]\n",
      " [  9  15]\n",
      " [ 12  20]\n",
      " [ 15  25]\n",
      " [ 18  30]\n",
      " [ 21  35]\n",
      " [ 24  40]\n",
      " [ 27  45]\n",
      " [ 30  50]\n",
      " [ 33  55]\n",
      " [ 36  60]\n",
      " [ 39  65]\n",
      " [ 42  70]\n",
      " [ 45  75]\n",
      " [ 48  80]\n",
      " [ 51  85]\n",
      " [ 54  90]\n",
      " [ 57  95]\n",
      " [ 60 100]\n",
      " [ 63 105]\n",
      " [ 66 110]\n",
      " [ 69 115]\n",
      " [ 72 120]\n",
      " [ 75 125]\n",
      " [ 78 130]\n",
      " [ 81 135]\n",
      " [ 84 140]\n",
      " [ 87 145]\n",
      " [ 90 150]\n",
      " [ 93 155]\n",
      " [ 96 160]\n",
      " [ 99 165]\n",
      " [102 170]\n",
      " [105 175]\n",
      " [108 180]\n",
      " [111 185]\n",
      " [114 190]\n",
      " [117 195]\n",
      " [120 200]\n",
      " [123 205]\n",
      " [126 210]\n",
      " [129 215]\n",
      " [132 220]\n",
      " [135 225]]\n",
      "[[[  3   5]\n",
      "  [  6  10]\n",
      "  [  9  15]]\n",
      "\n",
      " [[ 12  20]\n",
      "  [ 15  25]\n",
      "  [ 18  30]]\n",
      "\n",
      " [[ 21  35]\n",
      "  [ 24  40]\n",
      "  [ 27  45]]\n",
      "\n",
      " [[ 30  50]\n",
      "  [ 33  55]\n",
      "  [ 36  60]]\n",
      "\n",
      " [[ 39  65]\n",
      "  [ 42  70]\n",
      "  [ 45  75]]\n",
      "\n",
      " [[ 48  80]\n",
      "  [ 51  85]\n",
      "  [ 54  90]]\n",
      "\n",
      " [[ 57  95]\n",
      "  [ 60 100]\n",
      "  [ 63 105]]\n",
      "\n",
      " [[ 66 110]\n",
      "  [ 69 115]\n",
      "  [ 72 120]]\n",
      "\n",
      " [[ 75 125]\n",
      "  [ 78 130]\n",
      "  [ 81 135]]\n",
      "\n",
      " [[ 84 140]\n",
      "  [ 87 145]\n",
      "  [ 90 150]]\n",
      "\n",
      " [[ 93 155]\n",
      "  [ 96 160]\n",
      "  [ 99 165]]\n",
      "\n",
      " [[102 170]\n",
      "  [105 175]\n",
      "  [108 180]]\n",
      "\n",
      " [[111 185]\n",
      "  [114 190]\n",
      "  [117 195]]\n",
      "\n",
      " [[120 200]\n",
      "  [123 205]\n",
      "  [126 210]]\n",
      "\n",
      " [[129 215]\n",
      "  [132 220]\n",
      "  [135 225]]]\n"
     ]
    }
   ],
   "source": [
    "# many to one with multiple features\n",
    "X1 = np.array([x+3 for x in range(0, 135, 3)])\n",
    "print(X1)\n",
    "\n",
    "X2 = np.array([x+5 for x in range(0, 225, 5)])\n",
    "print(X2)\n",
    "\n",
    "X = np.column_stack((X1, X2))\n",
    "print(X)\n",
    "\n",
    "X = array(X).reshape(15, 3, 2)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=np.array([(lambda X: X[i][2][0] + X[i][2][1])(X) for i in range(len(X))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 38909.8086 - val_loss: 140949.2344\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 38020.2227 - val_loss: 136296.1250\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 36989.3477 - val_loss: 130932.4375\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35838.1875 - val_loss: 125520.8125\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 34602.9570 - val_loss: 120633.6484\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 33297.8008 - val_loss: 115293.6250\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 31857.6035 - val_loss: 107771.4141\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 30294.4121 - val_loss: 102262.6484\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 28957.3691 - val_loss: 99165.5547\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 27971.0469 - val_loss: 96604.0391\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 27176.1777 - val_loss: 94220.8984\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 26467.7168 - val_loss: 91964.8438\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 25799.3281 - val_loss: 89651.9609\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 25147.6250 - val_loss: 87203.9062\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 24514.3340 - val_loss: 85000.7812\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 23923.3066 - val_loss: 83176.5078\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 23386.0254 - val_loss: 81519.5547\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 22890.5781 - val_loss: 79946.8828\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 22426.1855 - val_loss: 78495.3828\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 21991.7715 - val_loss: 77187.9844\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21588.0742 - val_loss: 75983.7422\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 21211.5156 - val_loss: 74807.7578\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 20854.4355 - val_loss: 73609.9609\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 20509.1738 - val_loss: 72397.6641\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 20171.5547 - val_loss: 71218.5625\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 19841.0879 - val_loss: 70112.9688\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 19518.3887 - val_loss: 69081.0938\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 19202.2949 - val_loss: 68085.6641\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 18888.4609 - val_loss: 67071.3359\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 18569.4492 - val_loss: 65977.9297\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 18235.0449 - val_loss: 64738.3555\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 17871.7578 - val_loss: 63257.2617\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 17461.3906 - val_loss: 61388.2852\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 16981.0215 - val_loss: 59022.1719\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 16410.7480 - val_loss: 56363.3711\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 15752.0117 - val_loss: 53851.5508\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 15030.7031 - val_loss: 51389.2500\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 14240.9531 - val_loss: 48373.5117\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 13281.3545 - val_loss: 44472.0781\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 11982.4111 - val_loss: 36756.2539\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 10200.8213 - val_loss: 30509.8594\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8726.3037 - val_loss: 25079.2266\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7509.6890 - val_loss: 20597.3594\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 6366.9360 - val_loss: 16419.6602\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 5227.7310 - val_loss: 11755.7881\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3954.0383 - val_loss: 8185.1187\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2763.9050 - val_loss: 6166.4829\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1934.2969 - val_loss: 4769.2485\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1373.4413 - val_loss: 3406.7688\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 915.2402 - val_loss: 1902.6143\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 505.7806 - val_loss: 569.5688\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 183.3519 - val_loss: 3.9428\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 28.0326 - val_loss: 635.6368\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 135.9972 - val_loss: 2075.5144\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 430.7283 - val_loss: 3097.6160\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 677.8251 - val_loss: 3602.9434\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 805.0017 - val_loss: 3577.6848\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 803.0275 - val_loss: 2968.4043\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 680.2438 - val_loss: 1903.3549\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 473.4128 - val_loss: 1060.7358\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 284.0801 - val_loss: 561.1871\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 159.8748 - val_loss: 242.2399\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 82.7343 - val_loss: 69.0119\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 39.1066 - val_loss: 4.8493\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 20.5834 - val_loss: 7.4714\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 19.1017 - val_loss: 42.6596\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 27.3899 - val_loss: 88.1745\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 39.9783 - val_loss: 132.3134\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 53.2969 - val_loss: 169.6310\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 65.2672 - val_loss: 197.8486\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 74.7525 - val_loss: 216.6887\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 81.1459 - val_loss: 225.4183\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 84.2906 - val_loss: 224.7125\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 84.3148 - val_loss: 215.7528\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 81.5318 - val_loss: 200.0247\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 76.3703 - val_loss: 179.1894\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 69.3195 - val_loss: 155.5760\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 60.9253 - val_loss: 129.9921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 51.6807 - val_loss: 103.4851\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 41.9522 - val_loss: 76.4302\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 32.0749 - val_loss: 48.1702\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 22.4225 - val_loss: 18.2342\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 13.9656 - val_loss: 0.0943\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 10.0294 - val_loss: 28.9679\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 15.1374 - val_loss: 45.6732\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18.7544 - val_loss: 37.4350\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 17.8226 - val_loss: 18.4470\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.5232 - val_loss: 4.9328\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.3679 - val_loss: 0.7043\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.4962 - val_loss: 0.0365\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.5564 - val_loss: 0.0252\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 8.0405 - val_loss: 0.0570\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.7015 - val_loss: 0.0642\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.4408 - val_loss: 0.0569\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.2181 - val_loss: 0.0457\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.0152 - val_loss: 0.0353\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.8230 - val_loss: 0.0271\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.6371 - val_loss: 0.0213\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.4556 - val_loss: 0.0174\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.2778 - val_loss: 0.0151\n",
      "WARNING:tensorflow:9 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000227CBA08DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[59.418816]]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(3, 2)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "history = model.fit(X, Y, epochs=100, validation_split=0.2, verbose=1)\n",
    "\n",
    "test_input = array([[8, 51],\n",
    "                    [11,56],\n",
    "                    [14,61]])\n",
    "\n",
    "test_input = test_input.reshape((1, 3, 2))\n",
    "test_output = model.predict(test_input, verbose=0)\n",
    "print(test_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 545ms/step - loss: 31201.3145 - val_loss: 113262.7500\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 31195.6797 - val_loss: 113223.6016\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 31187.7988 - val_loss: 113177.5000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 31176.4551 - val_loss: 113117.9766\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 31161.8125 - val_loss: 113048.5703\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 31143.6406 - val_loss: 112951.1953\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 31119.4277 - val_loss: 112772.7109\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 31083.5215 - val_loss: 112529.5000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 31031.2266 - val_loss: 112211.8203\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 30955.0879 - val_loss: 111803.2891\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 30846.0527 - val_loss: 111244.4922\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 30673.6406 - val_loss: 110578.4453\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 30430.3301 - val_loss: 109348.4297\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 30111.4668 - val_loss: 107706.3359\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 29669.2090 - val_loss: 105720.9297\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 29150.8750 - val_loss: 103514.9609\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 28528.8066 - val_loss: 100526.4453\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 27680.7188 - val_loss: 96146.2109\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 26542.9453 - val_loss: 86525.8203\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 24502.5488 - val_loss: 81888.0703\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 22551.9004 - val_loss: 76567.6797\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 20894.4863 - val_loss: 68718.0703\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 18748.9980 - val_loss: 59325.0664\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 16000.7627 - val_loss: 40404.4375\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 10745.1865 - val_loss: 22041.0703\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 6028.7134 - val_loss: 6708.0352\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1908.5734 - val_loss: 17.4707\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 60.3632 - val_loss: 10517.1055\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2787.5527 - val_loss: 17905.9512\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4787.0698 - val_loss: 15193.8467\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4036.6843 - val_loss: 8325.5723\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2233.9084 - val_loss: 3048.2571\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 805.9097 - val_loss: 373.7606\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 124.1530 - val_loss: 3.5843\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 62.0997 - val_loss: 605.3924\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 265.3111 - val_loss: 1646.5306\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 588.2047 - val_loss: 2539.9690\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 854.8405 - val_loss: 2968.3660\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 971.8460 - val_loss: 1399.5043\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 485.5678 - val_loss: 616.8179\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 320.8301 - val_loss: 282.6783\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 206.1911 - val_loss: 39.3425\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 107.8419 - val_loss: 38.9903\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 59.2294 - val_loss: 311.8421\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 88.6178 - val_loss: 606.5598\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 145.0140 - val_loss: 698.9533\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 168.0989 - val_loss: 608.7781\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 151.8160 - val_loss: 451.3942\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 115.4514 - val_loss: 271.5373\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 77.2298 - val_loss: 117.2828\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 49.1611 - val_loss: 25.6891\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 37.4685 - val_loss: 0.3688\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 40.2226 - val_loss: 16.9512\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 48.6453 - val_loss: 41.5221\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 52.0364 - val_loss: 46.9655\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 43.3386 - val_loss: 6.2188\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 25.1882 - val_loss: 77.6337\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 40.0245 - val_loss: 56.5865\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 34.0141 - val_loss: 3.6421\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 21.4128 - val_loss: 14.0874\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 23.9134 - val_loss: 35.2554\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 29.1260 - val_loss: 29.3024\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 26.8794 - val_loss: 8.1026\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 20.1453 - val_loss: 1.7263\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 16.8882 - val_loss: 23.6367\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 20.0476 - val_loss: 33.5352\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 21.2380 - val_loss: 16.4580\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 17.1710 - val_loss: 1.0239\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 13.7783 - val_loss: 3.4605\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 14.3686 - val_loss: 10.0729\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 15.6681 - val_loss: 8.8204\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 14.7042 - val_loss: 2.1933\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 12.1290 - val_loss: 0.9573\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 10.5148 - val_loss: 9.5163\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 10.9101 - val_loss: 17.0864\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 11.2125 - val_loss: 14.4597\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 9.8306 - val_loss: 6.2415\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.9724 - val_loss: 0.9711\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.1874 - val_loss: 0.2328\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step - loss: 7.2657 - val_loss: 0.4358\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 6.9977 - val_loss: 0.1952\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 5.9639 - val_loss: 1.7402\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 4.8130 - val_loss: 6.7151\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 4.2878 - val_loss: 12.3826\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.2299 - val_loss: 14.1761\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.8998 - val_loss: 11.0357\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.1093 - val_loss: 6.0444\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.3434 - val_loss: 2.4861\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.9853 - val_loss: 1.0587\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.8636 - val_loss: 0.9049\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.6089 - val_loss: 1.7221\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1.1535 - val_loss: 3.9375\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7498 - val_loss: 7.3234\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6333 - val_loss: 10.2554\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6699 - val_loss: 10.9588\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6268 - val_loss: 9.1982\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4519 - val_loss: 6.3323\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2960 - val_loss: 3.9215\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2773 - val_loss: 2.6149\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3391 - val_loss: 2.3229\n",
      "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000227BD0E8D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[73.0089]]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(200, activation='relu', return_sequences=True, input_shape=(3, 2)))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(25, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history = model.fit(X, Y, epochs=100, validation_split=0.2, verbose=1)\n",
    "\n",
    "test_output = model.predict(test_input, verbose=0)\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 32437.2754 - val_loss: 116127.8750\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 31768.5723 - val_loss: 113260.3516\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 31043.7363 - val_loss: 110642.7500\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 30290.4473 - val_loss: 108142.8984\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 29489.0625 - val_loss: 104990.7266\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 28567.5684 - val_loss: 101043.4766\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 27549.7324 - val_loss: 97815.2109\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 26540.6113 - val_loss: 94168.5703\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 25457.6250 - val_loss: 88996.6016\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 24266.0098 - val_loss: 83348.4141\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 23127.3379 - val_loss: 79254.1953\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 22195.3438 - val_loss: 76478.3359\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 21449.3652 - val_loss: 74223.4766\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 20795.5410 - val_loss: 72211.2578\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 20185.2793 - val_loss: 70327.3828\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 19590.3223 - val_loss: 68476.0625\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 18985.4219 - val_loss: 66544.6484\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 18345.6504 - val_loss: 64355.2188\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 17642.0098 - val_loss: 61633.9688\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 16855.8301 - val_loss: 58310.1875\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 16023.3701 - val_loss: 54749.6133\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 15154.9062 - val_loss: 50907.7930\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 14221.1992 - val_loss: 46427.6875\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 13238.1279 - val_loss: 42804.5117\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 12328.4854 - val_loss: 40120.1602\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11545.9062 - val_loss: 37695.1523\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 10840.4678 - val_loss: 35338.7930\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 10165.3486 - val_loss: 33032.2852\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9488.6885 - val_loss: 30850.9316\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 8799.8486 - val_loss: 28699.6504\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 8085.1060 - val_loss: 26315.8203\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7309.1953 - val_loss: 23462.2246\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6418.4180 - val_loss: 19607.8770\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 5351.9834 - val_loss: 14602.5107\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4150.7397 - val_loss: 10069.2432\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3017.2805 - val_loss: 6404.8667\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2058.4187 - val_loss: 3554.3352\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1278.6600 - val_loss: 1902.0009\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 717.4167 - val_loss: 854.0696\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 350.2898 - val_loss: 246.9434\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 129.9103 - val_loss: 2.2311\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 31.1733 - val_loss: 452.7009\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 127.8462 - val_loss: 1262.7638\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 303.7533 - val_loss: 1930.5898\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 455.5673 - val_loss: 2386.7256\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 551.3200 - val_loss: 2540.7122\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 575.6457 - val_loss: 2068.1843\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 494.7619 - val_loss: 1394.9320\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 351.6456 - val_loss: 1165.5693\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 275.7299 - val_loss: 972.4269\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 223.9743 - val_loss: 774.2520\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 176.7098 - val_loss: 577.3204\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 132.9384 - val_loss: 410.3604\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 95.9752 - val_loss: 288.3627\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 68.3420 - val_loss: 203.5208\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 49.2405 - val_loss: 143.6015\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 36.4955 - val_loss: 98.9497\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 28.2104 - val_loss: 64.5961\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 23.1909 - val_loss: 38.8800\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 20.5256 - val_loss: 21.0240\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 19.3057 - val_loss: 10.1032\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 18.5990 - val_loss: 4.9045\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 17.6931 - val_loss: 5.3462\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 17.3036 - val_loss: 2.8070\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 16.6073 - val_loss: 0.0416\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 15.4901 - val_loss: 0.4521\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.8196 - val_loss: 0.3850\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.5765 - val_loss: 2.0296\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 13.7912 - val_loss: 3.0928\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 13.1908 - val_loss: 0.0450\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 12.4010 - val_loss: 0.1232\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 11.4139 - val_loss: 2.6639\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 10.5759 - val_loss: 0.5493\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 9.4515 - val_loss: 0.9775\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 8.8075 - val_loss: 0.1301\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.7340 - val_loss: 1.7999\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.2059 - val_loss: 0.0235\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6.5316 - val_loss: 0.6953\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 5.9099 - val_loss: 0.8488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.3294 - val_loss: 2.7152\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.9346 - val_loss: 8.7612\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.6386 - val_loss: 10.3471\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.3880 - val_loss: 6.7525\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.1926 - val_loss: 7.3295\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 4.0527 - val_loss: 11.3212\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.9699 - val_loss: 10.2468\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.8500 - val_loss: 7.6750\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.7314 - val_loss: 10.4427\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.5671 - val_loss: 13.4823\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.4343 - val_loss: 9.3792\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.2605 - val_loss: 7.5553\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.1017 - val_loss: 9.5353\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.9125 - val_loss: 6.3319\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.6906 - val_loss: 2.9168\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.4744 - val_loss: 3.5018\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.2309 - val_loss: 1.7607\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.9934 - val_loss: 0.4217\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.7854 - val_loss: 1.0967\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.5936 - val_loss: 0.1739\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.4146 - val_loss: 0.2877\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000227CAFE6700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[69.88552]]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(3, 2)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history = model.fit(X, Y, epochs=100, validation_split=0.2, verbose=1)\n",
    "test_output = model.predict(test_input, verbose=0)\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 12  20]\n",
      " [ 21  35]\n",
      " [ 30  50]\n",
      " [ 39  65]\n",
      " [ 48  80]\n",
      " [ 57  95]\n",
      " [ 66 110]\n",
      " [ 75 125]\n",
      " [ 84 140]\n",
      " [ 93 155]\n",
      " [102 170]\n",
      " [111 185]\n",
      " [120 200]\n",
      " [129 215]\n",
      " [138 230]]\n"
     ]
    }
   ],
   "source": [
    "# many to one case where we want one output for each feature in the time-step\n",
    "Y = list()\n",
    "for x in X:\n",
    "    new_item = list()\n",
    "    new_item.append(x[2][0]+3)\n",
    "    new_item.append(x[2][1]+5)\n",
    "    Y.append(new_item)\n",
    "\n",
    "Y = np.array(Y)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 642ms/step - loss: 9502.6924 - val_loss: 32987.6211\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 9275.5010 - val_loss: 32060.7910\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 9039.7656 - val_loss: 31029.2520\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 8795.2256 - val_loss: 29959.5684\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8548.4336 - val_loss: 28954.8340\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 8309.7910 - val_loss: 28100.4434\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 8087.5991 - val_loss: 27412.8203\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7884.8657 - val_loss: 26834.0527\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 7695.8359 - val_loss: 26284.9277\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7510.4868 - val_loss: 25701.2500\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7320.2788 - val_loss: 25039.3809\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 7117.1470 - val_loss: 24290.6250\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6897.5625 - val_loss: 23470.6074\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6660.9062 - val_loss: 22599.4219\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 6407.0708 - val_loss: 21665.3105\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6134.8477 - val_loss: 20611.9902\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 5843.3379 - val_loss: 19389.8105\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5536.2397 - val_loss: 18056.4629\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 5225.4458 - val_loss: 16779.2637\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4927.9980 - val_loss: 15679.1250\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4657.6519 - val_loss: 14777.0938\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4419.6030 - val_loss: 14042.9844\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4210.5820 - val_loss: 13422.1885\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4021.7903 - val_loss: 12854.8174\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3842.7161 - val_loss: 12289.9365\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 3663.9617 - val_loss: 11705.5459\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3478.0576 - val_loss: 11113.2510\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3278.1482 - val_loss: 10519.0918\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 3054.3196 - val_loss: 9876.1240\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2788.5906 - val_loss: 9054.2432\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2452.9844 - val_loss: 7805.7642\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2024.8478 - val_loss: 5897.2852\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1546.2930 - val_loss: 3990.8289\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1148.5298 - val_loss: 2782.0417\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 844.0027 - val_loss: 1711.6602\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 608.3310 - val_loss: 1237.7251\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 462.9458 - val_loss: 927.5156\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 355.6273 - val_loss: 707.6248\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 275.1666 - val_loss: 564.8333\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 217.5565 - val_loss: 527.2185\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 183.2613 - val_loss: 600.5533\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 169.3353 - val_loss: 705.8167\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 166.6449 - val_loss: 779.6205\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 166.1664 - val_loss: 797.1213\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 162.5508 - val_loss: 771.0649\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 154.6238 - val_loss: 737.9284\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 144.5746 - val_loss: 709.7912\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 134.4190 - val_loss: 676.5792\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 124.0426 - val_loss: 630.2731\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 112.6621 - val_loss: 569.7395\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 100.0594 - val_loss: 497.6938\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 86.6546 - val_loss: 418.4614\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 73.2278 - val_loss: 337.0023\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 60.6675 - val_loss: 258.4649\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 49.7842 - val_loss: 187.7396\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 41.1663 - val_loss: 128.6865\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 35.0785 - val_loss: 83.2313\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 31.4321 - val_loss: 51.0134\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 29.8474 - val_loss: 29.9579\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 29.7825 - val_loss: 17.3138\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 30.6669 - val_loss: 10.4828\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 31.9915 - val_loss: 7.4114\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 33.3519 - val_loss: 6.6303\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 34.4536 - val_loss: 6.9185\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 35.0700 - val_loss: 7.5364\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 35.0511 - val_loss: 8.2450\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 34.3204 - val_loss: 9.2805\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 32.8684 - val_loss: 11.4843\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 30.7964 - val_loss: 15.0579\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 28.3326 - val_loss: 19.4034\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 25.7214 - val_loss: 27.2882\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 23.3539 - val_loss: 44.7832\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 22.0532 - val_loss: 65.9699\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 22.0636 - val_loss: 74.1479\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 21.6350 - val_loss: 66.8781\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 19.9286 - val_loss: 51.4240\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 17.5715 - val_loss: 36.1354\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 15.3613 - val_loss: 25.1232\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 13.6405 - val_loss: 18.2716\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 12.3547 - val_loss: 14.1783\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 11.3782 - val_loss: 11.7658\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.6619 - val_loss: 10.4160\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 10.1203 - val_loss: 9.7253\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.6766 - val_loss: 9.3181\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 9.1929 - val_loss: 8.9874\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.6339 - val_loss: 8.7338\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 8.0962 - val_loss: 8.6114\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 7.6505 - val_loss: 8.1154\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 7.2630 - val_loss: 7.3274\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 6.9471 - val_loss: 6.4824\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 6.7214 - val_loss: 5.7981\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 6.5570 - val_loss: 5.3778\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6.3931 - val_loss: 5.2167\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.2048 - val_loss: 5.2397\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.0270 - val_loss: 5.2860\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.8814 - val_loss: 5.1535\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5.7201 - val_loss: 4.8400\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.5391 - val_loss: 4.5303\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.3806 - val_loss: 4.3548\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 5.2348 - val_loss: 4.3356\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(3, 2)))\n",
    "model.add(Dense(2))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history = model.fit(X, Y, epochs=100, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000227C5C19040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[29.275103 49.783188]]\n"
     ]
    }
   ],
   "source": [
    "test_input = array([[20,34],\n",
    "                    [23,39],\n",
    "                    [26,44]])\n",
    "\n",
    "test_input = test_input.reshape((1, 3, 2))\n",
    "test_output = model.predict(test_input, verbose=0)\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 8980.4883 - val_loss: 31560.8594\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8975.0654 - val_loss: 31547.0254\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8969.8486 - val_loss: 31537.9590\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8967.9219 - val_loss: 31534.6152\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8967.3916 - val_loss: 31527.4004\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 8966.1221 - val_loss: 31504.2988\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8961.9219 - val_loss: 31479.4062\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8955.6299 - val_loss: 31461.3906\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 8949.9697 - val_loss: 31440.6621\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 8943.7568 - val_loss: 31415.0723\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 8936.5166 - val_loss: 31391.9707\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 8928.1328 - val_loss: 31355.1953\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 8916.3320 - val_loss: 31299.6426\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 8895.9189 - val_loss: 31181.3770\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 8864.8066 - val_loss: 31049.8125\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 8823.6299 - val_loss: 30861.0801\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 8761.8604 - val_loss: 30575.6641\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8676.8750 - val_loss: 30177.9785\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 8564.3896 - val_loss: 29660.5000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8421.8105 - val_loss: 29042.2500\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 8249.2217 - val_loss: 28243.9434\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8048.5586 - val_loss: 27262.7832\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7798.8750 - val_loss: 26097.8750\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7482.3555 - val_loss: 24812.7285\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7032.3638 - val_loss: 23090.4785\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6403.6421 - val_loss: 20587.0332\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 5682.0991 - val_loss: 18031.1035\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 4902.9175 - val_loss: 15063.0576\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3939.6982 - val_loss: 10935.7852\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2796.4148 - val_loss: 6711.5317\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1705.4165 - val_loss: 2963.4441\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 685.5818 - val_loss: 155.7956\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 181.4469 - val_loss: 483.6024\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 227.9865 - val_loss: 2072.5020\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 656.2200 - val_loss: 2842.4885\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 845.5801 - val_loss: 2378.1145\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 699.6844 - val_loss: 1303.1464\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 421.3985 - val_loss: 535.6254\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 175.4595 - val_loss: 107.7771\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 48.7235 - val_loss: 25.7099\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 20.6997 - val_loss: 137.8411\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 50.6862 - val_loss: 296.6683\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 97.5697 - val_loss: 430.6233\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 139.7147 - val_loss: 500.9362\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 164.7284 - val_loss: 496.1061\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 168.3175 - val_loss: 427.3253\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 152.3496 - val_loss: 317.3075\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 122.5073 - val_loss: 192.1683\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 86.1920 - val_loss: 78.6613\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 52.1275 - val_loss: 12.2916\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 28.3030 - val_loss: 3.6926\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 18.4662 - val_loss: 47.7423\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 22.8488 - val_loss: 123.0155\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 37.0742 - val_loss: 195.9619\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 52.8876 - val_loss: 236.9321\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 62.0497 - val_loss: 234.1849\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 60.9390 - val_loss: 195.0414\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 51.3460 - val_loss: 137.5497\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 37.9236 - val_loss: 80.3601\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 25.2210 - val_loss: 35.9756\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 15.9379 - val_loss: 9.2760\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 10.6999 - val_loss: 1.3417\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 9.4396 - val_loss: 13.5893\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 12.3368 - val_loss: 20.1197\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 14.9176 - val_loss: 22.5194\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 16.3696 - val_loss: 22.3482\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 16.3187 - val_loss: 15.7023\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 13.6301 - val_loss: 7.7586\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 10.0722 - val_loss: 1.7876\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.9951 - val_loss: 2.5714\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 8.0512 - val_loss: 2.8930\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 7.5764 - val_loss: 2.3414\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 6.4325 - val_loss: 4.2217\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.0938 - val_loss: 5.7989\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6.3629 - val_loss: 4.8027\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.2443 - val_loss: 3.1322\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.7543 - val_loss: 1.6459\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.1730 - val_loss: 1.3249\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8318 - val_loss: 2.3746\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.8116 - val_loss: 3.1134\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.8213 - val_loss: 2.4382\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.6883 - val_loss: 1.2972\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.5460 - val_loss: 0.6915\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 4.4849 - val_loss: 0.5101\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.3903 - val_loss: 0.3311\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.1396 - val_loss: 0.1254\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.7702 - val_loss: 0.1361\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.4275 - val_loss: 0.4832\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.2149 - val_loss: 0.9499\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.1002 - val_loss: 1.1920\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.9739 - val_loss: 1.1143\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.7823 - val_loss: 0.8818\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 2.5620 - val_loss: 0.6556\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.3633 - val_loss: 0.4768\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.1952 - val_loss: 0.3214\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0388 - val_loss: 0.1775\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.8820 - val_loss: 0.0774\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.7351 - val_loss: 0.0785\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.6227 - val_loss: 0.2055\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.5464 - val_loss: 0.4010\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000227CB6B9EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[29.692759 49.948353]]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(3, 2)))\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(25, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(2))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history = model.fit(X, Y, epochs=100, validation_split=0.2, verbose=1)\n",
    "\n",
    "test_output = model.predict(test_input, verbose=0)\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 987ms/step - loss: 10514.7207 - val_loss: 35932.2539\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 10226.0127 - val_loss: 34822.4180\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 9951.3164 - val_loss: 33907.7344\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 9703.5137 - val_loss: 33122.4023\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 9481.0811 - val_loss: 32387.7246\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9272.0225 - val_loss: 31683.7188\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 9070.4873 - val_loss: 31005.2793\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 8873.8066 - val_loss: 30347.1973\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8680.1182 - val_loss: 29701.9766\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 8487.8467 - val_loss: 29059.0625\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 8295.3350 - val_loss: 28406.1230\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 8101.2422 - val_loss: 27736.9941\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7905.4282 - val_loss: 27063.2031\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7709.2852 - val_loss: 26397.8887\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 7514.2954 - val_loss: 25742.2793\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 7321.0298 - val_loss: 25049.0156\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 7122.1655 - val_loss: 24308.4629\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6915.6953 - val_loss: 23552.8730\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 6703.4805 - val_loss: 22830.4453\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6488.8921 - val_loss: 22139.8770\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6271.2441 - val_loss: 21425.1328\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6045.6226 - val_loss: 20679.0977\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5808.6548 - val_loss: 19883.8398\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5554.2319 - val_loss: 18956.5879\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5271.4805 - val_loss: 17792.4746\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4952.2729 - val_loss: 16383.4561\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4602.7583 - val_loss: 15002.8623\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4246.2700 - val_loss: 13792.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3889.7871 - val_loss: 12498.8369\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3504.9934 - val_loss: 10793.7002\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3058.2327 - val_loss: 8771.0791\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2548.5686 - val_loss: 6635.2515\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1998.0319 - val_loss: 4685.8071\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1448.7816 - val_loss: 2990.9368\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 907.7707 - val_loss: 980.1531\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 373.4919 - val_loss: 114.8299\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 79.1250 - val_loss: 633.7459\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 108.3238 - val_loss: 1216.5831\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 225.1946 - val_loss: 1621.9840\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 322.9290 - val_loss: 1774.8463\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 371.6853 - val_loss: 1752.7216\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 379.9207 - val_loss: 1625.1406\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 361.0147 - val_loss: 1434.8359\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 323.4671 - val_loss: 1241.3416\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 277.9026 - val_loss: 1067.0817\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 232.7375 - val_loss: 905.2463\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 190.7327 - val_loss: 750.8117\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 152.3207 - val_loss: 605.2325\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 117.9315 - val_loss: 472.3260\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 88.2031 - val_loss: 355.5113\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 63.6611 - val_loss: 256.8488\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 44.5157 - val_loss: 176.9281\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 30.6261 - val_loss: 115.0865\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 21.5373 - val_loss: 69.7199\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 16.5578 - val_loss: 38.6090\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 14.8408 - val_loss: 19.1962\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 15.4530 - val_loss: 8.8008\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 17.4413 - val_loss: 4.7885\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 19.8787 - val_loss: 4.7315\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 21.9153 - val_loss: 6.5652\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 22.8209 - val_loss: 8.6486\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 21.9948 - val_loss: 9.5785\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 19.0529 - val_loss: 7.9992\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 13.9366 - val_loss: 3.8272\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 7.6040 - val_loss: 5.1946\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.1697 - val_loss: 21.3728\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 11.7010 - val_loss: 22.8352\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 11.9448 - val_loss: 16.3462\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.6492 - val_loss: 10.0894\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.9021 - val_loss: 6.0980\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 4.5228 - val_loss: 4.2015\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.3027 - val_loss: 3.3502\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.0437 - val_loss: 2.6480\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 6.1181 - val_loss: 2.0914\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 5.4787 - val_loss: 2.1609\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 4.4219 - val_loss: 3.1398\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.3206 - val_loss: 4.9874\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.4645 - val_loss: 7.5029\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.0218 - val_loss: 10.4165\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.0319 - val_loss: 13.3121\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.3543 - val_loss: 15.3836\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.6437 - val_loss: 15.8762\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 2.6032 - val_loss: 14.9557\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 2.2696 - val_loss: 13.3273\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.8676 - val_loss: 11.5429\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.5650 - val_loss: 9.8870\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.4084 - val_loss: 8.4906\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.3692 - val_loss: 7.4065\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.3937 - val_loss: 6.6395\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.4303 - val_loss: 6.1676\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.4415 - val_loss: 5.9581\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.4093 - val_loss: 5.9760\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.3343 - val_loss: 6.1860\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.2316 - val_loss: 6.5477\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1232 - val_loss: 7.0085\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0289 - val_loss: 7.5012\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9583 - val_loss: 7.9478\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9115 - val_loss: 8.2685\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8806 - val_loss: 8.3963\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8531 - val_loss: 8.2919\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000227C30FA3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[29.812836 49.301643]]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(3, 2)))\n",
    "model.add(Dense(2))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history = model.fit(X, Y, epochs=100, validation_split=0.2, verbose=1)\n",
    "test_output = model.predict(test_input, verbose=0)\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 7, 10, 13, 16, 19, 22, 25, 28, 31, 34, 37, 40, 43]\n",
      "[[2, 3], [5, 6], [8, 9], [11, 12], [14, 15], [17, 18], [20, 21], [23, 24], [26, 27], [29, 30], [32, 33], [35, 36], [38, 39], [41, 42], [44, 45]]\n"
     ]
    }
   ],
   "source": [
    "# one to many with single feature\n",
    "X = list()\n",
    "Y = list()\n",
    "X = [x+3 for x in range(-2, 43, 3)]\n",
    "\n",
    "for i in X:\n",
    "    output_vector = list()\n",
    "    output_vector.append(i+1)\n",
    "    output_vector.append(i+2)\n",
    "    Y.append(output_vector)\n",
    "\n",
    "print(X)\n",
    "print(Y)\n",
    "\n",
    "X = np.array(X).reshape(15, 1, 1)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 236ms/step - loss: 429.8820 - val_loss: 1550.6732\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 423.6541 - val_loss: 1527.2133\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 417.0865 - val_loss: 1502.4603\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 410.3382 - val_loss: 1474.9801\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 402.8879 - val_loss: 1444.8717\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 394.9902 - val_loss: 1411.3280\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 386.6557 - val_loss: 1373.9049\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 376.4530 - val_loss: 1333.7628\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 367.4108 - val_loss: 1288.7833\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 354.7078 - val_loss: 1242.1323\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 343.9059 - val_loss: 1189.8883\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 329.7857 - val_loss: 1134.7286\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 316.4019 - val_loss: 1076.2021\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 303.4495 - val_loss: 1012.7593\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 286.3701 - val_loss: 948.2599\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 269.2141 - val_loss: 882.3395\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 255.3787 - val_loss: 810.8245\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 236.8583 - val_loss: 739.5599\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 220.0629 - val_loss: 666.2588\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 199.8254 - val_loss: 595.8046\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 182.8667 - val_loss: 525.4404\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 164.2936 - val_loss: 457.9619\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 148.3290 - val_loss: 391.3643\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 130.8156 - val_loss: 330.0232\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 113.3528 - val_loss: 275.3737\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 99.5699 - val_loss: 224.6287\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 84.9981 - val_loss: 180.4196\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 72.5093 - val_loss: 141.8567\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 60.6766 - val_loss: 109.4928\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 51.4065 - val_loss: 81.8785\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 41.5177 - val_loss: 60.4507\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 34.3956 - val_loss: 43.2246\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 28.7189 - val_loss: 29.5145\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 23.5744 - val_loss: 19.3006\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 18.6843 - val_loss: 12.4397\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 15.6076 - val_loss: 7.7601\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 12.7816 - val_loss: 5.0587\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 10.6173 - val_loss: 3.8103\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 9.1586 - val_loss: 3.6651\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 7.8882 - val_loss: 4.2442\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6.9871 - val_loss: 5.2911\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6.3479 - val_loss: 6.5056\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5.9822 - val_loss: 7.8929\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.6029 - val_loss: 9.1230\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.4057 - val_loss: 10.2883\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.2675 - val_loss: 11.3349\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5.1273 - val_loss: 12.1069\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.0517 - val_loss: 12.7191\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.9850 - val_loss: 13.0720\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.9424 - val_loss: 13.3692\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.8977 - val_loss: 13.5013\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.8646 - val_loss: 13.5852\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.8341 - val_loss: 13.5111\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.8062 - val_loss: 13.4060\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.7777 - val_loss: 13.4410\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.7606 - val_loss: 13.5305\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.7307 - val_loss: 13.4529\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.7090 - val_loss: 13.1607\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.6868 - val_loss: 12.8712\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.6619 - val_loss: 12.7104\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.6399 - val_loss: 12.6645\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.6212 - val_loss: 12.6343\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.5943 - val_loss: 12.3784\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.5657 - val_loss: 12.3111\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.5491 - val_loss: 12.2094\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.5321 - val_loss: 12.2653\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.5019 - val_loss: 12.2095\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.4790 - val_loss: 12.1045\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.4601 - val_loss: 12.0654\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.4531 - val_loss: 11.6425\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4.4155 - val_loss: 11.6433\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 4.3959 - val_loss: 11.4467\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.3728 - val_loss: 11.3530\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 4.3606 - val_loss: 11.4331\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.3284 - val_loss: 11.4583\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.3121 - val_loss: 11.4207\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.2857 - val_loss: 11.2596\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.2728 - val_loss: 11.3089\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 4.2420 - val_loss: 11.2037\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.2235 - val_loss: 11.1465\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.2040 - val_loss: 10.9217\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.1825 - val_loss: 10.9094\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.1707 - val_loss: 10.5608\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4.1407 - val_loss: 10.5608\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.1242 - val_loss: 10.6876\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.1004 - val_loss: 10.3877\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.0805 - val_loss: 10.5066\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.0518 - val_loss: 10.4561\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.0367 - val_loss: 10.4243\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.0140 - val_loss: 10.2317\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.9922 - val_loss: 10.1246\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.9697 - val_loss: 9.9810\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.9544 - val_loss: 9.9746\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.9337 - val_loss: 10.0301\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.9077 - val_loss: 9.8338\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 3.8879 - val_loss: 9.7909\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 3.8737 - val_loss: 9.5321\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.8515 - val_loss: 9.4787\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.8264 - val_loss: 9.3725\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.8115 - val_loss: 9.2777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a60bf1e5b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001A60D633C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[8.6439905 8.660675 ]]\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 265ms/step - loss: 466.5866 - val_loss: 1719.1007\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 464.4266 - val_loss: 1712.5684\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 462.3593 - val_loss: 1704.7490\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 459.5469 - val_loss: 1695.1387\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 456.2471 - val_loss: 1681.9307\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 453.0281 - val_loss: 1663.6820\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 447.4276 - val_loss: 1638.7924\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 439.1081 - val_loss: 1605.1898\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 428.9996 - val_loss: 1557.5020\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 417.8024 - val_loss: 1488.3281\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 397.2605 - val_loss: 1394.0424\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 370.5195 - val_loss: 1265.9498\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 332.7069 - val_loss: 1100.9589\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 296.9854 - val_loss: 895.6019\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 239.9753 - val_loss: 667.5108\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 180.7841 - val_loss: 437.4187\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 112.9518 - val_loss: 247.3080\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 67.3079 - val_loss: 112.2584\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 32.1563 - val_loss: 54.3231\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 18.3443 - val_loss: 57.6890\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 17.7057 - val_loss: 70.4248\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 18.5206 - val_loss: 59.7697\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 14.3268 - val_loss: 32.3462\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 8.0123 - val_loss: 12.5124\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.7217 - val_loss: 2.9585\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.0235 - val_loss: 0.3627\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.8899 - val_loss: 0.6022\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.9559 - val_loss: 0.8335\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.7440 - val_loss: 0.6021\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.4420 - val_loss: 0.4310\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.1149 - val_loss: 0.4343\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.9620 - val_loss: 0.4181\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.8359 - val_loss: 0.2773\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2.7557 - val_loss: 0.1755\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.5858 - val_loss: 0.0487\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.4512 - val_loss: 0.1432\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.3459 - val_loss: 0.3270\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.2673 - val_loss: 0.5101\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2.1962 - val_loss: 0.5702\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.0999 - val_loss: 0.6928\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.0291 - val_loss: 0.6735\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.9680 - val_loss: 0.7047\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.8974 - val_loss: 0.7891\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.8394 - val_loss: 0.9717\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.7869 - val_loss: 1.2579\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.7320 - val_loss: 1.4785\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.6923 - val_loss: 1.5027\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.6480 - val_loss: 1.6043\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.6210 - val_loss: 1.6692\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.5563 - val_loss: 1.9503\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.5212 - val_loss: 2.1468\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.4931 - val_loss: 2.3977\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.4667 - val_loss: 2.3537\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.4267 - val_loss: 2.4499\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.4203 - val_loss: 2.8324\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.3950 - val_loss: 2.6748\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.3541 - val_loss: 2.7974\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.3336 - val_loss: 2.8137\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.3170 - val_loss: 2.8859\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.2920 - val_loss: 3.0950\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.2761 - val_loss: 3.2044\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.2469 - val_loss: 3.4258\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.2528 - val_loss: 3.8189\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.2250 - val_loss: 3.4282\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.2015 - val_loss: 3.4102\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1899 - val_loss: 3.2426\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.1662 - val_loss: 3.1950\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.1617 - val_loss: 3.2144\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.1434 - val_loss: 3.4823\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.1277 - val_loss: 3.4868\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.1244 - val_loss: 3.7872\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0977 - val_loss: 3.5704\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0850 - val_loss: 3.3589\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0678 - val_loss: 3.1439\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0649 - val_loss: 2.8602\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0473 - val_loss: 2.8829\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.0296 - val_loss: 3.0631\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0276 - val_loss: 3.4655\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.0121 - val_loss: 3.2792\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0028 - val_loss: 3.0239\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9826 - val_loss: 3.1959\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9726 - val_loss: 3.1534\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9562 - val_loss: 3.0242\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9428 - val_loss: 2.8765\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9329 - val_loss: 2.7688\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9219 - val_loss: 2.6384\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9065 - val_loss: 2.6795\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9070 - val_loss: 2.5690\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8860 - val_loss: 2.5341\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8774 - val_loss: 2.5771\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8666 - val_loss: 2.8408\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8556 - val_loss: 2.8677\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8475 - val_loss: 2.4343\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8283 - val_loss: 2.3199\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8158 - val_loss: 2.2180\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8209 - val_loss: 2.4271\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7957 - val_loss: 2.2986\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7851 - val_loss: 2.0806\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7799 - val_loss: 1.8862\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7681 - val_loss: 1.8951\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001A61054CD30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[10.737126 11.722481]]\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 216ms/step - loss: 461.1591 - val_loss: 1676.8602\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 454.1223 - val_loss: 1647.5771\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 446.3687 - val_loss: 1618.3844\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 439.0319 - val_loss: 1589.3892\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 429.6093 - val_loss: 1562.1920\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 423.0135 - val_loss: 1532.5846\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 415.7087 - val_loss: 1500.8145\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 405.5837 - val_loss: 1469.4760\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 399.2747 - val_loss: 1433.4872\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 387.4486 - val_loss: 1397.4214\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 376.4561 - val_loss: 1358.3533\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 365.7198 - val_loss: 1314.2499\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 354.1217 - val_loss: 1264.4777\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 339.7396 - val_loss: 1210.4174\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 326.9848 - val_loss: 1147.8651\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 308.9554 - val_loss: 1080.5598\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 289.1458 - val_loss: 1009.3474\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 270.0356 - val_loss: 929.9793\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 249.7232 - val_loss: 841.9808\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 229.1858 - val_loss: 747.2795\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 203.4948 - val_loss: 651.0961\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 178.7854 - val_loss: 553.1268\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 154.5073 - val_loss: 453.7161\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 126.4365 - val_loss: 361.5471\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 105.3062 - val_loss: 271.1925\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 83.8663 - val_loss: 189.7225\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 61.4452 - val_loss: 124.2031\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 45.8756 - val_loss: 71.7081\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 32.4560 - val_loss: 34.4418\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 22.1132 - val_loss: 12.0795\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 14.3938 - val_loss: 2.6865\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 9.5184 - val_loss: 2.6612\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 6.7689 - val_loss: 8.3270\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.2875 - val_loss: 15.8149\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.0763 - val_loss: 23.0391\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.0067 - val_loss: 27.8926\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.0233 - val_loss: 29.6203\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.0620 - val_loss: 29.5668\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5.0203 - val_loss: 28.2415\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.9537 - val_loss: 25.8769\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.8583 - val_loss: 23.0693\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.6510 - val_loss: 21.6132\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.5862 - val_loss: 19.9298\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.5327 - val_loss: 18.1992\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4.4969 - val_loss: 16.6497\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 4.4490 - val_loss: 15.5557\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.3956 - val_loss: 14.9566\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.3669 - val_loss: 14.5027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.3102 - val_loss: 14.3050\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4.2708 - val_loss: 14.4220\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.2283 - val_loss: 14.7192\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.1887 - val_loss: 14.5291\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.1528 - val_loss: 14.8138\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.1117 - val_loss: 14.7863\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.0730 - val_loss: 14.8055\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.0306 - val_loss: 14.4018\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.9944 - val_loss: 14.2926\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.9508 - val_loss: 13.8212\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.9071 - val_loss: 13.5465\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.8690 - val_loss: 13.2937\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.8336 - val_loss: 13.0070\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.7920 - val_loss: 12.6835\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.7497 - val_loss: 12.6462\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.7148 - val_loss: 12.4833\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.6909 - val_loss: 12.8986\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.6398 - val_loss: 12.5408\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.5949 - val_loss: 12.2950\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.5571 - val_loss: 11.9129\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.5337 - val_loss: 11.3002\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.4787 - val_loss: 11.0214\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.4593 - val_loss: 11.5173\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.4006 - val_loss: 11.4730\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.3578 - val_loss: 11.3910\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.3350 - val_loss: 11.4220\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2844 - val_loss: 10.7434\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.2443 - val_loss: 10.5049\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2181 - val_loss: 9.7636\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3.1622 - val_loss: 9.4696\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.1283 - val_loss: 9.2025\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.0911 - val_loss: 9.3321\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 3.0511 - val_loss: 9.0548\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.0153 - val_loss: 9.0018\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2.9753 - val_loss: 9.1428\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2.9381 - val_loss: 9.0899\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.9031 - val_loss: 9.0936\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2.8749 - val_loss: 8.4618\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.8191 - val_loss: 8.3983\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2.7860 - val_loss: 8.0966\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.7457 - val_loss: 7.7810\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2.7245 - val_loss: 7.2323\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2.6688 - val_loss: 7.2066\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.6352 - val_loss: 7.3350\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2.6025 - val_loss: 6.9697\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 2.5650 - val_loss: 7.1420\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.5237 - val_loss: 6.9141\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.4915 - val_loss: 7.0120\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.4448 - val_loss: 6.7953\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.4064 - val_loss: 6.6267\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 2.3771 - val_loss: 6.5384\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.3502 - val_loss: 5.8030\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001A6138599D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[9.175339 9.475454]]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(1, 1)))\n",
    "model.add(Dense(2))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X, Y, epochs=100, validation_split=0.2, batch_size=3)\n",
    "\n",
    "test_input = array([10])\n",
    "test_input = test_input.reshape((1, 1, 1))\n",
    "test_output = model.predict(test_input, verbose=0)\n",
    "print(test_output)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(1, 1)))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(2))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "history = model.fit(X, Y, epochs=100, validation_split=0.2, verbose=1, batch_size=3)\n",
    "\n",
    "test_output = model.predict(test_input, verbose=0)\n",
    "print(test_output)\n",
    "\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(1, 1)))\n",
    "model.add(Dense(2))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history = model.fit(X, Y, epochs=100, validation_split=0.2, verbose=1, batch_size=3)\n",
    "test_output = model.predict(test_input, verbose=0)\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 79ms/step - loss: 905.1554 - val_loss: 3140.6277\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 865.9722 - val_loss: 3003.8579\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 830.9038 - val_loss: 2872.6907\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 789.1575 - val_loss: 2748.7410\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 749.5898 - val_loss: 2605.7136\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 707.8474 - val_loss: 2413.4187\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 646.4099 - val_loss: 2157.2388\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 574.1957 - val_loss: 1843.3258\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 484.9339 - val_loss: 1518.7356\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 410.3751 - val_loss: 1202.5439\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 325.8188 - val_loss: 929.0964\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 242.4731 - val_loss: 644.1112\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 166.2301 - val_loss: 369.0283\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 102.9339 - val_loss: 208.2105\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 61.3851 - val_loss: 125.2390\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 37.8364 - val_loss: 76.0949\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 23.2925 - val_loss: 45.8756\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 14.5785 - val_loss: 27.0042\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 9.2050 - val_loss: 16.0869\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 5.9451 - val_loss: 10.2859\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 4.4038 - val_loss: 7.6945\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.7536 - val_loss: 5.5235\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 3.4210 - val_loss: 5.3207\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 3.3229 - val_loss: 5.1555\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.2758 - val_loss: 5.3899\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 3.2629 - val_loss: 5.8893\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.1985 - val_loss: 5.9022\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 3.1638 - val_loss: 5.7284\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.1143 - val_loss: 5.7097\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.0775 - val_loss: 5.6837\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 3.0570 - val_loss: 5.0507\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 3.0043 - val_loss: 5.2009\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 2.9659 - val_loss: 4.8237\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 2.9248 - val_loss: 4.8621\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 2.8912 - val_loss: 4.7306\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.8557 - val_loss: 4.5324\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.8301 - val_loss: 4.5967\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.7913 - val_loss: 4.4638\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 2.7523 - val_loss: 4.5559\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 2.7238 - val_loss: 4.3412\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 2.6931 - val_loss: 3.9940\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 2.6693 - val_loss: 4.2428\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 2.6428 - val_loss: 3.7712\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.5920 - val_loss: 3.8069\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 2.5652 - val_loss: 3.6146\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 2.5461 - val_loss: 3.8619\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 2.5032 - val_loss: 3.8168\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 2.4824 - val_loss: 3.2066\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 2.4422 - val_loss: 3.2402\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 2.4113 - val_loss: 3.0997\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.3777 - val_loss: 3.1284\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 2.3508 - val_loss: 3.1922\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.3224 - val_loss: 3.0905\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.2949 - val_loss: 3.2358\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.2656 - val_loss: 3.1210\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.2371 - val_loss: 2.9059\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.2102 - val_loss: 2.7909\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.1869 - val_loss: 2.3555\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.1603 - val_loss: 2.3141\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.1355 - val_loss: 2.3157\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.1056 - val_loss: 2.3929\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.0804 - val_loss: 2.4305\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 2.0533 - val_loss: 2.4681\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.0291 - val_loss: 2.5108\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.0048 - val_loss: 2.4610\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.9919 - val_loss: 2.0620\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.9559 - val_loss: 2.1457\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.9322 - val_loss: 2.1136\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.9077 - val_loss: 2.1628\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.8872 - val_loss: 2.2474\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.8680 - val_loss: 1.9067\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.8381 - val_loss: 1.8281\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.8203 - val_loss: 1.8988\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.7966 - val_loss: 1.9230\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.7756 - val_loss: 1.8474\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.7761 - val_loss: 1.4915\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.7332 - val_loss: 1.6229\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.7118 - val_loss: 1.6162\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.6915 - val_loss: 1.6115\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.6740 - val_loss: 1.4369\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.6510 - val_loss: 1.4818\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.6455 - val_loss: 1.6618\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.6124 - val_loss: 1.5693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.5940 - val_loss: 1.5011\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.5745 - val_loss: 1.2899\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.5585 - val_loss: 1.1535\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.5449 - val_loss: 1.0898\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.5243 - val_loss: 1.3178\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.5111 - val_loss: 1.5092\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.4864 - val_loss: 1.3821\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.4749 - val_loss: 1.1023\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.4581 - val_loss: 1.0047\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.4338 - val_loss: 1.1569\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.4155 - val_loss: 1.1989\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.4015 - val_loss: 1.2355\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.3849 - val_loss: 1.0528\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.3682 - val_loss: 1.0330\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.3537 - val_loss: 0.9622\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.3379 - val_loss: 0.8880\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.3241 - val_loss: 0.9939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a61a541b50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001A61CF780D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[41.629787 61.911396]]\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 130ms/step - loss: 987.7256 - val_loss: 3550.6296\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 974.5079 - val_loss: 3502.3203\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 961.4678 - val_loss: 3418.2280\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 937.8309 - val_loss: 3271.0786\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 893.6589 - val_loss: 3042.9824\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 831.2165 - val_loss: 2691.8230\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 732.6320 - val_loss: 2234.5945\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 584.0366 - val_loss: 1678.7859\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 408.2905 - val_loss: 1000.9673\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 191.7451 - val_loss: 302.2462\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 54.1009 - val_loss: 10.4354\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 14.9133 - val_loss: 133.3337\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 20.6500 - val_loss: 76.6345\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 9.5578 - val_loss: 7.6915\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 4.6216 - val_loss: 0.2814\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 4.8551 - val_loss: 0.4149\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 3.4092 - val_loss: 3.5676\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.6821 - val_loss: 7.9338\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.2693 - val_loss: 4.1715\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.7353 - val_loss: 1.8807\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.4898 - val_loss: 1.2516\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.2144 - val_loss: 1.0072\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.0289 - val_loss: 0.6351\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.9026 - val_loss: 0.3049\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8246 - val_loss: 0.1736\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7463 - val_loss: 0.1147\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.6988 - val_loss: 0.1052\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6541 - val_loss: 0.1047\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6137 - val_loss: 0.0931\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5952 - val_loss: 0.0933\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5573 - val_loss: 0.0918\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5295 - val_loss: 0.1050\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5003 - val_loss: 0.1605\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4866 - val_loss: 0.1778\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4562 - val_loss: 0.1750\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4386 - val_loss: 0.2212\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4215 - val_loss: 0.2924\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4009 - val_loss: 0.3240\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3848 - val_loss: 0.2880\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3702 - val_loss: 0.3181\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3527 - val_loss: 0.3832\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3425 - val_loss: 0.4018\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3302 - val_loss: 0.3767\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3173 - val_loss: 0.4288\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3083 - val_loss: 0.4953\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2987 - val_loss: 0.5514\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2858 - val_loss: 0.5228\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2820 - val_loss: 0.5082\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2719 - val_loss: 0.5266\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2649 - val_loss: 0.6528\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2570 - val_loss: 0.7129\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2530 - val_loss: 0.6875\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2456 - val_loss: 0.6312\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2375 - val_loss: 0.7203\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2340 - val_loss: 0.7778\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2258 - val_loss: 0.6369\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2206 - val_loss: 0.6434\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2161 - val_loss: 0.7582\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2131 - val_loss: 0.8126\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2077 - val_loss: 0.7475\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2034 - val_loss: 0.6758\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2005 - val_loss: 0.7846\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1924 - val_loss: 0.7070\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1890 - val_loss: 0.7603\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1851 - val_loss: 0.7620\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1816 - val_loss: 0.7749\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1792 - val_loss: 0.7921\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1794 - val_loss: 0.6963\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1742 - val_loss: 0.6169\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1681 - val_loss: 0.8044\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1653 - val_loss: 0.7058\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1606 - val_loss: 0.7211\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1591 - val_loss: 0.7336\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1569 - val_loss: 0.5813\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1513 - val_loss: 0.6769\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1493 - val_loss: 0.7553\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1451 - val_loss: 0.6509\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1420 - val_loss: 0.5667\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1402 - val_loss: 0.5625\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1386 - val_loss: 0.5247\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1328 - val_loss: 0.6327\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1319 - val_loss: 0.6280\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1263 - val_loss: 0.5091\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1259 - val_loss: 0.6328\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1202 - val_loss: 0.5293\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1216 - val_loss: 0.4496\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1166 - val_loss: 0.5682\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1130 - val_loss: 0.4948\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1095 - val_loss: 0.4484\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1083 - val_loss: 0.4282\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1052 - val_loss: 0.5175\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1022 - val_loss: 0.4111\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0998 - val_loss: 0.3576\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0979 - val_loss: 0.4105\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0941 - val_loss: 0.3495\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0913 - val_loss: 0.3889\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0887 - val_loss: 0.3942\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0870 - val_loss: 0.3134\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0842 - val_loss: 0.3471\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0833 - val_loss: 0.3957\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001A60A92F310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[41.275055 61.222473]]\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 107ms/step - loss: 867.3115 - val_loss: 2972.8750\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 807.5526 - val_loss: 2732.7964\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 737.9297 - val_loss: 2485.7712\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 670.3699 - val_loss: 2202.8723\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 598.8798 - val_loss: 1885.8494\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 495.5721 - val_loss: 1535.6550\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 396.2110 - val_loss: 1132.2428\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 291.8463 - val_loss: 721.7831\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 176.1293 - val_loss: 379.7426\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 89.3356 - val_loss: 127.1144\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 33.0708 - val_loss: 21.4699\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 9.5816 - val_loss: 28.1208\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 7.0254 - val_loss: 39.1589\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 6.4713 - val_loss: 22.2038\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 4.6051 - val_loss: 7.1368\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 3.1820 - val_loss: 3.1483\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 2.8359 - val_loss: 2.0967\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 2.4908 - val_loss: 3.1637\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.2893 - val_loss: 2.3772\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 2.0962 - val_loss: 1.2315\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1.9149 - val_loss: 1.1866\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.8410 - val_loss: 1.6618\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.6079 - val_loss: 0.7526\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.5218 - val_loss: 0.4805\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 1.3766 - val_loss: 0.5509\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.2431 - val_loss: 0.5138\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.1492 - val_loss: 0.3315\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.0344 - val_loss: 0.2015\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9172 - val_loss: 0.1508\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8333 - val_loss: 0.0408\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.7588 - val_loss: 0.0315\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6790 - val_loss: 0.0159\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6151 - val_loss: 0.0148\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5671 - val_loss: 0.0254\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5223 - val_loss: 0.0365\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4772 - val_loss: 0.0491\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4417 - val_loss: 0.0803\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4102 - val_loss: 0.0945\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3792 - val_loss: 0.1057\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3542 - val_loss: 0.1009\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3331 - val_loss: 0.1374\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3144 - val_loss: 0.1304\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2975 - val_loss: 0.1050\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2777 - val_loss: 0.1495\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2655 - val_loss: 0.1507\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2480 - val_loss: 0.0800\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2378 - val_loss: 0.0792\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2223 - val_loss: 0.0967\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2154 - val_loss: 0.0544\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1991 - val_loss: 0.0499\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1903 - val_loss: 0.0529\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1769 - val_loss: 0.0207\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1671 - val_loss: 0.0207\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1560 - val_loss: 0.0254\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1507 - val_loss: 0.0187\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1418 - val_loss: 0.0219\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1314 - val_loss: 0.0123\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1262 - val_loss: 0.0100\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1184 - val_loss: 0.0104\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1120 - val_loss: 0.0113\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1059 - val_loss: 0.0146\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.1007 - val_loss: 0.0164\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0953 - val_loss: 0.0195\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0913 - val_loss: 0.0213\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0865 - val_loss: 0.0283\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0827 - val_loss: 0.0288\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0787 - val_loss: 0.0299\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0779 - val_loss: 0.0392\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0715 - val_loss: 0.0356\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0691 - val_loss: 0.0520\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0653 - val_loss: 0.0652\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0647 - val_loss: 0.0585\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0631 - val_loss: 0.0455\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0596 - val_loss: 0.0621\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0569 - val_loss: 0.0790\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0555 - val_loss: 0.0600\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0529 - val_loss: 0.0660\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0509 - val_loss: 0.0692\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0496 - val_loss: 0.0733\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0486 - val_loss: 0.0745\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0477 - val_loss: 0.0887\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0458 - val_loss: 0.0791\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0449 - val_loss: 0.0770\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0442 - val_loss: 0.0697\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0419 - val_loss: 0.0864\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0416 - val_loss: 0.0784\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0401 - val_loss: 0.0765\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0387 - val_loss: 0.0699\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0383 - val_loss: 0.0709\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0364 - val_loss: 0.0633\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0369 - val_loss: 0.0553\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0362 - val_loss: 0.0782\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0343 - val_loss: 0.0626\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0330 - val_loss: 0.0558\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0321 - val_loss: 0.0585\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0318 - val_loss: 0.0618\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0306 - val_loss: 0.0549\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0297 - val_loss: 0.0567\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0293 - val_loss: 0.0619\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0282 - val_loss: 0.0535\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001A6214C68B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[41.122902 61.08271 ]]\n"
     ]
    }
   ],
   "source": [
    "# one to many with multiple features\n",
    "nums = 25\n",
    "\n",
    "X1 = list()\n",
    "X2 = list()\n",
    "X = list()\n",
    "Y = list()\n",
    "\n",
    "X1 = [(x+1)*2 for x in range(25)]\n",
    "X2 = [(x+1)*3 for x in range(25)]\n",
    "\n",
    "for x1, x2 in zip(X1, X2):\n",
    "    output_vector = list()\n",
    "    output_vector.append(x1+1)\n",
    "    output_vector.append(x2+1)\n",
    "    Y.append(output_vector)\n",
    "\n",
    "X = np.column_stack((X1, X2))\n",
    "#print(X)\n",
    "\n",
    "X = np.array(X).reshape(25, 1, 2)\n",
    "Y = np.array(Y)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(1, 2)))\n",
    "model.add(Dense(2))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X, Y, epochs=100, validation_split=0.2, batch_size=3)\n",
    "\n",
    "test_input = array([40, 60])\n",
    "test_input = test_input.reshape((1, 1, 2))\n",
    "test_output = model.predict(test_input, verbose=0)\n",
    "print(test_output)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(1, 2)))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(2))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "history = model.fit(X, Y, epochs=100, validation_split=0.2, verbose=1, batch_size=3)\n",
    "\n",
    "test_input = array([40, 60])\n",
    "test_input = test_input.reshape((1, 1, 2))\n",
    "test_output = model.predict(test_input, verbose=0)\n",
    "print(test_output)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(1, 2)))\n",
    "model.add(Dense(2))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history = model.fit(X, Y, epochs=100, validation_split=0.2, verbose=1, batch_size=3)\n",
    "test_output = model.predict(test_input, verbose=0)\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# many to many sequence problem with single feature\n",
    "X = [x for x in range(5, 301, 5)]\n",
    "Y = [y for y in range(20, 316, 5)]\n",
    "\n",
    "# 3D format of input/output fpr encoder-decoder\n",
    "X = np.array(X).reshape(20, 3, 1)\n",
    "Y = np.array(Y).reshape(20, 3, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
