{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "import timeit\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.Graph contains objects of tf.Operation and objects tf.Tensor flowing between them\n",
    "# Models in tf are saved as Graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function function_to_get_faster at 0x000001BB675A54C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[12.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to create/trace a graph in tf -> use tf.function directly or as decorator\n",
    "\n",
    "# some python function\n",
    "def function_to_get_faster(x, y, b):\n",
    "    x = tf.matmul(x, y)\n",
    "    x = x + b\n",
    "    return x\n",
    "\n",
    "# create tf.Funtion object -> convert function to graph now!\n",
    "a_function_traced_to_graph = tf.function(function_to_get_faster)\n",
    "\n",
    "# make some tf.Tensors\n",
    "x1 = tf.constant([[1.0, 2.0]])\n",
    "y1 = tf.constant([[2.0], [3.0]])\n",
    "b1 = tf.constant(4.0)\n",
    "\n",
    "a_function_traced_to_graph(x1, y1, b1).numpy().tolist()[0][0]\n",
    "\n",
    "# some decorated python function\n",
    "@tf.function\n",
    "def decorated_function_to_get_faster(x, y, b):\n",
    "    x = tf.matmul(x, y)\n",
    "    x = x + b\n",
    "    if b1.numpy()<0:\n",
    "        return x\n",
    "    else:\n",
    "        return x+tf.constant(0.0)\n",
    "\n",
    "# or loops of function is also fine to create graph. Any loops are also fine. Graph will \n",
    "# def func1(..): return func2(..)  ... def func2(..): return something\n",
    "\n",
    "decorated_function_to_get_faster(x1, y1, b1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speeding up with tf.Graph\n",
    "class SequentialModel(tf.keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SequentialModel, self).__init__(**kwargs)\n",
    "        # following will convert (batch_size, a, b,c ) -> (batch_size,a*b*c)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        # add lot of layers\n",
    "        num_layers = 100\n",
    "        self.inner_layers = [tf.keras.layers.Dense(64, activation='relu') for n in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(0.2)\n",
    "        self.outer_layer = tf.keras.layers.Dense(10)\n",
    "    \n",
    "    # @tf.function will trace a graph\n",
    "    def call(self, x):\n",
    "        x = self.flatten(x)\n",
    "        for layer in self.inner_layers:\n",
    "            x = layer(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.outer_layer(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = tf.random.uniform([25, 28, 28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(25, 10), dtype=float32, numpy=\n",
       "array([[ 5.72243217e-18, -1.18814767e-16, -6.70611734e-17,\n",
       "        -3.88738227e-17, -1.68027696e-17,  9.48875342e-18,\n",
       "        -5.20921358e-17,  6.86947625e-17, -9.63800211e-17,\n",
       "        -6.45736229e-17],\n",
       "       [ 6.17613536e-18, -1.48091879e-16, -8.07584439e-17,\n",
       "        -4.79163858e-17, -1.97955272e-17,  1.55454021e-17,\n",
       "        -6.56110199e-17,  8.59882239e-17, -1.22156617e-16,\n",
       "        -8.13277692e-17],\n",
       "       [ 2.85178292e-18, -9.13426368e-17, -5.07892668e-17,\n",
       "        -2.88825993e-17, -1.23308451e-17,  8.83083546e-18,\n",
       "        -4.10288532e-17,  5.25580503e-17, -7.45246785e-17,\n",
       "        -4.95432251e-17],\n",
       "       [ 6.90795363e-18, -1.34782357e-16, -7.33232615e-17,\n",
       "        -4.49410635e-17, -1.76797002e-17,  1.37441295e-17,\n",
       "        -6.08746036e-17,  7.88622548e-17, -1.11690241e-16,\n",
       "        -7.43601820e-17],\n",
       "       [ 6.38639185e-18, -1.37612546e-16, -7.63345298e-17,\n",
       "        -4.77203804e-17, -1.71819972e-17,  1.25086302e-17,\n",
       "        -6.51700929e-17,  8.09166736e-17, -1.13981187e-16,\n",
       "        -7.60715327e-17],\n",
       "       [ 7.40609544e-18, -1.56419179e-16, -8.62474887e-17,\n",
       "        -5.27198104e-17, -2.08042972e-17,  1.47392286e-17,\n",
       "        -7.14039510e-17,  9.21096052e-17, -1.29022216e-16,\n",
       "        -8.60858643e-17],\n",
       "       [ 3.61575328e-18, -7.55734508e-17, -4.18451878e-17,\n",
       "        -2.57470984e-17, -9.14239883e-18,  7.71967465e-18,\n",
       "        -3.62816140e-17,  4.44164655e-17, -6.31552398e-17,\n",
       "        -4.17684354e-17],\n",
       "       [ 2.57809656e-18, -4.53031568e-17, -2.50774576e-17,\n",
       "        -1.37532392e-17, -6.74778003e-18,  4.62804947e-18,\n",
       "        -1.74692274e-17,  2.57154058e-17, -3.68051664e-17,\n",
       "        -2.45854721e-17],\n",
       "       [ 6.46857142e-18, -1.40516201e-16, -7.80332279e-17,\n",
       "        -4.85508797e-17, -1.76648390e-17,  1.27071337e-17,\n",
       "        -6.62971232e-17,  8.25667931e-17, -1.16230443e-16,\n",
       "        -7.75923539e-17],\n",
       "       [ 4.26804434e-18, -9.94668143e-17, -5.71146640e-17,\n",
       "        -3.01576816e-17, -1.54540036e-17,  8.10326559e-18,\n",
       "        -4.10775510e-17,  5.64469241e-17, -8.00892416e-17,\n",
       "        -5.25749181e-17],\n",
       "       [ 4.12291136e-18, -7.56742875e-17, -4.34830617e-17,\n",
       "        -2.65264415e-17, -9.75006804e-18,  4.96918620e-18,\n",
       "        -3.39500665e-17,  4.36382573e-17, -6.11873109e-17,\n",
       "        -4.11733253e-17],\n",
       "       [ 7.31624956e-18, -1.45464078e-16, -7.99493289e-17,\n",
       "        -4.91132004e-17, -2.01769700e-17,  1.32839011e-17,\n",
       "        -6.48850399e-17,  8.59237104e-17, -1.19540953e-16,\n",
       "        -8.00753118e-17],\n",
       "       [ 2.49212293e-18, -5.67667585e-17, -3.09616880e-17,\n",
       "        -1.90790879e-17, -7.22706130e-18,  5.65206722e-18,\n",
       "        -2.62292090e-17,  3.31676926e-17, -4.69295693e-17,\n",
       "        -3.13453641e-17],\n",
       "       [ 7.18587597e-18, -1.59621665e-16, -8.89518002e-17,\n",
       "        -5.21830562e-17, -2.30657560e-17,  1.34720929e-17,\n",
       "        -6.93841811e-17,  9.28089897e-17, -1.29497865e-16,\n",
       "        -8.69791928e-17],\n",
       "       [ 6.71023471e-18, -1.36402109e-16, -7.52977615e-17,\n",
       "        -4.56965375e-17, -1.92857855e-17,  1.23190379e-17,\n",
       "        -6.02091798e-17,  8.03872450e-17, -1.11747032e-16,\n",
       "        -7.49323197e-17],\n",
       "       [ 4.07715173e-18, -8.35897309e-17, -4.64034626e-17,\n",
       "        -2.89326371e-17, -1.07242089e-17,  7.50676828e-18,\n",
       "        -3.92004333e-17,  4.93625556e-17, -6.91776771e-17,\n",
       "        -4.61531478e-17],\n",
       "       [ 4.89420476e-18, -1.10699371e-16, -6.15093886e-17,\n",
       "        -3.81847052e-17, -1.35835944e-17,  1.04992679e-17,\n",
       "        -5.31660446e-17,  6.53311417e-17, -9.22234782e-17,\n",
       "        -6.10945608e-17],\n",
       "       [ 2.56787137e-18, -6.01573916e-17, -3.48214616e-17,\n",
       "        -1.79355537e-17, -9.47521660e-18,  4.99033059e-18,\n",
       "        -2.49022492e-17,  3.42502007e-17, -4.85108144e-17,\n",
       "        -3.17928721e-17],\n",
       "       [ 5.05988655e-18, -1.06155946e-16, -6.12130263e-17,\n",
       "        -3.38645989e-17, -1.52036756e-17,  9.93245889e-18,\n",
       "        -4.75080001e-17,  6.17509187e-17, -8.72593225e-17,\n",
       "        -5.75409929e-17],\n",
       "       [ 5.56938142e-18, -1.32904816e-16, -7.53133786e-17,\n",
       "        -4.25059132e-17, -1.85287696e-17,  1.09461208e-17,\n",
       "        -5.85923527e-17,  7.63382025e-17, -1.07841231e-16,\n",
       "        -7.17437105e-17],\n",
       "       [ 5.03134055e-18, -1.15192722e-16, -6.40506992e-17,\n",
       "        -3.88179053e-17, -1.41255119e-17,  1.07620143e-17,\n",
       "        -5.40468430e-17,  6.66396686e-17, -9.45755498e-17,\n",
       "        -6.33898613e-17],\n",
       "       [ 5.96755722e-18, -1.27549781e-16, -7.11690847e-17,\n",
       "        -4.46854944e-17, -1.51163899e-17,  1.18960955e-17,\n",
       "        -6.26063095e-17,  7.54932606e-17, -1.06605191e-16,\n",
       "        -7.05344585e-17],\n",
       "       [ 2.77676756e-18, -7.51958197e-17, -4.21660578e-17,\n",
       "        -2.43463424e-17, -9.99718163e-18,  6.64061340e-18,\n",
       "        -3.40383366e-17,  4.32461969e-17, -6.12552059e-17,\n",
       "        -4.08394917e-17],\n",
       "       [ 5.24620196e-18, -1.07009100e-16, -5.88994154e-17,\n",
       "        -3.61301904e-17, -1.44561029e-17,  1.02383619e-17,\n",
       "        -4.88148297e-17,  6.33552388e-17, -8.85186686e-17,\n",
       "        -5.89262359e-17],\n",
       "       [ 6.47756535e-18, -1.35105778e-16, -7.41399998e-17,\n",
       "        -4.59705493e-17, -1.65003672e-17,  1.41227855e-17,\n",
       "        -6.46076697e-17,  7.96599679e-17, -1.13321070e-16,\n",
       "        -7.46912726e-17]], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager time: 3.9543137999989995\n"
     ]
    }
   ],
   "source": [
    "# without graph\n",
    "eager_model = SequentialModel()\n",
    "eager_model(input_data)\n",
    "print(\"Eager time:\", timeit.timeit(lambda: eager_model(input_data), number=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager time: 3.060538200001247\n"
     ]
    }
   ],
   "source": [
    "# with tracing graph\n",
    "eager_model_with_graph = SequentialModel()\n",
    "eager_model_with_graph.call = tf.function(eager_model_with_graph.call)\n",
    "\n",
    "print(\"Eager time:\", timeit.timeit(lambda: eager_model_with_graph(input_data), number=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.eager.def_function.Function object at 0x000001BB7111B6A0>\n"
     ]
    }
   ],
   "source": [
    "# when you do tf.function() (== a_function) -> you make a polymorphic function which has several graph functions\n",
    "\n",
    "def afunction(a):\n",
    "    return tf.constant(a)\n",
    "\n",
    "print(tf.function(lambda x: tf.constant(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager called  2021-01-01 23:01:28.591233\n",
      "Eager called  2021-01-01 23:01:29.082197\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bb66ebb220>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identity layer with eager side-effects\n",
    "class EagerLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(EagerLayer, self).__init__()\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        print(\"Eager called \",str(datetime.now()))\n",
    "        return inputs\n",
    "    \n",
    "\n",
    "class SequentialModel(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(SequentialModel, self).__init__()\n",
    "    self.flatten = tf.keras.layers.Flatten()\n",
    "    self.dense_1 = tf.keras.layers.Dense(128, activation=\"relu\")\n",
    "    self.dropout = tf.keras.layers.Dropout(0.2)\n",
    "    self.dense_2 = tf.keras.layers.Dense(10)\n",
    "    self.eager = EagerLayer()\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.flatten(x)\n",
    "    x = self.dense_1(x)\n",
    "    x = self.dropout(x)\n",
    "    x = self.dense_2(x)\n",
    "    return self.eager(x)\n",
    "    \n",
    "input_data = tf.random.uniform([60, 28, 28])\n",
    "labels = tf.random.uniform([60])\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    \n",
    "model = SequentialModel()\n",
    "# set loss function, optimization, etc. Nothing about graph tracing here\n",
    "model.compile(run_eagerly=False, loss=loss_fn)\n",
    "model.fit(input_data, labels, epochs=1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run all functions eagerly.\n",
      "\n",
      "Calling twice eagerly\n",
      "Eager called  2021-01-01 23:02:34.986816\n",
      "Eager called  2021-01-01 23:02:34.991300\n"
     ]
    }
   ],
   "source": [
    "# Now, globally set everything to run eagerly\n",
    "tf.config.run_functions_eagerly(True)\n",
    "print(\"Run all functions eagerly.\")\n",
    "\n",
    "# Create a polymorphic function\n",
    "polymorphic_function = tf.function(model)\n",
    "\n",
    "print(\"\\nCalling twice eagerly\")\n",
    "# When you run the function again, you will see the side effect\n",
    "# twice, as the function is running eagerly.\n",
    "result = polymorphic_function(input_data)\n",
    "result = polymorphic_function(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-55-782fe9ce7b18>:2: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.run_functions_eagerly` instead of the experimental version.\n"
     ]
    }
   ],
   "source": [
    "# Don't forget to set it back when you are done\n",
    "tf.config.experimental_run_functions_eagerly(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
